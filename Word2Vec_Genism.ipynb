{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word2Vec - Genism.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MkmHuw46sRli"
      },
      "source": [
        "import re\r\n",
        "import pandas as pd\r\n",
        "from time import time\r\n",
        "from collections import defaultdict\r\n",
        "import spacy"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PoRATrbG9oW"
      },
      "source": [
        "# Import PyDrive and associated libraries.\n",
        "# This only needs to be done once per notebook.\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "# Download a file based on its file ID.\n",
        "#\n",
        "# A file ID looks like: laggVyWshwcyP6kEI-y_W3P8D26sz\n",
        "file_id = 'REPLACE_WITH_YOUR_FILE_ID'\n",
        "downloaded = drive.CreateFile({'id': file_id})\n",
        "print('Downloaded content \"{}\"'.format(downloaded.GetContentString()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_nhnPaKHGI8",
        "outputId": "bec7a549-3587-4bc1-ac89-d190aa7fc282"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpFL5JoAsVnO"
      },
      "source": [
        "import logging  # Setting up the loggings to monitor gensim\r\n",
        "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gJXzy-X4HqQC",
        "outputId": "b178b4f9-307c-4105-dc70-76cb4c4dc835"
      },
      "source": [
        "%cd /content/drive/MyDrive/GenismFiles"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Errno 2] No such file or directory: '/content/drive/MyDrive/GenismFiles'\n",
            "/content/drive/MyDrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XO2ck99snZV",
        "outputId": "8818d96f-b871-499c-8046-8580f628a428"
      },
      "source": [
        "df = pd.read_csv('simpsons_dataset.csv')\r\n",
        "df.shape"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(158314, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EYB6we9FthzY",
        "outputId": "6e8e05c4-f311-4b08-b231-9627e0cb3abb"
      },
      "source": [
        "df.isnull().sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    17814\n",
              "spoken_words          26459\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X0wfUj2otknk",
        "outputId": "4b6c8432-7e86-4405-df84-2041f0da8010"
      },
      "source": [
        "df = df.dropna().reset_index(drop=True)\r\n",
        "df.isnull().sum()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:34:56: NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "raw_character_text    0\n",
              "spoken_words          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ufejkx42tnG0"
      },
      "source": [
        "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\r\n",
        "\r\n",
        "def cleaning(doc):\r\n",
        "    # Lemmatizes and removes stopwords\r\n",
        "    # doc needs to be a spacy Doc object\r\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\r\n",
        "    # Word2Vec uses context words to learn the vector representation of a target word,\r\n",
        "    # if a sentence is only one or two words long,\r\n",
        "    # the benefit for the training is very small\r\n",
        "    if len(txt) > 2:\r\n",
        "        return ' '.join(txt)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zUh36Y5tqjU"
      },
      "source": [
        "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxqKWASTttAU",
        "outputId": "5ac4e490-e445-4bba-f252-20cb199a04ee"
      },
      "source": [
        "t = time()\r\n",
        "\r\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\r\n",
        "\r\n",
        "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Time to clean up everything: 1.22 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6gvNOpLt3Nk",
        "outputId": "3cf85c4b-6ac9-4eae-94cc-3c018a9739af"
      },
      "source": [
        "df_clean = pd.DataFrame({'clean': txt})\r\n",
        "df_clean = df_clean.dropna().drop_duplicates()\r\n",
        "df_clean.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(85964, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "aN9trQfeuG88",
        "outputId": "fe256189-7bc8-4e91-c002-bb03f8fa82ab"
      },
      "source": [
        "df_clean.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>actually little disease magazine news show nat...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>know sure like talk touch lesson plan teach</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>life worth live</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>poll open end recess case decide thought final...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>victory party slide</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               clean\n",
              "0  actually little disease magazine news show nat...\n",
              "2        know sure like talk touch lesson plan teach\n",
              "3                                    life worth live\n",
              "4  poll open end recess case decide thought final...\n",
              "7                                victory party slide"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wg-ZoygyuZJ1",
        "outputId": "48395a98-b779-4c6d-c664-01220e9a4363"
      },
      "source": [
        "!pip install gensim"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.19.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (4.1.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKqUnAsluKMc",
        "outputId": "ab58f598-d03c-4954-f705-59f4f39a6e98"
      },
      "source": [
        "from gensim.models.phrases import Phrases, Phraser"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:36:20: 'pattern' package not found; tag filters are not available for English\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afxWC4JHutt9"
      },
      "source": [
        "sent = [row.split() for row in df_clean['clean']]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u05b_i-wuyI9",
        "outputId": "15c7048d-07a4-446c-f78b-7488d55a84bc"
      },
      "source": [
        "phrases = Phrases(sent, min_count=30, progress_per=10000)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:36:20: collecting all words and their counts\n",
            "INFO - 11:36:20: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
            "INFO - 11:36:20: PROGRESS: at sentence #10000, processed 63561 words and 52816 word types\n",
            "INFO - 11:36:20: PROGRESS: at sentence #20000, processed 130943 words and 99866 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #30000, processed 192972 words and 138532 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #40000, processed 249842 words and 172659 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #50000, processed 311265 words and 208566 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #60000, processed 373588 words and 243702 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #70000, processed 436441 words and 278740 word types\n",
            "INFO - 11:36:21: PROGRESS: at sentence #80000, processed 497829 words and 311886 word types\n",
            "INFO - 11:36:21: collected 330804 word types from a corpus of 537160 words (unigram + bigrams) and 85964 sentences\n",
            "INFO - 11:36:21: using 330804 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VMAt3DWcu2Rz",
        "outputId": "7615f57e-073d-444c-aa03-f8dc68658966"
      },
      "source": [
        "bigram = Phraser(phrases)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:36:21: source_vocab length 330804\n",
            "INFO - 11:36:25: Phraser built with 126 phrasegrams\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42tW7Dq_vINT"
      },
      "source": [
        "sentences = bigram[sent]"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOGon_CdvQfy",
        "outputId": "188a572a-b6d9-455a-b1af-dff810537cc3"
      },
      "source": [
        "for sent in sentences:\r\n",
        "  print(sent)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "['right', 'numbskull', 'son', 'fool', 'town']\n",
            "['fix', 'drive', 'car']\n",
            "['good', 'get', 'feed', 'reality', 'show']\n",
            "['wish', 'fix', 'faucet']\n",
            "['okay', 'homer', 'speak', 'sound', 'whistle']\n",
            "['wife', 'look', 'hope', 'idea', 'destroy', 'life', 'know']\n",
            "['smile', 'nod', 'stall', 'stall', 'stall']\n",
            "['change', 'mind']\n",
            "['right', 'try', 'mean', 'sex']\n",
            "['okay', 'homer', 'moment', 'truth', 'get_to', 'tell', 'marge', 'want', 'kid']\n",
            "['uh', 'oh', 'pick', 'name', 'put', 'thought', 'have', 'baby', 'stall', 'stall', 'stall']\n",
            "['fat', 'pathetic', 'slob', 'kid']\n",
            "['oh', 'right', 'dad', 'phew', 'sweet', 'maybe', 'thing', 'kid']\n",
            "['blow', 'surprise', 'pretend', 'forget']\n",
            "['uh', 'oh', 'honest', 'tell', 'train']\n",
            "['homer_simpson', 'want', 'cheat', 'friend', 'lie', 'wife', 'avoid', 'kid', 'jesus']\n",
            "['simulation', 'bring', 'brain', 'subsidiary', 'penis']\n",
            "['marge', 'think', 'flander', 'annoy', 'marriage', 'get', 'interesting']\n",
            "['wow', 'bart', 'feeling', 'mrs', 'doody']\n",
            "['cop', 'sight', 'go_to', 'save', 'clerk', 'go_to', 'law', 'hand']\n",
            "['lord', 'dire', 'emergency', 'fix', 'house', 'new', 'house', 'rib']\n",
            "['happy', 'period', 'lie', 'time', 'find']\n",
            "['mirror', 'mirror', 'wall', 'baldest']\n",
            "['gee', 'think', 'big', 'package']\n",
            "['worry', 'friend', 'physical']\n",
            "['uh', 'oh', 'go_to', 'work', 'marriage', 'alternatively']\n",
            "['wait_minute', 'guy', 'know', 'want']\n",
            "['oh', 'man', 'wait', 'book', 'marge', 'give']\n",
            "['book', 'go_to', 'daughter', 'sad', 'time', 'good', 'lie', 'child']\n",
            "['okay', 'eat', 'finish', 'okay', 'finish', 'ask']\n",
            "['play', 'cool', 'homer', 'let', 'know', 'perfect']\n",
            "['million_dollar', 'glad', 'die']\n",
            "['wait', 'tell', 'marge', 'win', 'know', 'buy', 'ticket', 'suppose', 'onstage', 'rich', 'tell', 'wife']\n",
            "['calm', 'homer', 'calm']\n",
            "['get', 'stay', 'mad', 'morning', 'fight', 'win', 'lose']\n",
            "['okay', 'imagine', 'bond', 'girl']\n",
            "['oh_god', 'flirt']\n",
            "['flirt', 'okay', 'homer', 'let', 'easy', 'break', 'heart']\n",
            "['oh_god', 'marge', 'think']\n",
            "['regret', 'mr', 'weathergirl', 'bad', 'financial', 'decision', 'time', 'oh', 'think', 'will', 'think', 'want', 'think']\n",
            "['eat', 'ear', 'eat', 'ear']\n",
            "['eat', 'boy', 'ear', 'dog', 'mouth', 'eat']\n",
            "['finally', 'time', 'big', 'bump']\n",
            "['okay', 'good', 'mood', 'therapy']\n",
            "['double', 'cross', 'gangster']\n",
            "['wonder', 'bird', 'moon', 'miss', 'marge']\n",
            "['whoa', 'get', 'want']\n",
            "['get', 'win', 'hand', 'rest', 'trick']\n",
            "['ooh', 'better', 'careful', 'purpose', 'game', 'friend', 'friend', 'win']\n",
            "['popular', 'gracious', 'winner']\n",
            "['ask', 'hair', 'head', 'stop', 'eighteen', 'inch', 'ago']\n",
            "['place', 'boring', 'somebody', 'interesting', 'go_to']\n",
            "['money', 'piss', 'away']\n",
            "['sure', 'beat', 'slave', 'hot', 'stove']\n",
            "['care', 'doggone', 'dugong', 'wish', 'feel', 'kind', 'passion', 'maybe', 'join', 'mission']\n",
            "['darn', 'long', 'bank', 'line', 'moment', 'thought', 'darn', 'long', 'bank', 'line']\n",
            "['hm', 'help', 'eat', 'cheating']\n",
            "['hm', 'kid', 'act', 'awfully', 'strange', 'maybe', 'sit', 'homer', 'go']\n",
            "['know', 'homer', 'thinking', 'think', 'want', 'baby', 'time', 'ironically', 'change', 'mind', 'want', 'way', 'want']\n",
            "['man', 'thing', 'sure', 'turn', 'crap']\n",
            "['beautiful', 'something', 'clever']\n",
            "['relax', 'wrong', 'explain', 'understand']\n",
            "['love', 'accept', 'need', 'mask', 'anymore']\n",
            "['sound_like', 'drug', 'kick', 'feel', 'urge', 'straighten', 'fly', 'right']\n",
            "['time', 'rid', 'competition']\n",
            "['oh', 'man', 'guy', 'pressure', 'marriage']\n",
            "['curve', 'hot', 'wheel', 'track', 'puberty']\n",
            "['get_to', 'stop', 'letter']\n",
            "['girl', 'like', 'candy', 'wow']\n",
            "['learn', 'be', 'bust', 'tomater']\n",
            "['look', 'come', 'crawlin', \"'\"]\n",
            "['uh', 'oh', 'laugh', 'dry', 'british', 'wit', 'subtle', 'self', 'pity', 'ooh', 'stare', 'better', 'respond']\n",
            "['scanning', 'sarcasm', 'clean']\n",
            "['dizzy', 'nauseous', 'oh', 'popular']\n",
            "['like', 'anybody', 'meet', 'like', 'riddle', 'wrap', 'enigma', 'wrap', 'vest', 'sure', 'ugly', 'stop', 'stare']\n",
            "['oh', 'think', 'get', 'crush', 'nelson', 'muntz']\n",
            "['kiss', 'wonder', 'like']\n",
            "['oh', 'know', 'hear', 'music']\n",
            "['kind', 'relaxing', 'hard', 'turn', 'brain', 'stop', 'think', 'start', 'hey', 'work', 'oh', 'think']\n",
            "['ohh', 'ball', 'yarn', 'funny', 'feel', 'like', 'bat']\n",
            "['oh', 'gosh', 'enter', 'body', 'cat']\n",
            "['beh', 'mag', 'gie', 'hey', 'hey', 'sticky', 'hand', 'owww']\n",
            "['oh', 'yuck', 'sandwich', 'meat', 'bacon', 'canadian', 'bacon', 'mexican', 'bacon']\n",
            "['mouth', 'water', 'veal', 'chop']\n",
            "['stupid', 'boring', 'ballet']\n",
            "['geez', 'lisa', 'mad', 'come', 'dump', 'happen', 'big', 'sandwich']\n",
            "['girl', 'brilliant', 'finally', 'find', 'kid', 'relate']\n",
            "['wow', 'actually', 'pass', 'college', 'student', 'blue', 'clue', 'whoop', 'get_to', 'age']\n",
            "['coffee', 'house', 'listen', 'poetry', 'cat', 'table', 'care', 'single', 'great', 'day', 'life']\n",
            "['oh_god', 'social', 'studies', 'project', 'tomorrow', 'morning']\n",
            "['oh_god', 'wrong', 'correct', 'learn', 'care', 'feeling']\n",
            "['okay', 'talk', 'way']\n",
            "['fight', 'mean', 'reject', 'girl']\n",
            "['look', 'right', 'lisa', 'time', 'jazz', 'legend', 'swing', 'suburb']\n",
            "['lie', 'heritage', 'speak', 'fork', 'tongue', 'heap', 'big', 'trouble', 'think', 'stereotype', 'bad']\n",
            "['question', 'learn', 'question']\n",
            "['lisa', 'room', 'test']\n",
            "['oh_god', 'challenge', 'lisa', 'let', 'respond']\n",
            "['girl', 'snotty', 'shallow', 'tell']\n",
            "['better', 'hope', 'yes']\n",
            "['possible', 'meet', 'teacher', 'like']\n",
            "['aw', 'sweet', 'ralph', 'dream', 'dream', 'ralphe', 'sure', 'totally', 'change', 'fix']\n",
            "['wow', 'mom', 'cry', 'unimaginable', 'power', 'use', 'want', 'right', 'want', 'mom', 'stop', 'cry']\n",
            "['b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', 'o']\n",
            "['like', 'movie', 'theater', 'pay', 'price', 'awesome']\n",
            "['hello', 'lisa', 'daddy', 'mean', 'um', 'kirk', 'van_houten', 'speak', 'father']\n",
            "['homer', 'bart', 'like', 'spend', 'night', 'house', 'permission']\n",
            "['want', 'bart', 'remarkable', 'boy', 'disapprove', 'fathering', 'fat', 'stomach']\n",
            "['want', 'big', 'allowance', 'new', 'bike']\n",
            "['year', 'lisa', 'prom', 'milhouse']\n",
            "['want', 'eat', 'gallon', 'ice_cream', 'minute']\n",
            "['go_to', 'like', 'adult']\n",
            "['love', 'buy', 'clothe', 'know', 'itchy']\n",
            "['money', 'wallet', 'velcroed', 'tight']\n",
            "['adult', 'buyin', \"'\"]\n",
            "['want', 'buy', 'beer', 'uh', 'cigarette', 'magazine', 'boob', 'pair', 'sunglass']\n",
            "['hey', 'bartender', 'like', 'milk', 'tell', 'baby', 'come']\n",
            "['milhouse', 'milhouse', 'mean', 'son']\n",
            "['guy', \"'\", 'dad']\n",
            "['um', 'adult', 'shake', 'hand']\n",
            "['young_man', 'apologize', 'sister']\n",
            "['kid', 'let', 'handle', 'uh', 'like', 'single', 'nickel']\n",
            "['oh', 'single', 'day', 'girl', 'buddy', 'field_trip']\n",
            "['yeah', 'thomas', 'tank', 'engine']\n",
            "['ooo', 'careful', 'homer']\n",
            "['sorry', 'excuse', 'pardon']\n",
            "['hey', 'norman', 'go', 'get', 'drag', 'heh_heh', 'ya', 'fred', 'excuse', 'fred']\n",
            "['wonderful', 'santas', 'land', 'present', 'entire', 'second', 'grade', 'class']\n",
            "['oh', 'lisa', 'class']\n",
            "['frohlich', 'weihnachten', 'german', 'merry_christmas', 'germany', 'santa', 'servant', 'ruprecht', 'give', 'present', 'good', 'child', 'whip', 'rod', 'parent', 'bad', 'one']\n",
            "['meri', 'kurimasu', 'hotseiosha', 'japanese', 'priest', 'act', 'like', 'santa', 'claus', 'eye', 'head', 'child', 'better', 'behave', 'nearby']\n",
            "['present', 'lisa_simpson', 'tawanga', 'santa', 'claus', 'south', 'seas']\n",
            "['fourth_grade', 'favor', 'melody', 'medley', 'holiday', 'flavorite']\n",
            "['dash', 'snow', 'horse', 'open', 'sleigh', \"o'er\", 'field', 'laugh', 'way', 'ha_ha', 'ha', 'bell', 'bob', 'tail', 'ring', 'make', 'spirit', 'bright', 'fun', 'ride', 'sing', 'sleighing', 'song', 'tonight']\n",
            "['bart', 'sweet', 'homer', 'sing', 'like', 'little', 'angel']\n",
            "['jingle', 'bells', 'batman', 'smell', 'robin', 'lay', 'egg', 'batmobile', 'break', 'wheel', 'joker', 'get', 'away']\n",
            "['fifth', 'grade', 'favor', 'scene', 'charles', 'dickens', \"'\", 'christmas', 'carol']\n",
            "['oh', 'yeah', 'hello', 'patty', 'hello', 'selma', 'trip']\n",
            "['dear', 'friend', 'simpson', 'family', 'sadness', 'gladness', 'year', 'sadness', 'little', 'cat', 'snowball', 'unexpectedly', 'run', 'go', 'kitty', 'heaven', 'buy', 'new', 'little', 'cat', 'snowball', 'ii', 'guess', 'life', 'go', 'speaking', 'life', 'go', 'grampa', 'feisty', 'maggie', 'walk', 'lisa', 'get', 'straight', 'bart', 'love', 'bart', 'magic', 'season', 'touch']\n",
            "['marge', 'finish', 'stupid', 'letter']\n",
            "['homer', 'send', 'love', 'happy', 'holiday']\n",
            "['marge', 'extension', 'cord']\n",
            "['oh', 'heavens', 'sake', 'homer', 'utility', 'drawer']\n",
            "['sorry', 'big', 'kid', 'love', 'christmas']\n",
            "['right', 'child', 'let', 'letter', 'send', 'santa', 'workshop', 'north', 'pole']\n",
            "['oh', 'fat', 'guy', 'bring', 'present', 'be', 'santa']\n",
            "['pony', 'oh', 'lisa', 'ask', 'year', 'tell', 'santa', 'fit', 'pony', 'sleigh', 'hint']\n",
            "['want', 'pony', 'good', 'year']\n",
            "['oh', 'dear', 'maybe', 'bart', 'little', 'realistic']\n",
            "['yeah', 'cool', 'rest_life']\n",
            "['get', 'tattoo', 'christmas']\n",
            "['yeah', 'want', 'pay', 'allowance']\n",
            "['hello', 'marge', 'patty_selma', 'excited', 'see', 'baby', 'sister', 'christmas', 'eve']\n",
            "['homer', 'look', 'forward', 'visit']\n",
            "['doubt', 'homer', 'excite', 'man', 'marry', 'know', 'pick', 'rude']\n",
            "['okay', 'kid', 'prepare', 'dazzle', 'marge', 'turn', 'juice']\n",
            "['nice', 'try', 'dad']\n",
            "['hold', 'horse', 'son', 'hey', 'hey', 'simpson']\n",
            "['think', 'look', 'okay']\n",
            "['ho_ho', 'ho_ho', 'ho_ho', 'ho_ho', 'ho_ho', 'ho_ho']\n",
            "['oh', 'neat', 'o']\n",
            "['bright', 'flander', 'big']\n",
            "['kid', 'want', 'christmas', 'shopping']\n",
            "['spill', 'marge', 'hide', 'christmas', 'money']\n",
            "['oh', 'secret', 'turn']\n",
            "['oh', 'big', 'jar', 'year']\n",
            "['oh', 'bart', 'sweet', 'good', 'present', 'mother', 'make', 'look', 'dangerous']\n",
            "['wait_minute', 'old']\n",
            "['mm', 'hmm', 'mmm_hmm', 'mmm_hmm']\n",
            "['mmm_hmm', 'mmm_hmm']\n",
            "['attention', 'personnel', 'work', 'follow', 'announcement']\n",
            "['boss', 'friend', 'mr_burns']\n",
            "['hello', 'proud', 'announce', 'able', 'increase', 'safety']\n",
            "['plant', 'increase', 'cost', 'consumer', 'affect', 'management', 'pay', 'raise', 'semi', 'skilled', 'worker', 'christmas', 'bonus']\n",
            "['thing', 'merry_christmas']\n",
            "['oh', 'thank_god', 'big', 'jar']\n",
            "['mom', 'think', 'like']\n",
            "['yes', 'mrs_simpson', 'remove', 'son', 'tattoo', 'simple', 'routine', 'involve', 'laser']\n",
            "['expensive', 'insist', 'cash', 'payment']\n",
            "['thank_god', 'homer', 'christmas', 'bonus']\n",
            "['boy', 'squirm', 'want', 'sucker', 'near', 'eye', 'groin']\n",
            "['ow', 'quit', 'real', 'boss', 'tattoo']\n",
            "['mom', 'spend', 'christmas', 'money', 'have', 'surgically', 'remove']\n",
            "['true', 'jar', 'oh_god', 'ruin', 'christmas', 'cancel', 'present']\n",
            "['worry', 'homer', 'stretch', 'christmas', 'bonus', 'year']\n",
            "['oh', 'yeah', 'christmas', 'bonus', 'silly', \"this'll\", 'good', 'christmas', 'good', 'family', 'heh_heh']\n",
            "['feeling', 'tell', 'homer']\n",
            "['oh', 'love', 'marge']\n",
            "['homer', 'tell', 'time']\n",
            "['oh', 'good', 'love', 'deserve', 'guy', 'fat', 'wallet', 'credit_card', 'will', 'set', 'horrible', 'beeping']\n",
            "['think', 'christmas', 'bonus', 'ask']\n",
            "['marge', 'let', 'honest']\n",
            "['want', 'christmas', 'shopping', 'year']\n",
            "['marge', 'marge', 'marge', 'let', 'oooh', 'look', 'pantyhose', 'practical', 'allure', 'pack', 'oh', 'ninety']\n",
            "['oooh', 'pad', 'paper', 'bet', 'bart', 'think', 'million', 'thing', 'leave', 'little', 'maggie', 'oh', 'look', 'little', 'squeak', 'toy', 'say', 'dog', 'read']\n",
            "['ow', 'oh', 'simpson']\n",
            "['oh', 'little', 'mess', 'get', 'one', 'one']\n",
            "['hey', 'mr_simpson', 'drop', 'pork_chop']\n",
            "['happy', 'holidays', 'simpson']\n",
            "['gee', 'dad', 'go_to', 'good', 'christmas']\n",
            "['oh', 'dad', 'finally', 'home']\n",
            "['matter', 'homer', 'somebody', 'leave', 'lumpa', 'coal', 'stocking', 'sit', 'suck', 'beer', 'day', 'long']\n",
            "['crazy', 'getup', 'barn']\n",
            "['get', 'time', 'job', 'work', 'santa', 'mall']\n",
            "['know', 'pretty', 'selective']\n",
            "['mean', 'time', 'nuts']\n",
            "['welcome', 'aboard', 'simpson', 'pende', 'successful', 'completion', 'training', 'program']\n",
            "['dime', 'till', 'christmas', 'eve']\n",
            "['nixon', 'comet', 'cupid', 'donna', 'dixon']\n",
            "['like', 'little', 'boy']\n",
            "['homer', 'emergency', 'arise', 'tell', 'santa', 'busy', 'time', 'year', 'helper']\n",
            "['homer', 'seven', 'hour', 'late']\n",
            "['word', 'marge', 'head', 'straight', 'tub']\n",
            "['homer', 'sister', 'want', 'hello']\n",
            "['yeah', 'merry_christmas']\n",
            "['oh', 'christmas', 'know']\n",
            "['hey', 'hey', 'come']\n",
            "['think', 'kid', 'beauty']\n",
            "['want', 'robotoid', 'want', 'goop', 'monster', 'want', 'great', 'big', 'giant']\n",
            "['ah', 'son', 'need', 'junk', 'sure', 'get', 'important', 'decent', 'home', 'love', 'father', 'hey', 'afford', 'lunch', 'gimme', 'bite', 'donut']\n",
            "['load', 'quote', 'unquote', 'santa']\n",
            "['believe', 'kid', 'fallin', \"'\"]\n",
            "['hey', 'milhouse', 'dare', 'sit', 'lap']\n",
            "['oh', 'yeah', 'dare', 'yank', 'beard']\n",
            "['hope', 'feel', 'well', 'santa']\n",
            "['mrs', 'claus', 'sister', 'town', 'thank', 'listen', 'kid']\n",
            "['hey', 'santa', 'shake']\n",
            "['bart', 'ner', 'er', 'little', 'partner']\n",
            "['jolly', 'old', 'saint', 'nick']\n",
            "['want', 'word', 'santa', 'workshop', 'little', 'boy', 'cover', 'elfie']\n",
            "['kill', 'dad', 'know']\n",
            "['know', 'secret', 'bonus', 'year', 'family', 'miss', 'christmas']\n",
            "['dad', 'love', 'sink', 'low']\n",
            "['let', 'mushy', 'son', 'job']\n",
            "['hey', 'little', 'one', 'santa', 'ho_ho']\n",
            "['ah', 'son', 'day', 'go_to', 'know', 'satisfaction', 'payday', 'receive', 'big', 'fat', 'check', 'job']\n",
            "['right', 'dollar', 'gross', 'social', 'security']\n",
            "['beard', 'rental', 'christmas', 'club']\n",
            "['come', 'dad', 'let', 'home']\n",
            "['thirteen', 'buck', 'thirteen', 'buck']\n",
            "['right', 'thirteen', 'big', 'one', 'springfield', 'down', 'come']\n",
            "['hear', 'go', 'dog', 'track', 'get', 'hot', 'little', 'puppy', 'fourth', 'race', 'wanna', 'come']\n",
            "['bart', 'hear', 'santa_little', 'helper', 'sign', 'oman']\n",
            "['sorry', 'barney', 'total', 'washout', 'father', 'go_to', 'kid', 'sleazy', 'dog', 'track', 'christmas', 'eve']\n",
            "['come', 'simpson', 'dog', 'whirlwind', 'shot', 'money', 'bank']\n",
            "['ah', 'come', 'dad', 'miracle', 'save', 'simpson', \"'\", 'christmas', 'tv', 'teach', 'miracle', 'happen', 'poor', 'kid', 'christmas', 'happen', 'tiny', 'tim', 'happen', 'charlie', 'brown', 'happen', 'smurf', 'go_to', 'happen']\n",
            "['hey', 'moldy', 'think', 'santa', 'able', 'find', 'elf', 'county', 'snow']\n",
            "['doubt', 'bubble', 'sad', 'little', 'elf', 'christmas']\n",
            "['say', 'go', 'carol', 'bart']\n",
            "['money', 'money', 'get', 'lot', 'take']\n",
            "['open', 'present', 'dad']\n",
            "['know', 'tradition', 'son', 'till', 'eighth', 'race']\n",
            "['hey', 'barney', 'whirlwind']\n",
            "['number', 'lucky', 'dog', 'right', 'win', 'race']\n",
            "['scrawny', 'little', 'bag', 'bone']\n",
            "['come', 'dad', 'scrawny', 'little', 'bag', 'bone']\n",
            "['yeah', 'right', 'guess', 'whirlwind', 'hope', 'merry_christmas']\n",
            "['attention', 'racing', 'fan', 'late', 'scratch', 'fourth', 'race', 'number', 'sir', 'galahad', 'replace', 'santa_little', 'helper', 'sir', 'galahad', 'replace', 'santa_little', 'helper']\n",
            "['odd', 'santa_little', 'helper']\n",
            "['whoa', 'ninety', 'time', 'thirteen', 'equal', 'mer', 'ry', 'christmas']\n",
            "['come', 'boy', 'faith', 'keep', 'go']\n",
            "['boy', 'santa_little', 'helper']\n",
            "['typical', 'big', 'doofu', 'spoil']\n",
            "['oh', 'dear', 'trash', 'father']\n",
            "['wish', 'aside', 'fact', 'frailty', 'human', 'being', 'father', 'model', 'manhood', 'estimation', 'govern', 'prospect', 'adult', 'relationship', 'hope', 'bear', 'mind', 'knock', 'knock', 'far', 'young', 'defend', 'onslaught']\n",
            "['um', 'hm', 'watch', 'cartoon', 'dear']\n",
            "['come', 'bart', 'kiss', 'ticket', 'good_luck', 'need', 'heh_heh', 'heh']\n",
            "['come', 'screwy', 'mechanical', 'rabbit']\n",
            "['come', 'dog', 'man', 'come', 'santa_little', 'helper', 'run', 'baby', 'run']\n",
            "['come', 'santa_little', 'helper', 'run', 'tail']\n",
            "['come', 'left', 'quadrupe', 'follow', 'dog', 'o', \"'\", 'war', 'fido']\n",
            "['dog', 'war', 'come', 'fast', 'outside', 'lock', 'place', 'santa_little', 'helper']\n",
            "['worry', 'dad', 'maybe', 'suspense', 'miracle', 'happen']\n",
            "['clubhouse', 'turn', 'whirlwind', 'stake', 'big', 'lead', 'couple', 'length', 'quadrupe', 'fight', 'come', 'fast', 'chew', 'shoe']\n",
            "['whirlwind', 'country', 'mile', 'second', 'chew', 'shoe', 'follow', 'dog', 'o', \"'\", 'war']\n",
            "['possible', 'guess', 'tv', 'betray']\n",
            "['want', 'leave', 'till', 'dog', 'finish']\n",
            "['ah', 'forget', 'let']\n",
            "['find', 'winner', 'son']\n",
            "['beat', 'scram', 'lose', 'come', 'time']\n",
            "['look', 'dad', 'santa_little', 'helper']\n",
            "['oh', 'away', 'uh', 'uh']\n",
            "['yeah', 'come', 'stagger', 'home']\n",
            "['um', 'hm', 'smell', 'cheap', 'perfume']\n",
            "['right', 'look', 'everybody', 'confession']\n",
            "['christmas', 'bonus', 'try', 'let', 'ruin', 'christmas', 'everybody', 'matter']\n",
            "['hey', 'everybody', 'look', 'get']\n",
            "['dog', 'right', 'dad']\n",
            "['love', 'sight', 'possible']\n",
            "['run_away', 'easy', 'catch']\n",
            "['good', 'gift', 'homer']\n",
            "['yes', 'share', 'love']\n",
            "['number', 'mean', 'santa_little', 'helper']\n",
            "['rudolph', 'red', 'nosed', 'reindeer', 'shiny', 'nose', 'see', 'glow']\n",
            "['like', 'light', 'bulb']\n",
            "['reindeer', 'laugh', 'name']\n",
            "['like', 'shine', 'ola']\n",
            "['let', 'poor', 'rudolph', 'join', 'reindeer', 'game']\n",
            "['like', 'strip', 'poker']\n",
            "['foggy', 'christmas', 'eve', 'santa', 'come']\n",
            "['rudolph', 'nose', 'guide', 'sleigh', 'today']\n",
            "['reindeer', 'love', 'shout', 'glee', 'rudolph', 'red', 'nosed', 'reindeer', 'history']\n",
            "['like', 'attila', 'hun']\n",
            "['yeah', 'mom', 'hurry']\n",
            "['point', 'turn', 'dear']\n",
            "['hmmmm', 'word', 'lousy', 'letter']\n",
            "['oh', 'wait', 'good']\n",
            "['would', 'triple', 'word', 'score']\n",
            "['d', 'dad', 'would', 'word']\n",
            "['game', 'stup', 'would']\n",
            "['hey', 'shut', 'boy']\n",
            "['yeah', 'bart', 'suppose', 'develop', 'verbal', 'ability', 'big', 'aptitude', 'test', 'tomorrow']\n",
            "['look', 'would', 'thing', 'dictionary']\n",
            "['think', 'short', 'leg', 'couch']\n",
            "['would', 'ego', 'superego', 'component', 'psyche']\n",
            "['turn', 'kwyjibo', 'k', 'w', 'y', 'j', 'b', 'o']\n",
            "['point', 'plus', 'triple', 'word', 'score', 'plus', 'point', 'letter', 'game', 'outta']\n",
            "['wait_minute', 'little', 'cheater', 'go', 'tell', 'kwyjibo']\n",
            "['kwyjibo', 'uh', 'big', 'dumb', 'balding']\n",
            "['north', 'american', 'ape', 'chin']\n",
            "['big', 'dumb', 'balding', 'ape']\n",
            "['uh', 'oh', 'kwyjibo', 'loose']\n",
            "['chew', 'gum', 'school', 'ground', 'trash']\n",
            "['principal_skinner', 'fellow', 'child', 'vandalize', 'school', 'property']\n",
            "['look', 'bart', 'come', 'skinner']\n",
            "['umm', 'deep', 'trouble']\n",
            "['sloppy', 'speller', 'preferred', 'spelling', 'wiener', 'w', 'e', 'n', 'e', 'r', 'e', 'acceptable', 'ethnic', 'variant']\n",
            "['good', 'boy', 'boy', 'let', 'hand']\n",
            "['mmm_hmm', 'good', 'okay', 'simpson']\n",
            "['catch', 'red', 'handed']\n",
            "['simpson', 'go', 'little', 'talk']\n",
            "['yes', 'office', 'school']\n",
            "['bart', 'hope', 'will', 'bear', 'sort', 'simple', 'minded', 'grudge', 'merely', 'try', 'fend', 'desecration', 'school', 'building']\n",
            "['want', 'worry', 'class', 'test', 'effect', 'grade', 'merely', 'determine', 'future', 'social', 'status', 'financial', 'success']\n",
            "['mrs_krabappel', 'bart', 'suppose', 'face', 'window', 'will', 'tempt', 'look', 'neighbor', 'paper']\n",
            "['right', 'martin', 'bart']\n",
            "['remember', 'visualize', 'complex', 'problem', 'relax', 'test', 'start']\n",
            "['seven', 'thirty', 'm', 'express', 'train', 'travel', 'mile', 'hour', 'leave', 'santa', 'fe', 'bind', 'phoenix', 'mile', 'away']\n",
            "['shhhhh', 'visualize', 'bart']\n",
            "['time', 'local', 'train', 'travel', 'thirty', 'mile', 'hour', 'carry', 'passenger', 'leave', 'phoenix', 'bind', 'santa', 'fe']\n",
            "['car', 'long', 'carry', 'number', 'passenger', 'car']\n",
            "['hour', 'later', 'number', 'passenger', 'equal', 'half', 'number', 'minute', 'past', 'hour', 'time', 'plus']\n",
            "['second', 'stop', 'half', 'passenger', 'plus', 'twice', 'get', 'stop']\n",
            "['get', 'stowaway', 'sir']\n",
            "['twice', 'fare', 'tucson', 'flagstaff', 'minus', 'third', 'fare', 'albuquerque', 'el', 'paso']\n",
            "['bart', 'student', 'class', 'chance', 'stop', 'bother']\n",
            "['bother', 'mrs_krabappel', 'finish', 'outside', 'read', 'tree']\n",
            "['look', 'bart', 'naughty', 'dog']\n",
            "['good', 'boy', 'get', 'well', 'good', 'sheep', 'stray', 'flock', 'need', 'hug', 'extra', 'hard']\n",
            "['exactly', 'kind', 'crapola', 'louse', 'hey', 'look', 'weiner', 'sure']\n",
            "['mr', 'mrs_simpson']\n",
            "['catch', 'son', 'deface', 'school', 'property', 'morning', 'estimate', 'damage', 'seventy', 'dollar', 'frankly', 'think', 'terribly', 'unfair', 'taxpayer', 'foot', 'bill']\n",
            "['yeah', 'crummy', 'system', 'go_to']\n",
            "['wife', 'think', 'want', 'pay']\n",
            "['like', 'extreme', 'penalty', 'isolate', 'incident', 'bart', 'behavior', 'unruly', 'frequently', 'absent', 'school', 'give', 'teacher', 'pathetic', 'excuse', 'note', 'obviously', 'childish', 'forgery', 'compare']\n",
            "['rate', 'reluctant', 'decision']\n",
            "['mr', 'skinner', 'doctor', 'pryor', 'say', 'urgent']\n",
            "['mr', 'mrs_simpson', 'district', 'psychiatrist', 'dr', 'j', 'loren', 'pryor']\n",
            "['need', 'psychiatrist', 'know', 'kid', 'nuts']\n",
            "['oh', 'contrary', 'exciting', 'news', 'aptitude', 'test', 'administer', 'morning', 'reveal', 'young', 'bart', 'gifted', 'child']\n",
            "['son', 'genius', 'mr_simpson']\n",
            "['certain', 'child', 'suppose', 'know', 'q', 'course', 'uh', 'range', 'doubt']\n",
            "['uh', 'upside', 'sixteen']\n",
            "['tell', 'bart', 'bore', 'school']\n",
            "['um', 'hmmm', 'feel', 'little', 'frustrated']\n",
            "['uh_huh', 'dream', 'leave', 'class', 'pursue', 'intellectual', 'development', 'independent', 'basis']\n",
            "['wow', 'like', 'readin', \"'\", 'mind', 'man']\n",
            "['ha', 'child', 'bart', 'intellect', 'force', 'slow', 'pace', 'normal', 'person', 'probably', 'go', 'lash', 'way', 'like']\n",
            "['bart', 'like', 'try', 'kind', 'school', 'rely', 'grade', 'rule', 'bell', 'buzzer', 'school', 'wall', 'little', 'assignment', 'feel', 'need', 'sound', 'good', 'bart']\n",
            "['come', 'bart', 'mother', 'try', 'help', 'ahead', 'enjoy']\n",
            "['excellent', 'set', 'information', 'need', 'ish', 'mr', 'mrs_simpson', 'congratulation']\n",
            "['think', 'mood', 'celebrate']\n",
            "['doc', 'mean', 'son', 'genius', 'happen']\n",
            "['genius', 'level', 'intelligence', 'usually', 'result', 'heredity', 'environment']\n",
            "['uh', 'case', 'total', 'mystery']\n",
            "['look', 'intelligent', 'dear']\n",
            "['about', 'tie', 'son', 'everybody', 'know', 'boy', 'genius', 'wear', 'tie']\n",
            "['stifle', 'creativity', 'dad']\n",
            "['bart', 'big', 'day', 'eat', 'little', 'nutritious']\n",
            "['nonsense', 'marge', 'frosty', 'krusty', 'flake', 'get', 'today']\n",
            "['chemical', 'make', 'smart', 'lisa', 'maybe', 'try']\n",
            "['say', 'genius', 'family', 'sort', 'spare', 'case', 'bart', 'brain', 'blow']\n",
            "['care', 'stupid', 'test', 'say', 'bart', 'dimwit']\n",
            "['maybe', 'dimwit', 'easy', 'street']\n",
            "['rush', 'dad', 'scenic', 'route']\n",
            "['worry', 'son', 'let', 'tie']\n",
            "['hook', 'go', 'thing']\n",
            "['nurture', 'brilliant', 'brain', 'get', 'ticket', 'opera', 'tonight', 'hurry', 'dress', 'start']\n",
            "['wrong', 'father', 'kiss', 'son', 'think', 'boy', 'pay_attention', 'day', 'achieve', 'simpson', 'dream', 'generation', 'outsmart']\n",
            "['bart_simpson', 'ms', 'melon', 'learning', 'coordinator']\n",
            "['let', 'right', 'start', 'rule', 'rule', 'feel', 'sleepy', 'nap', 'bore', 'feel', 'free', 'book', 'start', 'read']\n",
            "['comic_book', 'mix', 'week', 'prop', 'film', 'illiteracy']\n",
            "['bart', 'student', 'share', 'work', 'area', 'ethan', 'foley']\n",
            "['o', 'memsahib', 'bart', 'rabbi', 'memo']\n",
            "['ethan', 'good', 'palindrome', 'know', 'sentence', 'spell', 'backward', 'forwards', 'sidney', 'swift']\n",
            "['trab', 'ing', 'norm', 'doog']\n",
            "['oh', 'mind', 'sidney', 'speak', 'backwards', 'phonetic', 'today', 'say', 'good_morning', 'bart', 'cecile', 'shapiro']\n",
            "['cool', 'hamster', 'name']\n",
            "['hamster', 'number', 'infect', 'staphylococci', 'virus', 'hamster', 'number', 'control', 'hamster']\n",
            "['hi', \"li'l\", 'control', 'hamster']\n",
            "['attach', 'bart', 'dissect', 'week']\n",
            "['discover', 'desk', 'people']\n",
            "['let', 'welcome', 'new', 'member', 'collective', 'experience', 'bart_simpson']\n",
            "['continue', 'debate', 'yesterday', 'leave', 'calvin', 'tanya', 'argue', 'free', 'illusion']\n",
            "['oh', 'mom', 'tonight']\n",
            "['ask', 'humankind', 'freedom', 'freedom', 'fraught', 'paradox', 'freud', 'show', 'childhood', 'shape', 'subconscious', 'mind', 'help', 'think']\n",
            "['good', 'ian', 'example', 'paradox']\n",
            "['law', 'order', 'man', 'freedom']\n",
            "['want', 'peace', 'prepare', 'war']\n",
            "['um', 'hmm', 'um', 'hmm', 'smart', 'child', 'class', 'quiet', 'bart', 'paradox', 'affect', 'life']\n",
            "['guess', 'paradox', 'thank', 'bart']\n",
            "['tell', 'bart', 'trade', 'weight', 'bowling', 'ball', 'eighth', 'moon', 'jupiter', 'lunch', 'weight', 'feather', 'second', 'moon', 'neptune', 'lunch']\n",
            "['trade', 'thousand', 'picoliter', 'milk', 'gill']\n",
            "['uh', 'bart', 'wager', 'cupcake']\n",
            "['think', 'new', 'kid']\n",
            "['wow', 'readin', \"'\", 'comic_book', 'uh', 'guess', 'want', 'overheat', 'old', 'noggin', 'eh']\n",
            "['tell', 'celebrate', 'day', 'genius', 'school', 'whaddaya', 'round', 'frosty', 'chocolate', 'milkshake']\n",
            "['bart', 'feel', 'bad', 'go', 'year', 'uh', 'hmmm', 'word', 'encourage', 'grow']\n",
            "['hey', 'lee', 'eye', 'guy', 'peanut']\n",
            "['guy', 'peanut', 'dear']\n",
            "['jeez', 'beer', 'opera', 'dog']\n",
            "['toreador', 'oh', 'spit', 'floor', 'use', 'cuspidor']\n",
            "['bart', 'stop', 'fool', 'homer', 'stop', 'encourage']\n",
            "['stifle', 'boy', 'marge', 'suppose', 'encourage']\n",
            "['way', 'bull', 'go_to', 'miss', 'target', 'big', 'man']\n",
            "['be', 'till', 'fat', 'lady', 'sing']\n",
            "['y', 'equal', 'r', 'cube', 'determine', 'rate', 'change', 'curve', 'correctly', 'think', 'pleasantly', 'surprise']\n",
            "['bart', 'derivative', 'd', 'y', 'equal', 'r', 'square', 'd', 'r', 'r', 'square', 'd', 'r', 'r', 'd', 'r', 'r', 'hardy', 'har', 'har']\n",
            "['hey', 'guy', 'great', 'ya']\n",
            "['yeah', 'beat', 'professor']\n",
            "['build', 'rocket', 'ship', 'brainiac']\n",
            "['come', 'forget', 'film', 'festival']\n",
            "['sorry', 'bart', 'mother', 'buy', 'ticket', 'snooty', 'movie', 'direct', 'swedish', 'meatball']\n",
            "['um', 'look', 'dad', 'get', 'tell']\n",
            "['wait', 'son', 'get', 'kinda', 'dark']\n",
            "['right', 'homer', 'come', 'baby', 'right', 'plate', 'lemme', 'feel', 'wind']\n",
            "['worry', 'homeboy', 'fast']\n",
            "['oh', 'think', 'eh', 'come', 'real', 'heat']\n",
            "['whoa', 'yeah', 'strike', 'outta']\n",
            "['want', 'tell', 'son']\n",
            "['uh', 'nothing', 'pop']\n",
            "['try', 'lab', 'partner', 'bart', 'volunteer', 'soon', 'assign', 'somebody', 'look', 'dangerous']\n",
            "['pretty', 'secret', 'madam']\n",
            "['right', 'go', 'know', 'happen', 'mix', 'acid', 'basis', 'right']\n",
            "['bart', 'want', 'emphasize', 'angry', 'concerned', 'young_man', 'sixteen', 'q', 'simple', 'experiment', 'work', 'bart_simpson', 'figure', 'wrong', 'tell', 'class', 'move', 'slowly']\n",
            "['want', 'old', 'class']\n",
            "['oh', 'bart', 'remember', 'boredom', 'ennui', 'intellectual', 'malaise']\n",
            "['yeah', 'know', 'kinda', 'think', 'undercover']\n",
            "['undercover', 'bart', 'intrigue']\n",
            "['pretend', 'regular', 'dumb', 'kid', 'know', 'study', 'stuff', 'know', 'make', 'tick']\n",
            "['like', 'jane', 'goodall', 'chimp']\n",
            "['uh_huh', 'impressive', 'bart', 'write', 'proposal', 'talk', 'principal_skinner']\n",
            "['know', 'outline', 'project', 'hope', 'achieve', 'require']\n",
            "['confession', 'bart_simpson', 'regular', 'dumb', 'kid', 'period', 'cheat', 'intelligence', 'test', 'period']\n",
            "['uh', 'finish', 'principal_skinner', 'interested']\n",
            "['oh', 'know', 'misspell', 'confession']\n",
            "['hey', \"lookin_'\", 'good', 'bart']\n",
            "['little', 'accident', 'chemistry', 'today']\n",
            "['bet', 'little', 'turpentine', 'will', 'come', 'son']\n",
            "['discourage', 'son', 'bet', 'einstein', 'turn', 'sort', 'color', 'invent', 'light', 'bulb']\n",
            "['dad', 'get_to', 'tell', 'hope', 'will', 'mad']\n",
            "['cheat', 'intelligence', 'test', 'sorry', 'want', 'past', 'week', 'great', 'stuff', 'help', 'thing', 'close', 'love', 'dad', 'think', 'bring', 'close', 'possibly', 'bad']\n",
            "['think', 'bart', 'stupid', 'mom']\n",
            "['march', 'butt', 'right']\n",
            "['son', 'come', 'hug', 'kiss', 'feel', 'well']\n",
            "['think', 'dumb', 'fall', 'insult']\n",
            "['class', 'want', 'field_trip', 'repeat', 'infamous', 'visit', 'springfield', 'state', 'prison', 'want', 'good', 'behavior', 'especially', 'bart_simpson']\n",
            "['mrs_krabappel', 'unlock', 'door']\n",
            "['sorry', 'little', 'dudes', 'party', 'hardy', 'equal', 'tardy']\n",
            "['right', 'child', 'count']\n",
            "['hey', 'otto', 'hey', 'ottoman']\n",
            "['new', 'tattoos', 'otto']\n",
            "['oh', 'funny', 'ask', 'man', 'morning', 'wake']\n",
            "['uh', 'till', 'fourteen', 'little', 'friend']\n",
            "['oh', 'mrs_krabappel', 'wendell', 'puke', 'bus', 'ride']\n",
            "['try', 'shake', 'seat', 'like']\n",
            "['class', 'remember', 'stick', 'body', 'window', 'know', 'tragic', 'story', 'young_man', 'stick', 'arm', 'window', 'rip', 'big', 'truck', 'come', 'direction']\n",
            "['bart_simpson', 'sit', 'tomfoolery']\n",
            "['otto', 'sure', 'uh']\n",
            "['shortcut', 'mrs', 'k', 'trust']\n",
            "['mrs_krabappel', 'mrs_krabappel']\n",
            "['bart', 'word', 'subject', 'humiliation', 'make', 'sing', 'class']\n",
            "['song', 'john', 'henry', 'steel', 'drivin', \"'\", 'man']\n",
            "['go_to', 'sing', 'bart_simpson']\n",
            "['yeah', 'bart_simpson', 'go_to', 'sing']\n",
            "['bart', 'oh', 'like', 'uh', 'uh', 'uh']\n",
            "['yes', 'sherri', 'terri', 'know', 'behave']\n",
            "['take', 'bart_simpson', 'graveyard', 'bury', 'sand', 'oh', 'yeah', 'locomotive', 'come', 'roarin', \"'\", 'say', \"'\", 'lie', 'steel', 'drivin', \"'\", 'man', 'lord', 'lord', 'oh', 'lie']\n",
            "['hey', 'wendell', 'buddy']\n",
            "['plant', 'harness', 'power', 'atom', 'energy', 'run', 'favorite', 'video', 'game', 'yummy', 'cotton', 'candy', 'machine', 'let', 'learn', 'nuclear', 'energy', 'shall', 'light']\n",
            "['people', 'think', 'nuclear', 'energy', 'think']\n",
            "['talk', 'nuclear', 'energy', 'mean']\n",
            "['exactly', 'nuclear', 'energy', 'know', 'know', 'smilin', \"'\", 'joe', 'fission']\n",
            "['hi', 'energy', 'eater', 'smilin', \"'\", 'joe', 'fission', 'atomic', 'tour', 'guide', 'strange', 'exciting', 'world', 'nuclear_power']\n",
            "['rod', 'uranium', 'thirty', 'hi', 'rod', 'hey', 'rod', 'do', 'rod']\n",
            "['hey', 'guy', 'look', 'hot']\n",
            "['uh', 'oh', 'about', 'dip', 'pool']\n",
            "['rod', 'water', 'hot', 'boil']\n",
            "['ooch', 'ooch', 'ouch', 'ooh', 'hot', 'oh', 'pain']\n",
            "['steam', 'spin', 'turbine', 'generate', 'energy']\n",
            "['uh', 'oh', 'whoop', 'look', 'like', 'little', 'leftover', 'nuclear', 'waste', 'problem', \"nobody'll\", 'find', 'million', 'year']\n",
            "['know', 'true', 'story', 'nuclear', 'energy', 'longer', 'misunderstood', 'friend', 'smilin', \"'\"]\n",
            "['uh', 'thermal', 'regulator', 'right', 'look', 'window', 'water', 'rejoin', 'rest', 'nature', 'biosphere']\n",
            "['hey', 'bart', 'dad', 'say', 'dad', 'incompetent']\n",
            "['mean', 'spend', 'time', 'yak', 'scarf', 'donut', 'job']\n",
            "['oh', 'okay', 'think', 'puttin', \"'\"]\n",
            "['know', 'defy', 'tell', 'difference', 'donut', 'one', 'bake', 'today', 'hey', 'boy', \"s'posed\", 'second', 'field_trip']\n",
            "['come', 'simpson', 'want', 'kid', 'sit', 'butt', 'stuff', 'face', 'tour', 'house']\n",
            "['right', 'get_to', 'action']\n",
            "['hey', 'dad', 'hey', 'dad', 'yo', 'homer']\n",
            "['oh', 'hi', 'boy']\n",
            "['want', 'hear', 'simpson', 'fire', 'oh', 'hi', 'girl']\n",
            "['good', 'job', 'fireworks', 'factory']\n",
            "['about', 'supervise', 'technician', 'toxic', 'waste', 'dump']\n",
            "['supervise', 'technician', 'technical', 'supervisor', 'worthwhile', 'life', 'big', 'worthless']\n",
            "['homer', 'find', 'job', 'cause', 'plenty', 'industrial', 'accident', 'bounce']\n",
            "['right', 'young', 'able', 'bodied', 'watch', 'springfield', 'come']\n",
            "['technical', 'supervisor', 'care']\n",
            "['freely', 'initial', 'p']\n",
            "['hold', 'check', 'ah', 'p', 'freely', 'hey', 'everybody', 'p', 'freely']\n",
            "['wait_minute', 'listen', 'lousy', 'bum', 'hold', 'dead', 'swear', 'go_to', 'slice', 'heart', 'half']\n",
            "['punk', 'someday', 'moe']\n",
            "['ahh', 'know', 'tough', 'catch', 'keep', 'change']\n",
            "['moe', 'think', 'whoops', 'moe', 'little', 'low', 'fund', 'think', 'cover']\n",
            "['think', 'year', 'deserve', 'explanation']\n",
            "['think', 'go', 'job', 'able', 'pay']\n",
            "['think', 'know', 'homer', 'good', 'provider', 'get', 'marry', 'mr', 'berger', 'promise', 'come', 'old', 'job', 'anytime', 'want']\n",
            "['think', 'kind', 'work']\n",
            "['sure', 'forget', 'like', 'ride', 'bicycle']\n",
            "['hey', 'mama', 'fry']\n",
            "['dad', 'eat', 'get', 'mustard']\n",
            "['lie', 'like', 'unemployed', 'whale']\n",
            "['thing', 'advantage', 'old', 'guy', 'get_to', 'sign', 'report', 'card', 'dad']\n",
            "['loaftime', 'cable', 'network', 'unemployed', 'tip', 'win', 'lottery', 'right']\n",
            "['unemployed', 'work', 'sober', 'sit', 'house', 'day', 'duff', 'time', 'duff', 'beer', 'make', 'day', 'fly']\n",
            "['wonderful', 'duff', 'duff', 'beer']\n",
            "['beer', 'temporary', 'solution']\n",
            "['beer', 'ah', 'maybe']\n",
            "['oh', 'smash', 'open', 'little', 'boy', 'piggy', 'bank', 'measly', 'cent', 'buy', 'beer', 'wait_minute', 'lemme', 'count', 'sure']\n",
            "['dear', 'family', 'utter', 'failure', 'well', 'time', 'read', 'watery', 'grave', 'leave', 'word', 'father', 'give', \"'\", 'stand', 'tall', 'courage', \"'\", 'hope', 'provide', 'well', 'model', 'death', 'life', 'warm', 'regard', 'love', 'homer', 'j', 'simpson']\n",
            "['oh', 'look', 'like', 'young', 'simpson', 'go', 'kill']\n",
            "['maybe', 'maybe', 'take', 'boulder', 'walk']\n",
            "['mom', 'mom', 'wake']\n",
            "['swipe', 'piggy', 'bank']\n",
            "['hey', 'idiot', 'watch', 'go']\n",
            "['boy', 'intersection', 'dangerous', 'ought', 'stop', 'sign']\n",
            "['oh', 'homer', 'think', 'kill', 'love']\n",
            "['yeah', 'dad', 'yeah', 'love']\n",
            "['kill', 'kill', 'thing', 'purpose', 'reason', 'live', 'care', 'face', 'care', 'fight', 'rest', 'street', 'get', 'stop', 'sign']\n",
            "['ah', 'agenda', 'police', 'chief_wiggum', 'update', 'graffiti', 'problem']\n",
            "['secret', 'city', 'siege', 'graffiti', 'vandal', 'know', 'el', 'barto', 'police', 'artist', 'composite', 'sketch', 'culprit', 'information', 'contact', 'immediately']\n",
            "['want', 'run', 'dark', 'alley']\n",
            "['new', 'business', 'homer_simpson', 'local', 'resident', 'mr_simpson']\n",
            "['nervous', 'believe', 'homer']\n",
            "['lady_gentleman', 'esteem', 'councilman', 'boy', 'girl', 'retire', 'people', 'well', 'danger', 'come', 'form', 'dinosaur', 'torment', 'cavemen', 'ancestor']\n",
            "['think', 'stop', 'sign', 'd', 'street', 'twelfth']\n",
            "['approve', 'meeting', 'adjourn', 'coffee', 'maple', 'log', 'lobby']\n",
            "['hey', 'think', 'go_to', 'stop', 'stop', 'sign', 'sadly', 'mistake']\n",
            "['oh', 'homer', 'proud']\n",
            "['dip', 'sign', 'instance', 'people', 'will', 'catch', 'guard', 'little', 'road']\n",
            "['ah', 'great', 'family', 'come', 'know', 'small', 'potato', 'danger', 'town', 'big', 'dip']\n",
            "['mean', 'go', 'old', 'boss']\n",
            "['gee', 'dad', 'hero']\n",
            "['okay', 'assume', 'say', 'think', 'hear']\n",
            "['bring', 'speed', 'bump']\n",
            "['mile', 'hour', 'speed', 'limit', 'main', 'street']\n",
            "['man', 'synonymous', 'safety', 'homer_simpson']\n",
            "['unlike', 'nut', 'good', 'honest', 'american', 'oppose', 'wrongdoing', 'especially', 'carelessness', 'occur']\n",
            "['look', 'man', 'crowd', 'palm', 'hand', 'see', 'like', 'jolson']\n",
            "['homer_simpson', 'sir', 'work', 'plant', 'fire', 'gross', 'incompetence']\n",
            "['oh', 'little', 'game', 'simpson', 'character', 'right']\n",
            "['life', 'hand', 'man', 'smarter', 'incompetent', 'boob', 'know', 'work', 'go', 'bowl', 'watch', 'pass', 'promotion', 'time', 'stink']\n",
            "['hey', 'hey', 'simpson']\n",
            "['burns', 'want', 'talk', 'privately']\n",
            "['ah', 'homer_simpson', 'meet']\n",
            "['simpson', 'want', 'rejoin', 'power_plant', 'family']\n",
            "['hear', 'simpson', 'want', 'come', 'technical', 'supervisor', 'supervise', 'technician', 'hell', 'want', 'charge', 'safety', 'plant']\n",
            "['safety', 'sir', 'truth', 'know', 'actually', 'cause', 'accident', 'employee', 'doozie', 'find']\n",
            "['generous', 'offer', 'make', 'good', 'exactly', 'thirty', 'second', 'simpson']\n",
            "['charge', 'safety', 'place', 'blow', 'sky', 'high', 'nah', 'concentrate', 'work', 'gee', 'guy', 'desk', 'sure', 'big', 'let', 'marge', 'support', 'family', 'guy', 'get', 'clean', 'shirt', 'see']\n",
            "['umm', 'hey', 'job']\n",
            "['excellent', 'duty', 'step', 'balcony', 'tell', 'crowd', 'plant', 'safe']\n",
            "['lady_gentleman', 'plant']\n",
            "['oh', 'sit', 'tight', 'right']\n",
            "['mean', 'willing', 'good', 'job', 'raise', 'principle']\n",
            "['hmm', 'way', 'sound', 'little', 'far', 'fetched', 'lug', 'look', 'vow', 'continue', 'spend', 'free', 'minute', 'crusade', 'safety', 'course', 'lot', 'free', 'minute', 'give', 'job']\n",
            "['stupid', 'look', 'sound', 'good', 'testing', 'indicate']\n",
            "['get', 'job', 'work']\n",
            "['work', 'goodbye', 'friend']\n",
            "['worry', 'appoint', 'new', 'safety', 'inspector', 'plant', 'big', 'fat', 'raise']\n",
            "['hey', 'pop', 'dad', 'watch']\n",
            "['whoa', 'easy', 'drop', 'careful']\n",
            "['look', 'better', 'system', 'right', 'want', 'embarrass', 'boss', 'picnic']\n",
            "['try', 'unfortunate', 'noise', 'system', 'marge', 'want', 'embarrass', 'company', 'picnic']\n",
            "['sure', 'know', 'boss', 'love', 'delicious', 'gelatin', 'dessert']\n",
            "['oh', 'homer', 'mr_burns', 'say', 'like']\n",
            "['marge', 'time', 'speak', 'word', 'bonehead']\n",
            "['kid', 'stately', 'burn', 'manor', 'heaven', 'earth']\n",
            "['okay', 'look', 'boss', 'go_to', 'picnic', 'want', 'father', 'love', 'respect']\n",
            "['oh', 'thank', 'mr_burns', 'glad', 'invite']\n",
            "['miss', 'little', 'league']\n",
            "['oh', 'fight', 'good', 'time']\n",
            "['fire', 'man', 'smither', 'want', 'unpleasant', 'family', 'ruin', 'picnic']\n",
            "['go', 'tug', 'war', 'sir']\n",
            "['afternoon', 'mr_burns']\n",
            "['ah', 'hello', 'uh', 'uh']\n",
            "['oh', 'yes', 'lovely', 'wife', 'marge', 'look', 'little', 'lisa', 'grow', 'like', 'weed', 'brat']\n",
            "['correct', 'man', 'brat', 'oh', 'boss', 'look', 'bring', 'gelatin', 'dessert']\n",
            "['oh', 'love', 'peter', 'anybody', 'bring', 'damn', 'fool', 'go', 'tell', 'love', 'slimy', 'goop', 'toss', 'pile']\n",
            "['hear', 'dad', 'lie', 'underwear', 'scratch']\n",
            "['heh_heh', 'heh', 'congratulate', 'son', 'fine', 'joke', 'old_man']\n",
            "['remember', 'far', 'know', 'nice', 'normal', 'family']\n",
            "['hey', 'bart', 'fountain', 'rotten', 'egg']\n",
            "['oh', 'adorable', 'little_girl']\n",
            "['thank', 'dump', 'nursery', 'glass', 'punch']\n",
            "['hey', 'boy', 'torture', 'swans']\n",
            "['ummm', 'maybe', 'punch']\n",
            "['think', 'leave', 'kid', 'unsupervise']\n",
            "['bart', 'lisa', 'maggie']\n",
            "['whoa', 'careful', 'dad', 'blow', 'gasket', 'lose', 'job']\n",
            "['remember', 'rule', 'year']\n",
            "['yeah', 'shut', 'mouth', 'let', 'boss', 'win']\n",
            "['know', 'love', 'son', 'joshua', 'captain', 'football', 'team', 'daughter', 'amber', 'get', 'lead', 'school', 'play', 'usually', 'use', 'grade', 'tie', 'breaker', 'get', 'straight', 'term', 'mother']\n",
            "['uh_huh', 'uh', 'sense', 'greatness', 'family']\n",
            "['mr_burns', 'ready']\n",
            "['man', 'pathetic', 'go']\n",
            "['bart', 'oh', 'bart', 'noooo']\n",
            "['sit', 'enjoy', 'shade']\n",
            "['hey', 'brother', 'pour', 'wine']\n",
            "['good', 'bye', 'friend', 'lonely']\n",
            "['hey', 'homie', 'try', 'punch']\n",
            "['snap', 'marge', 'get', 'come', 'boss', 'go', 'toast']\n",
            "['pick', 'perfect', 'time', 'start']\n",
            "['musician', 'cease', 'infernal', 'tutlitating', 'thank', 'come']\n",
            "['oh', 'sorry', 'sorry', 'sorry']\n",
            "['time', 'goodbye', 'property', 'year', 'suggest', 'dawdle', 'hound', 'release', 'minute']\n",
            "['good', 'time', 'son']\n",
            "['yeah', 'thank', 'pop']\n",
            "['awww', 'kind', 'family', 'unity', 'like', 'smither']\n",
            "['man', 'predict', 'big', 'thing', 'power_plant']\n",
            "['quick', 'bart', 'kiss']\n",
            "['kiss', 'dad', 'kid']\n",
            "['bart', 'buck', 'kiss']\n",
            "['see', 'obvious', 'attempt', 'curry', 'favor']\n",
            "['fabulous', 'observation', 'sir', 'fabulous']\n",
            "['boy', 'glad', 'home', 'act', 'normal']\n",
            "['oh', 'come', 'cornball', 'routine', 'love', 'daddy', 'break']\n",
            "['honey', 'look', 'tired', 'like', 'drive']\n",
            "['ohhh', 'homie', 'think', 'go', 'sick']\n",
            "['farmer', 'dog', 'bingo', 'oh']\n",
            "['b', 'n', 'g', 'o', 'b', 'n', 'g', 'o', 'b', 'n', 'g', 'o', 'bingo', 'oh']\n",
            "['yeah', 'homer', 'room']\n",
            "['people', 'obviously', 'freak']\n",
            "['father', 'family', 'work', 'day', 'find', 'food', 'child', 'unable', 'fend', 'baby', 'bald', 'eaglet', 'dependant', 'mother', 'regurgitate', 'food', 'find']\n",
            "['look', 'everybody', 'yesterday', 'real', 'eye', 'opener', 'get', 'better', 'family', 'tonight', 'go', 'shovel', 'food', 'mouth', 'stare', 'tv', 'go', 'eat', 'dining', 'room', 'table', 'like', 'normal', 'family']\n",
            "['good', 'commence', 'shovel']\n",
            "['okay', 'rub', 'dub', 'dub', 'thank', 'grub']\n",
            "['ignore', 'boy', 'lord', 'chatter', 'bow', 'head', 'dear_lord', 'thank', 'microwave', 'bounty', 'deserve', 'mean', 'kid', 'uncontrollable', 'hellion', 'pardon', 'french', 'act', 'like', 'savage', 'picnic', 'oh', 'course', 'omnivorous', 'oh', 'lord', 'smite', 'family']\n",
            "['amen', 'let', 'eat']\n",
            "['homer', 'long', 'suppose', 'sit', 'listen', 'badmouth', 'man', 'upstairs']\n",
            "['sorry', 'marge', 'think', 'bad', 'family', 'town']\n",
            "['maybe', 'large', 'community']\n",
            "['sad', 'truth', 'family', 'like']\n",
            "['think', 'huh', 'way', 'find', 'follow']\n",
            "['look', 'kid', 'fighting', 'yelling']\n",
            "['oh', 'think', 'let', 'door', 'number']\n",
            "['have', 'conversation', 'actually', 'enjoy', 'talk']\n",
            "['wish', 'hear', 'say']\n",
            "['papa', 'believe', 'hear', 'rustle', 'bush']\n",
            "['probably', 'old_man', 'pipe', 'slipper']\n",
            "['whoa', 'look', 'place', 'dump']\n",
            "['bad', 'think', 'trample', 'poor', 'sap', \"'\", 'flower', 'bed']\n",
            "['fan', 'get', 'little_bit', 'anxious', 'folk']\n",
            "['matter', 'homer', 'bloodiest', 'fight', 'year', 'sittin', \"'\", 'like', 'thirsty', 'bump', 'log']\n",
            "['thanks', 'duty', 'couple', 'beer', 'nice']\n",
            "['buck', 'boy', 'kid']\n",
            "['good', 'moe', 'hey', 'listen', 'look', 'family', 'peeping', 'tom', 'terrorize', 'neighborhood']\n",
            "['quiet', 'boy', 'let', 'nice', 'people', 'enjoy', 'beer', 'uh', 'worry', 'dog', 'scent']\n",
            "['hey', 'get', 'bobo']\n",
            "['get', 'wiener', 'pocket']\n",
            "['figure', 'come', 'stupid', 'dog']\n",
            "['send', 'doctor', 'advertise', 'pro', 'wrestling']\n",
            "['know', 'moe', 'mom', 'say', 'stick', 'say', 'homer', 'big', 'disappointment', 'god_bless', 'soul']\n",
            "['blame', 'homer', 'get', 'deal', 'bad', 'hand', 'get', 'crummy', 'little', 'kid', 'control']\n",
            "['talk', 'way', 'kid']\n",
            "['tremendous', 'right', 'get', 'hurt', 'lady_gentleman', 'fight']\n",
            "['star', 'boxing', 'bring', 'dr', 'marvin', 'monroe', 'family', 'therapy', 'center']\n",
            "['honey', 'go', 'work', 'today']\n",
            "['honey', 'problem', 'will', 'well', 'till', 'admit']\n",
            "['admit', 'better', 'shut', 'big', 'yap']\n",
            "['hi', 'friend', 'dr', 'marvin', 'monroe', 'scene', 'look', 'familiar', 'help', 'gimmick', 'pill', 'fad', 'diet', 'family', 'bliss', 'double', 'money', 'today']\n",
            "['dr', 'marvin', 'monroe', 'family', 'therapy', 'center', 'hug', 'right']\n",
            "['learn', 'answer', 'life', 'problem', 'bottle', 'heh_heh', 'tv']\n",
            "['right', 'time', 'family', 'meeting']\n",
            "['meeting', 'watch_tv']\n",
            "['look', 'know', 'know', 'family', 'need', 'help', 'professional', 'help', 'appointment', 'dr', 'marvin', 'monroe']\n",
            "['fat', 'guy', 'tv']\n",
            "['box', 'lisa', 'box', 'world', 'difference']\n",
            "['gee', 'homer', 'sure', 'right', 'thing']\n",
            "['honey', 'give', 'matter', 'lot', 'study', 'commercial', 'see', 'good', 'cost', 'dollar']\n",
            "['go', 'dig', 'deep', 'marge', 'kid', \"'\", 'college', 'fund']\n",
            "['oh', 'come', 'marge', 'scrimp', 'chance', 'actually', 'someplace']\n",
            "['eighty', 'dollar', 'cent']\n",
            "['college', 'fund', 'save', 'year']\n",
            "['guess', 'need', 'partial', 'scholarship']\n",
            "['lick', 'save', 'family', 'go_to', 'supreme', 'sacrifice']\n",
            "['dad', 'pawn', 'tv']\n",
            "['oh', \"c'mon\", 'dad']\n",
            "['homer', 'pawn', 'engagement', 'ring', 'instead']\n",
            "['appreciate', 'honey', 'need', 'dollar']\n",
            "['pay', 'dollar', 'lovely', 'motorola']\n",
            "['mister', 'get', 'deal']\n",
            "['money', 'college', 'fund', 'tv', 'homer', 'drive', 'stake', 'heart', 'love']\n",
            "['hey', 'pain', 'gain']\n",
            "['pay', 'cash', 'check']\n",
            "['cash', 'course', 'get', 'dollar', 'right', 'hold', 'right', 'look', 'check', 'big', 'one']\n",
            "['want', 'impress', 'big', 'space', 'tv']\n",
            "['come', 'family', 'let', 'celebrate', 'new', 'find', 'ability', 'express', 'love', 'take', 'frosty', 'chocolate', 'milkshake']\n",
            "['young', 'girl', 'dream', 'vassar']\n",
            "['hello', 'dr', 'marvin', 'monroe', 'doubt', 'recognize', 'tv']\n",
            "['homer', 'stifle', 'youngster', 'family', 'feel', 'free', 'express', 'pad', 'jumbo', 'marker', 'want', 'draw', 'fear', 'anxiety', 'root', 'unhappiness', 'deep', 'cleansing', 'breath', 'begin']\n",
            "['homer', 'get', 'homer']\n",
            "['whoops', 'sorry', 'pay_attention']\n",
            "['pay_attention', 'notice', 'family', 'see', 'stern', 'authority', 'figure', 'ogre']\n",
            "['ogre', 'strong', 'word']\n",
            "['right', 'doc', 'successful', 'diagnosis']\n",
            "['whoa', 'okay', 'want', 'kill', 'good', 'healthy', 'necessarily', 'wrong', 'hostile', 'conflict', 'ask', 'use', 'patent', 'aggression', 'therapy', 'mallet']\n",
            "['okay', 'let', 'deep', 'cleansing', 'breath']\n",
            "['wait_minute', 'mallet', 'thing', 'padded', 'foam', 'rubber', 'point']\n",
            "['work', 'better', 'padding', 'doc']\n",
            "['yes', 'conclude', 'portion', 'treatment']\n",
            "['ridiculous', 'cure', 'go', 'require', 'somewhat', 'unorthodox', 'method']\n",
            "['worry', 'plenty', 'time', 'explain', 'warm', 'electric', 'generator']\n",
            "['comfy', 'good', 'touch', 'button', 'important', 'reason', 'e', 'wire', 'rest', 'family', 'ability', 'shock', 'ability', 'shock']\n",
            "['know', 'aversion', 'therapy', 'hurt', 'emotionally', 'hurt', 'physically', 'gradually', 'learn', 'hurt', 'will', 'wonderful', 'homer']\n",
            "['oh', 'yes', 'doctor']\n",
            "['boy', 'gobble', 'juice', 'sir']\n",
            "['excellent', 'excellent', 'energy', 'conservation', 'fad', 'dead', 'dodo']\n",
            "['doctor', 'monroe', 'patient', 'flee', 'building']\n",
            "['stop', 'stop', 'damage', 'equipment']\n",
            "['hey', 'nice', 'hair', 'mom']\n",
            "['gee', 'think', 'make', 'real', 'progress']\n",
            "['wait_minute', 'doc', 'tv', 'commercial', 'say', 'family', 'bliss', 'double', 'money']\n",
            "['oh', 'right', 'money']\n",
            "['homer', 'wonderful', 'pleasant', 'surprise']\n",
            "['money', 'feeling', 'earn']\n",
            "['excuse', 'dear', 'head', 'pawn', 'shop', 'tv']\n",
            "['piece', 'junk', 'forget', 'go', 'new', 'tv', 'inch', 'screen', 'realistic', 'flesh', 'tone', 'little', 'cart', 'wheel', 'dining', 'room', 'holiday']\n",
            "['oh', 'homer', 'love']\n",
            "['uh', 'uh', 'homer', 'lisa', 'make', 'teacher']\n",
            "['greasy', 'mitt', 'outta']\n",
            "['mrs', 'hoover', 'birthday']\n",
            "['know', 'name', 'people', 'like']\n",
            "['teacher', 'pet', 'apple', 'polisher', 'butt', 'kisser']\n",
            "['bart', 'say', 'butt', 'kisser', 'like', 'bad', 'thing']\n",
            "['boy', 'hurt', 'grease', 'wheel', 'little']\n",
            "['grease', 'wheel', 'dad', 'like', 'teacher']\n",
            "['surely', 'lisa', 'work', 'bart', 'cupcake', 'good', 'grade']\n",
            "['dad', 'good', 'grade', 'because', 'smart', 'pay_attention', 'study', 'hard']\n",
            "['yeah', 'right', 'lis', 'road', 'success', 'bart', 'work', 'brain']\n",
            "['uh', 'oh', 'school', 'bus', 'get_to']\n",
            "['yo', 'otto', 'man']\n",
            "['yo', 'bart', 'dude']\n",
            "['hey', 'believe', 'man', 'sister', 'pile', 'cupcake', 'butter', 'teacher', 'will', 'anybody', 'measly', 'little', 'crumb']\n",
            "['bad_news', 'man']\n",
            "['oh', 'thanks', 'little', 'lady']\n",
            "['better', 'let', 'hold', 'lis']\n",
            "['snivel', 'toad', 'little', 'egg', 'sucker']\n",
            "['backscratcher', 'foot', 'licker', 'honor', 'student']\n",
            "['right', 'right', 'look', 'sorry', 'get', 'upset', 'heat', 'moment', 'say', 'thing', 'mean']\n",
            "['little', 'egg', 'sucker']\n",
            "['generous', 'nature', 'spirit', 'giving']\n",
            "['open', 'mouth', 'close', 'eye', 'big', 'surprise']\n",
            "['thank', 'lis', 'good']\n",
            "['look', 'janey', 'cupcakes']\n",
            "['hey', 'big', 'idea', 'sister', 'man']\n",
            "['cupcake', 'knock', 'block']\n",
            "['bart', 'friend', 'nelson', 'muntz']\n",
            "['nah', 'happen', 'time', 'somebody', 'blood', 'splatter']\n",
            "['hey', 'wait_minute', 'right', 'bleed', 'blood']\n",
            "['uh', 'accident', 'man', 'terrible', 'ghastly', 'mistake', 'ask', 'anybody']\n",
            "['uh', 'oh', 'cold', 'wind']\n",
            "['hello', 'kid', 'board', 'good', 'play', 'friendly', 'child']\n",
            "['uh', 'oh', 'bell', 'come']\n",
            "['oh', 'school', 'son', 'hurry', 'time', 'class']\n",
            "['scoot', 'young', 'simpson', 'learn', 'afoot']\n",
            "['okay', 'nelson', 'duke']\n",
            "['hmmm', 'lunchtime', 'lunchtime']\n",
            "['be', 'go_to', 'outta', 'fourth_grade', 'alive']\n",
            "['get_to', 'tell', 'principal_skinner', 'bart']\n",
            "['squeal', 'violate', 'code', 'school', 'yard']\n",
            "['hey', 'everybody', 'come', 'brother', 'bart', 'bully', 'killer']\n",
            "['look', 'everybody', 'soon', 'big_deal', 'say', 'hero', 'say', 'fear', 'safety']\n",
            "['nelson', 'mistake', 'happen', 'man', 'listen', 'kick', 'sister', 'bake', 'cupcake', 'morning']\n",
            "['beating', 'schedule', 'afternoon']\n",
            "['goodbye', 'little', 'dude', 'look', 'life', 'like', 'man']\n",
            "['yes', 'school', 'nurse', 'wonderful', 'job', 'reconstruct', 'little', 'face', 'fight', 'goodbye', 'son', 'guess', 'right', 'homework', 'waste', 'time']\n",
            "['thank', 'bart', 'get', 'day', 'school']\n",
            "['yeah', 'get', 'day', 'work']\n",
            "['day', 'work', 'go_to', 'beloved', 'son', 'oh', 'bart', 'oh', 'bart']\n",
            "['well', 'homer', 'brave', 'bye_bye', 'bart', 'special', 'little', 'guy']\n",
            "['bart', 'cupcake', 'want', 'help', 'think', 'give', 'place', 'horrible', 'tragedy', 'avoid', 'know', 'eat', 'place', 'lovingly', 'forehead']\n",
            "['hey', 'look', 'get', 'food', 'thing', 'road', 'dude']\n",
            "['boy', 'sure', 'teach', 'lesson', 'whew', 'thank', 'guy', 'guess', 'leave', 'hearty', 'handshake', 'right', 'guy']\n",
            "['go_to', 'tomorrow', 'simpson']\n",
            "['oh', 'man', 'guy', 'tough', 'love']\n",
            "['hi', 'mom', 'hi', 'dad']\n",
            "['tough', 'day', 'school', 'boy']\n",
            "['let', 'pay', 'inevitable', 'price', 'help', 'sister']\n",
            "['little', 'scuffle', 'eh', 'hope', 'win']\n",
            "['go_to', 'miss', 'big', 'guy']\n",
            "['bart', 'mother', 'fool', 'idea', 'upset']\n",
            "['dad', 'need', 'help']\n",
            "['come', 'bart', 'want', 'mother', 'cry', 'let', 'help', 'dry', 'tear']\n",
            "['come', 'marge', 'bug', 'help', 'lisa']\n",
            "['bart', 'hope', 'go', 'straight', 'principal']\n",
            "['violate', 'code', 'school', 'yard', 'bart', 'die']\n",
            "['earth', 'talk', 'homer']\n",
            "['code', 'school', 'yard', 'marge', 'rule', 'teach', 'boy', 'man', 'let', 'tattle', 'fun', 'different', 'sure', 'feel', 'exactly', 'way', 'hmmm']\n",
            "['oh', 'homer', 'ridiculous', 'bart', 'instead', 'fight', 'try', 'little', 'understanding']\n",
            "['yeah', 'right', 'ought', 'good', 'laugh']\n",
            "['shh', 'bully', 'friend', 'little', 'chunky']\n",
            "['yeah', 'pretty', 'chunkified', 'right']\n",
            "['huh', 'huh', 'bet', 'study']\n",
            "['pretty', 'dumb', 'special', 'class']\n",
            "['tomorrow', 'instead', 'bicker', 'boy', 'talk', 'surprised', 'far', 'little', 'understanding']\n",
            "['thank', 'mrs', 'maharishi', 'gandhi', 'let', 'boy']\n",
            "['mean', 'fight', 'dirty', 'dad']\n",
            "['unfortunately', 'son', 'simpson', 'bend', 'rule', 'little', 'order', 'hold']\n",
            "['time', 'bully', 'think', 'go_to', 'throw', 'punch', 'throw', 'glob', 'mud', 'eye', 'sock', 'stagger', 'blind']\n",
            "['wrong', 'hit', 'turn']\n",
            "['chance', '-PRON-', 'right', 'family', 'jewel', 'little', 'doozy', 'simpson', 'trademark', 'generation']\n",
            "['remember', 'family', 'jewel', 'son']\n",
            "['whoa', 'ouch', 'ow', 'ooh', 'oh', 'boy']\n",
            "['good', 'advice', 'tough', 'simpson', 'alive']\n",
            "['yeah', 'remember', 'fight', 'home']\n",
            "['half', 'people', 'name', 'grampa']\n",
            "['second', 'floor', 'dank', 'room', 'left']\n",
            "['dear', 'advertiser', 'disgust', 'way', 'old', 'people', 'depict', 'television', 'vibrant', 'fun', 'love', 'sex', 'maniacs', 'bitter', 'resentful', 'individual', 'remember', 'good', 'old', 'day', 'entertainment', 'bland', 'inoffensive', 'following', 'list', 'word', 'want', 'hear', 'television', 'number', 'bra', 'number', 'horny', 'number', 'family', 'jewel']\n",
            "['need', 'advice', 'grampa', 'bully', 'school', 'keep', 'beat']\n",
            "['let', 'tell', 'boy', 'stand', 'bully', 'go_to', 'pick', 'rest_life']\n",
            "['simpson', 'gimme', 'newspaper']\n",
            "['want', 'crossword', 'puzzle']\n",
            "['say', 'gimme', 'puzzle']\n",
            "['guess', 'help', 'know']\n",
            "['herman', 'large', 'type', 'edition', 'month', 'soldier', 'fortune', 'come']\n",
            "['interest', 'authentic', 'nazi', 'underpant']\n",
            "['actually', 'come', 'want', 'meet', 'grandson', 'bart']\n",
            "['hello', 'young', 'american']\n",
            "['hello', 'sir', 'uh', 'mr', 'herman', 'lose', 'arm', 'war']\n",
            "['arm', 'let', 'way', 'time', 'teacher', 'tell', 'arm', 'inside', 'bus', 'window']\n",
            "['bart', 'get', 'problem', 'local', 'young', 'bully', 'name', 'nelson', 'think', 'help', 'kind', 'strategy']\n",
            "['strategy', 'hmmm', 'man']\n",
            "['need', 'need', 'train', 'hard', 'let']\n",
            "['okay', 'key', 'springfield', 'elm', 'street', 'greeks', 'know', 'carthaginians', 'know', 'know', 'need', 'declaration', 'war']\n",
            "['way', 'nice', 'legal', 'okay', 'use', 'franco', 'prusssian', 'war', 'change', 'otto', 'von', 'bismark', 'read', 'bart_simpson']\n",
            "['psst', 'grampa', 'think', 'guy', 'little', 'nuts']\n",
            "['oh', 'yeah', 'general', 'george', 's', 'patton', 'little', 'nut', 'guy', 'completely', 'mind', 'fail']\n",
            "['yeah', 'way', 'past', 'hour']\n",
            "['okay', 'know', 'right']\n",
            "['fight', 'nelson', 'bully']\n",
            "['guy', 'torment', 'year', 'sick']\n",
            "['promise', 'victory', 'promise', 'good', 'time', 'thing', 'know']\n",
            "['whoa_whoa', 'right', 'okay', 'promise', 'victory', 'promise', 'good', 'time']\n",
            "['get', 'b', 'arithmetic']\n",
            "['woulda', 'get', 'sick']\n",
            "['nerve', 'sir', 'stand', 'barking', 'anymore']\n",
            "['will', 'coward', 'army']\n",
            "['sorry', 'bart', 'push', 'plane', 'march', 'cliff', 'send', 'die', 'god', 'forsake', 'rock', 'reason', 'slap', '-PRON-', 'apologize', 'boy', 'right']\n",
            "['english', 'class', 'good']\n",
            "['right', 'enemy', 'hit', 'hit', 'let', 'group', 'martinez', 'steinberg', \"o'hara\", 'chang', 'olajuwon', 'herman']\n",
            "['get', 'rhyme', 'dictionary']\n",
            "['nelson', 'elm', 'street', 'video', 'arcade']\n",
            "['intelligence', 'indicate', 'shake', 'kid', 'quarter', 'arcade', 'head', 'kwik_e', 'mart', 'cherry', 'squishee']\n",
            "['hit', 'leave', 'kwik_e', 'mart', 'start', 'saturation', 'bombing', 'get', 'water', 'balloon']\n",
            "['round', 'sir', 'okay', 'happy_birthday']\n",
            "['death', 'guess', 'stuck']\n",
            "['okay', 'main', 'force', 'split', 'group', 'circle', 'way', 'cut', 'enemy', 'retreat', 'drive', 'way', 'close', 'trap', 'classic', 'pincer', 'movement', 'fail', 'year_old']\n",
            "['nelson', 'arcade', 'general']\n",
            "['know', 'think', 'old', 'think', 'time', 'pass', 'think', 'hear', 'scream', 'pain', 'look', 'terror', 'young_man', 'eye', 'thank', 'heaven', 'child']\n",
            "['hey', 'good', 'squishee']\n",
            "['hey', 'bird', 'go_to', 'suck', 'meal', 'straw', 'shut', 'trap']\n",
            "['looky', 'little', 'bart_simpson']\n",
            "['nelson', 'afraid', 'go', 'teach', 'lesson']\n",
            "['ha', 'oh', 'yeah', 'army']\n",
            "['artillery', 'commence', 'saturation', 'bombing']\n",
            "['awright', 'kid', 'make']\n",
            "['tree', 'tall', 'gray', 'haired', 'kid', 'butt', 'right']\n",
            "['guess', 'learn', 'lesson', 'untie', 'ya']\n",
            "['second', 'untie', 'go', 'beat', 'death', 'man']\n",
            "['go', 'attitude', 'go', 'untie']\n",
            "['hah', 'go_to']\n",
            "['uh', 'oh', 'right']\n",
            "['worry', 'ready', 'eventuality', 'armistice', 'treaty', 'article', 'nelson', 'raise', 'fist', 'anger', 'article', 'nelson', 'recognize', 'bart', 'right', 'exist', 'article', 'nelson', 'shall', 'official', 'power', 'shall', 'remain', 'figurehead', 'menace', 'neighborhood']\n",
            "['wow', 'sound', 'good', 'okay', 'sign']\n",
            "['boy', 'play', 'war']\n",
            "['yes', 'mrs_simpson']\n",
            "['mr', 'largo', 'country']\n",
            "['lady_gentleman', 'boy', 'girl', 'contrary', 'see', 'war', 'glamorous', 'fun', 'winner', 'loser', 'good', 'war', 'follow', 'exception', 'american', 'revolution', 'world_war', 'ii', 'star', 'war', 'trilogy', 'like', 'learn', 'war', 'lot', 'book', 'local', 'library', 'cool', 'gory', 'picture', 'good', 'night', 'everybody', 'peace', 'man']\n",
            "['lisa', 'lisa', 'problem', 'fall', 'lisa']\n",
            "['sorry', 'dad', 'woman', 'child']\n",
            "['wha', \"'\", 'th']\n",
            "['hell', 'key', 'steal', 'key', 'come', 'late', 'work']\n",
            "['oh', 'homer', 'lose', 'head', 'securely', 'fasten', 'neck']\n",
            "['den', 'great', 'idea']\n",
            "['warm', 'cold', 'cold', 'ice', 'cold']\n",
            "['try', 'rumpus', 'room']\n",
            "['rumpus', 'room', 'great', 'idea']\n",
            "['sorry', 'everybody', 'get', 'cupcake']\n",
            "['mom', 'scarf', 'cupcake', 'past', 'decade']\n",
            "['simple', 'cupcake', 'bring', 'pleasure']\n",
            "['right', 'hey', 'hey']\n",
            "['lisa', 'room', 'crazy', 'bebop', 'country', \"'_tis\", 'thee']\n",
            "['wail', 'homeless', 'family', 'live', 'car', 'iowa', 'farmer', 'land', 'take', 'away', 'unfeele', 'bureaucrat', 'west', 'virginia', 'coal', 'miner', 'cough']\n",
            "['fine', 'good', 'lisa', 'unpleasant', 'people', 'go', 'recital', 'week']\n",
            "['day', 'noon', 'bell', 'ring', 'herd', 'feed', 'time', 'sit', 'like', 'cattle', 'chew', 'cud', 'dread', 'inevitable']\n",
            "[\"c'mon\", 'lee', 'wait']\n",
            "['lisa', 'play', 'dodge', 'ball', 'object', 'game', 'avoid', 'ball', 'weave', 'duck', 'path']\n",
            "['word', 'dodge', 'ball']\n",
            "['listen', 'missy', 'tell', 'get', 'way', 'ball']\n",
            "['sad', 'play', 'dodge', 'ball', 'ridiculous', 'let', 'enthusiasm', 'play', 'ball']\n",
            "['come', 'come', 'let']\n",
            "['red', 'trunk', 'record', 'win', 'loss', 'undisputed', 'champ', 'house', 'battle', 'bart_simpson', 'whoopee', 'whoo', 'whoo', 'whoo', 'lavender', 'trunk', 'record', 'zero', 'win', 'defeat', 'oh', 'correction', 'humiliating', 'defeat', 'knockout']\n",
            "['homer', 'human', 'punching', 'bag', 'simpson', 'boo', 'boo', 'hiss']\n",
            "['homer', 'second', 'folk', 'new', 'record']\n",
            "['way', 'come', 'duck', 'ugh', 'wait_minute', 'way', 'stupid']\n",
            "['send', 'note', 'school']\n",
            "['time', 'little', 'hoodlum', 'oop', 'way']\n",
            "['see', 'way', 'prove']\n",
            "['hey', 'right', 'note', 'lisa']\n",
            "['lisa', 'refuse', 'play', 'dodge', 'ball', 'sad', 'look', 'sad', 'tear', 'eye']\n",
            "['kind', 'sad', 'sorry', 'dad', 'understand']\n",
            "['oh', 'sure', 'princess', 'feeling', 'know', 'like', 'stomach', 'hurt', 'go', 'crazy', 'climb', 'daddy', 'knee', 'tell']\n",
            "['wonder', 'point', 'difference', 'exist', 'sleep', 'night', 'suffering', 'world']\n",
            "['eh', 'er', 'eh']\n",
            "['come', 'lisa', 'ride', 'homer', 'horsey', 'giddiyap', 'whee']\n",
            "['lisa', 'honey', 'upstairs', 'draw', 'nice', 'hot', 'bath', 'help', 'feel', 'sad']\n",
            "['sorry', 'dad', 'know', 'mean']\n",
            "['thank', 'know', 'mean']\n",
            "['gee', 'homer', 'look', 'like', 'get', 'real', 'problem', 'hand']\n",
            "['right', 'bart', 'vacuum', 'floor']\n",
            "['hey', 'man', 'wrong']\n",
            "['time', 'trouble', 'get', 'know', 'hop', 'boy']\n",
            "['stupid', 'homer', 'think', 'big', 'stupid', 'homer', 'stupid', 'homer']\n",
            "['oh', 'bad', 'certainly', 'fun', 'vacuum', 'maybe', 'pleasure', 'scrub', 'tub']\n",
            "['typical', 'bart', 'think']\n",
            "['hey', 'stuff', 'like', 'maggie']\n",
            "['watch', 'prove', 'maggie', 'come', 'love', 'best']\n",
            "['maggie', 'come', 'girl', 'come']\n",
            "['come', 'maggie', 'choice', 'obvious']\n",
            "['maggie', 'glitter', 'look', 'substance']\n",
            "['right', 'maggie', 'bart']\n",
            "['exactly', 'come', 'love']\n",
            "['oh', 'come', 'let', 'boy', 'oh', 'great', 'oh', 'geeze']\n",
            "['gee', 'dad', 'bad']\n",
            "['concentrate', 'infernal', 'racket', 'lisa', 'lisa']\n",
            "['lisa', 'tell', 'play', 'saxamathing', 'house']\n",
            "['play', 'blue', 'dad']\n",
            "['lisa', 'sorry', 'mean', 'yell', 'ahead', 'play', 'blue', 'happy']\n",
            "['okay', 'dad', 'work', 'fingering', 'finger', 'clack', 'key', 'loud']\n",
            "['clack', 'loud', 'want', 'lis']\n",
            "['get', 'find', 'sound']\n",
            "['little', 'tune', 'italian', 'suit', 'blue']\n",
            "['wait', 'margie', 'door', 'let', 'happy', 'face', 'people', 'know', 'good', 'mommy', 'size', 'smile']\n",
            "['bart', 'easy', 'dad']\n",
            "['go', 'easy', 'old', 'slow', 'weak', 'pathetic']\n",
            "['homer', 'wake', 'wake', 'oh', 'let', 'wipe', 'drool']\n",
            "['know', 'marge', 'get', 'old', 'terrible', 'thing', 'think', 'sad', 'day', 'life', 'realize', 'beat', 'dad', 'thing', 'bart', 'experience', 'age', 'awake']\n",
            "['try', 'figure', 'bother', 'lisa', 'know', 'bart', 'handful', 'maggie', 'need', 'attention', 'little', 'lisa', 'young', 'woman']\n",
            "['oh', 'kind', 'underwear', 'thing']\n",
            "['low', 'b', 'flat']\n",
            "['okay', 'lisa', 'altissimo', 'register']\n",
            "['nice', 'nice', 'rupture']\n",
            "['thanks', 'mr', 'murphy']\n",
            "['help', 'kid', 'terrific', 'horn', 'player', 'ton', 'soul', 'jam']\n",
            "['oh', 'lonely', 'baby', 'leave', 'get', 'money', 'free', 'oh', 'lonely', 'day', 'bear', 'get', 'rusty', 'rusty', 'old', 'horn']\n",
            "['get', 'bratty', 'brother', 'bug', 'day', 'mornin', \"'\", 'mother', 'give', 'cupcake', 'away', 'dad', 'act', 'like', 'belong', 'belong', 'zoo', 'sa', 'dest', 'kid', 'grade', 'number']\n",
            "['aw', 'come', 'cheer']\n",
            "['know', 'play', 'pretty', 'real', 'problem']\n",
            "['yeah', 'feel', 'well']\n",
            "['blue', 'feel', 'well', 'make', 'people', 'feel', 'bad', 'make', 'buck', 'remind', 'neighborhood', 'play', 'little', 'club', 'call', 'jazz', 'hole']\n",
            "['lisa', 'away', 'jazzman']\n",
            "['mom', 'stay', 'little', 'longer']\n",
            "['come', 'come', 'worried', 'personal', 'fear', 'unfamiliar']\n",
            "['today', 'fire', 'race', 'downtown', 'springfield', 'gutting', 'symphony', 'hall', 'springfield', 'museum', 'natural', 'history', 'springfield', 'art', 'center']\n",
            "['barney', 'bowl', 'rama']\n",
            "['fire', 'official', 'say', 'alarm', 'blaze', 'take', 'hour', 'control']\n",
            "['hear', 'oh_god', 'lane', 'kinda', 'warped', 'oh', 'food']\n",
            "['think', 'nice', 'sister', 'bart']\n",
            "['oh', 'yeah', 'easy']\n",
            "['know', 'answer', 'know', 'answer', 'know', 'answer', 'let', 'drop', 'okay']\n",
            "['okay', 'bart', 'loving', 'attitude', 'nice', 'sister']\n",
            "['bart', 'time', 'like', 'present']\n",
            "['yeah', 'moe', 'tavern', 'moe', 'speak']\n",
            "['hold', 'uh', 'jacques', 'strap', 'hey', 'guy', 'look', 'jacques', 'strap']\n",
            "['oh', 'wait_minute', 'jacques', 'strap', 'cowardly', 'little', 'runt', 'hold', 'go_to', 'gut', 'like', 'fish', 'drink', 'blood']\n",
            "['sense', 'humor', 'man']\n",
            "['lisa', 'late', 'band', 'practice', 'let']\n",
            "['gimme', 'quarter', 'laundry']\n",
            "['corner', 'use', 'quarter', 'laundry']\n",
            "['hey', 'kid', 'pretty', 'good']\n",
            "['good', 'kid', 'thousand', 'fight', 'original', 'quarter']\n",
            "['listen', 'teach', 'fight', 'like']\n",
            "['tell', 'bark', 'like', 'dog']\n",
            "['little', 'ruff', 'ruff', 'ruff']\n",
            "['get', 'deal', 'fido']\n",
            "['look', 'like', 'quarter', 'old_man']\n",
            "['okay', 'tip', 'give', 'go', 'pound', 'tar', 'certain', 'little', 'smarty', 'pant', 'tonight']\n",
            "['howie', 'think', 'tell', 'stop', 'waste', 'money', 'stupid', 'place']\n",
            "['uh', 'oh', 'sorry', 'mom']\n",
            "['man', 'age', 'ashamed']\n",
            "['excuse', 'think', 'hear', 'wife', 'call']\n",
            "['lisa', 'listen', 'important', 'want', 'smile', 'today']\n",
            "['feel', 'like', 'smile']\n",
            "['matter', 'feel', 'inside', 'know', 'show', 'surface', 'count', 'mother', 'teach', 'bad', 'feeling', 'push', 'way', 'past', 'knee', 'walk', 'fit', 'invite', 'party', 'boy', 'like', 'happiness', 'follow']\n",
            "['hey', 'nice', 'smile']\n",
            "['hey', 'talk', 'go', 'weird']\n",
            "['know', 'think', 'sort', 'brainiac', 'guess', 'okay']\n",
            "['hey', 'come', 'house', 'practice', 'homework']\n",
            "['minute', 'people', 'minute', 'miss', 'simpson', 'hope', 'will', 'repeat', 'yesterday', 'outburst', 'unbridled', 'creativity']\n",
            "['lisa', 'apologize', 'wrong', 'want', 'sad', 'honey', 'sad', 'ride', 'finish', 'feel', 'sad', 'let', 'smiling']\n",
            "['say', 'stop', 'smile', 'lisa']\n",
            "['go', 'knock', 'time', 'get', 'boring', 'man']\n",
            "['try_kill', 'hard', 'son', 'heh_heh', 'heh']\n",
            "['kid', 'tonight', 'night']\n",
            "['right', 'man', 'ask', 'mr', 'nice', 'guy']\n",
            "['oh', 'oh', 'block']\n",
            "['ha_ha', 'get', 'try', 'get', 'ya', 'block', 'crowd', 'foot', 'hurricane', 'homer', 'move', 'kill']\n",
            "['boy', 'like', 'attention']\n",
            "['quiet', 'marge', 'big', 'moment']\n",
            "['bart', 'bloody', 'pulp', 'simpson', 'rope', 'hope', 'misery', 'luck', 'bart', 'come', 'right']\n",
            "['game', 'game', 'coulda', 'beat', 'boy', 'marge', 'close']\n",
            "['sorry', 'important', 'silly', 'loud', 'game']\n",
            "['right', 'mom', 'like', 'use', 'occasion', 'announce', 'retirement', 'undefeated', 'world', 'video', 'boxing']\n",
            "['oh', 'calm', 'homer', 'lisa', 'idea', 'think', 'fun', 'family']\n",
            "['song', 'write', 'friend', 'great', 'little', 'lady', 'jazz']\n",
            "['get', 'bratty', 'brother', 'bug', 'day', 'mornin', \"'\", 'mother', 'give', 'cupcake', 'away', 'dad', 'act', 'like', 'belong', 'belong', 'zoo']\n",
            "['sad', 'kid', 'grade', 'number']\n",
            "['rusty', 'old', 'hunk', 'junk']\n",
            "['howdy', 'bart', 'hot', 'ya']\n",
            "['shut', 'flander', 'hey', 'dad', 'come', 'decent', 'mower', 'like', 'flander']\n",
            "['happy', 'get', 'son', 'try', 'flanders']\n",
            "['like', 'new', 'wheel', 'simpson']\n",
            "['wow', 'man', 'rv']\n",
            "['bart', 'suppose', 'uh', 'feature']\n",
            "['get', 'microwave', 'dishwasher', 'big', 'screen', 'tv', 'deep', 'fryer', 'roof']\n",
            "['yes', 'indeedilly', 'doodily']\n",
            "['afford', 'like', 'ned', 'mail', 'seven', 'dollar', 'week']\n",
            "['simple', 'simpson', 'credit']\n",
            "['thank_god', 'heh_heh', 'help']\n",
            "['like', 'fine', 'rv', 'well', 'land', 'behemoth']\n",
            "['yes', 'ultimate', 'behemoth']\n",
            "['stand', 'presence', 'behold', 'look', 'thing']\n",
            "['believe', 'man', 'build', 'vehicle']\n",
            "['satellite', 'dish', 'sir']\n",
            "['tell', 'son', 'satellite', 'vanstar', 'launch', 'february', 'thing']\n",
            "['think', 'afford', 'homer']\n",
            "['let', 'worry', 'later', \"c'mon\", 'let', 'tour', 'want', \"c'mon\"]\n",
            "['wait', 'till', 'flander', 'get', 'load']\n",
            "['man', 'convict', 'want', 'ask', 'blurt']\n",
            "['want', 'know', 'like', 'face']\n",
            "['say', 'mean', 'get', 'color', 'roman']\n",
            "['look', 'like', 'god', 'sort', 'step', 'credit', 'office', 'zeus', 'hey', 'dad', 'go_to', 'come', 'work', 'drive', 'home']\n",
            "['go_to', 'quote', 'price', 'check', 'credit', 'rating', 'lemme', 'want', 'clear', 'formality', 'say', 'bob', 'guy', 'good', 'yes', 'check', 'machine', 'place', 'long', 'story', 'matter', 'go_to', 'run', 'computer']\n",
            "['good', 'siren', 'approve']\n",
            "['know', 'siren', 'good', 'ha', 'mr_simpson', 'bad', 'siren', 'computer', 'case', 'go', 'blind', 'tell', 'sell', 'vehicle', 'fellow', 'business', 'siren', 'say']\n",
            "['ultimate', 'behemoth', 'wee', 'bit', 'price', 'range', 'wee', 'bit', 'polite', 'afford', 'thing', 'live', 'million']\n",
            "['price', 'range', 'want', 'away', 'hand', 'bob']\n",
            "['easy', 'ruin', 'feeling', 'get', 'little']\n",
            "['mr_simpson', 'go_to', 'well', 'rv', 'mean', 'good', 'way', 'mean', 'literally', 'buddy', 'know', 'wagon']\n",
            "['price', 'quote', 'go_to', 'hand', 'because', 'go_to', 'price', 'double']\n",
            "['word', 'month', 'vehicle', 'head', 'window']\n",
            "['oh', 'know', 'alright', 'confer', 'family']\n",
            "['mr_simpson', 'talk', 'human', 'wrong', 'look', 'like', 'man', 'able', 'decision', 'waste', 'man', 'right']\n",
            "['call', 'minute', 'come', 'say', \"'\", 'save', 'little', 'come', \"'\", 'want']\n",
            "['good', 'decision', 'go_to', 'go_to', 'go_to', 'change', 'life']\n",
            "['hey', 'flander', 'look', 'get']\n",
            "['oooh', 'beaut', 'hey', 'congratulation', 'simpson', 'sure', 'load', 'fun']\n",
            "['jealous', 'everybody', 'ready']\n",
            "['spirit', 'ready', 'nature', 'come']\n",
            "['tell', 'smell', 'game']\n",
            "['homer', 'tell', 'interstate']\n",
            "['stop', 'ask', 'direction']\n",
            "['worry', 'terrain', 'vehicle']\n",
            "['foot', 'get', 'wet']\n",
            "['ah', 'come', 'go', 'nature']\n",
            "['dear', 'father', 'say', 'worry']\n",
            "['okay', 'panic', 'word', 'slowly', 'open', 'door', 'slide', 'count']\n",
            "['simpson', 'enter', 'forest']\n",
            "['heh_heh', 'chance', 'real', 'pioneer']\n",
            "['yes', 'sir', 'real', 'adventure', 'bet', 'people', 'trade', 'world', 'adventure', 'like']\n",
            "['look', 'maggie', 'birdie']\n",
            "['finger', 'discount', 'man']\n",
            "['worry', 'situation', 'bad', 'forget', 'experienced', 'woodsman', 'stay', 'minute', 'way', 'try', 'bearing']\n",
            "['quick', 'job', 'shelter']\n",
            "['uh_huh', 'okay', 'help', 'know', 'girl', 'stay', 'relax']\n",
            "['remember', 'dad', 'handle', 'big', 'dipper', 'point', 'north', 'star']\n",
            "['nice', 'lisa', 'astronomy', 'class', 'wood']\n",
            "['maggie', 'go', 'mom']\n",
            "['oh', 'think', 'go', 'long', 'good', 'hand', 'lisa']\n",
            "['dangerous', 'animal', 'forest', 'dad']\n",
            "['worry', 'leave', 'leave']\n",
            "['remember', 'act', 'afraid', 'animal', 'smell', 'fear', 'like', 'afraid']\n",
            "['experienced', 'woodsman', 'like', 'feel', 'thing', 'natural', 'like', 'sense']\n",
            "['boy', 'certainly', 'take', 'long', 'time', 'hope', 'maggie', 'slow']\n",
            "['lucky', 'red', 'hat', 'oh', 'dear', 'god', 'bart']\n",
            "['bart', 'oh', 'bart', 'bart', 'bart', 'oh', 'bart', 'beautiful', 'son', 'take', 'fate', 'heaven', 'earth', 'befall']\n",
            "['alive', 'buck', 'nekkid']\n",
            "['oooh', 'jungle', 'man']\n",
            "['thing', 'learn', 'survive', 'wood', 'boy', 'conceal', 'nakedness']\n",
            "['okay', 'slap', 'fern', 'boy', 'mud', 'ooh', 'require', 'little', 'mollusk', 'mollusk', 'right', 'ready', 'hit', 'town']\n",
            "['dad', 'hungry', 'eat', 'starve', 'man']\n",
            "['ah', 'food', 'good', 'thinking', 'son']\n",
            "['young', 'sapling', 'ought', 'trick']\n",
            "['-PRON-', '-PRON-', 'aaah']\n",
            "['great', 'camping', 'trip', 'honey', 'travel', 'mile', 'see', 'squirrel']\n",
            "['ranger', 'gate', 'say', 'watch', 'bear']\n",
            "['bear', 'right', 'right', 'let', 'bear', 'um', 'hello', 'bear', 'um', 'come', 'donut', 'heck', 'come']\n",
            "['right', 'right', 'point']\n",
            "['hope', 'maggie', 'boy', 'right']\n",
            "['oh', 'sure', 'fine', 'build', 'fire', 'know', 'nature', 'imagine', 'father', 'experienced', 'woodsman']\n",
            "['yeah', 'suppose', 'night', 'mom']\n",
            "['g', 'g', 'good', 'night', 'd', 'dad']\n",
            "['g', 'g', 'good', 'night', 's', 'son', 's', 'sleep', 'tight']\n",
            "['know', 'quit', 'ask', 'pointless', 'bart', 'look']\n",
            "['honey', 'honey', 'save']\n",
            "['uh', 'homer', 'bee']\n",
            "['wah', 'neh', 'wah', 'neh']\n",
            "['oh', 'water', 'thattaway', 'man']\n",
            "['pleehhh', 'hnnnn', 'plem', 'feh']\n",
            "['femmmmm', 'wah', 'gnnn', 'hrmmerhrr']\n",
            "['bigfoot', 'legendary', 'half', 'man', 'half', 'ape', 'longer', 'legend', 'real', 'unedited', 'video', 'footage', 'take', 'earlier', 'today', 'hill', 'mile', 'southwest', 'tenderfoot', 'gorge']\n",
            "['plemk', 'heh', 'feh']\n",
            "['naturalist', 'take', 'absolutely', 'extraordinary', 'picture', 'impressed', 'creature', 'uncivilized', 'look', 'foul', 'language', 'indescribable', 'stench']\n",
            "['popular', 'supermarket', 'tabloid', 'offer', 'reward', 'bring', 'creature', 'alive', 'naturally', 'story', 'soon', 'develop', 'return', 'president', 'address', 'progress']\n",
            "['look', 'like', 'girl', 'get', 'right', 'good', 'thing', 'find', 'horrible', 'roam', 'wood']\n",
            "['understand', 'suppose', 'pork_chop', 'favorite']\n",
            "['hey', 'bear', 'try', 'interview']\n",
            "['bear', 'tape', 'bear', 'set']\n",
            "['okay', 'let', 'husband', 'describe', 'marital', 'relation', 'brutish']\n",
            "['arewethereyet', 'arewethereyet', 'arewethereyet']\n",
            "['little', 'farther', 'little', 'little', 'food']\n",
            "['nice', 'grizzle', 'nice', 'grizzle', 'nice', 'grizzle']\n",
            "['praise', 'grizzles', 'son']\n",
            "['maggie', 'oh', 'little_girl']\n",
            "['nice', 'grizzly', 'nice', 'grizzly']\n",
            "['later', 'grizzly', 'dude']\n",
            "['get', 'get', 'bigfoot']\n",
            "['lucky', 'get', 'time', 'rescue']\n",
            "['hell', 'talk', 'sir']\n",
            "['get', 'alive', 'johnson', 'get', 'tranquilizer', 'gun', 'ready']\n",
            "['dad', 'oh', 'dad']\n",
            "['avenge', 'son', 'avenge', 'death']\n",
            "['week', 'capture', 'bigfoot', 'turn', 'scientific', 'poser', 'century', 'creature', 'ultimately', 'release', 'question', 'remain', 'homer', 'man', 'fact', 'legendary', 'missing', 'link', 'know', 'bigfoot']\n",
            "['specialist', 'world', 'gather', 'springfield', 'primate', 'institute', 'firsthand', 'examination', 'controversial', 'creature', 'ready', 'announce', 'finding']\n",
            "['lady_gentleman', 'distinguish', 'colleague', 'extensive', 'biological', 'anatomical', 'testing', 'regret', 'announce', 'evidence', 'inconclusive', 'thing', 'human']\n",
            "['zat', 'vhat', 'think', 'bigfoot', 'flesh']\n",
            "['disagree', 'think', 'eet', 'eez', 'man', 'ze', 'eye', 'glimmer', 'human', 'intelligence']\n",
            "['glimmer', 'eye', 'sloping', 'apelike', 'forehead']\n",
            "['oh', 'marge', 'guy', 'work', 'go', 'field', 'day']\n",
            "['cheer', 'homer', 'let']\n",
            "['gentlemen', 'gentlemen', 'fraulein', 'zis', 've', 'agree', 'speciman', 'average', 'human', 'brilliant', 'beast']\n",
            "['ooh', 'stupid', 'egghead']\n",
            "['oh', 'homer', 'brilliant', 'beast']\n",
            "['know', 'bart', 'age', 'pull', 'boner', 'think', 'find', 'people', 'pretty', 'decent', 'half', 'oh', 'oh']\n",
            "['get', 'corner', 'boy', 'away', 'head']\n",
            "['dad', 'thing', 'fault', 'run']\n",
            "['son', 'mess', 'matter', 'tempting', 'let', 'boy', 'rip', 'limb', 'limb', 'blood', 'thirsty', 'mob']\n",
            "['die', 'like', 'father', 'son']\n",
            "['look', 'get', '-PRON-']\n",
            "['murderous', 'mob', 'beg', 'spare', 'life', 'hear', 'story', 'end', 'head', 'beloved', 'town', 'founder']\n",
            "['ah', 'minute', 'second']\n",
            "['okay', 'start', 'sunday', 'morning']\n",
            "['kid', 'late', 'church', 'butts', 'right']\n",
            "['ready', 'inspection', 'mom']\n",
            "['nice', 'maggie', 'lisa', 'look', 'lovely', 'bart', 'assume', 'position']\n",
            "['oh', 'bart', 'father']\n",
            "['phillips', 'break', 'free']\n",
            "['yard', 'run', 'get', 'upset', 'making']\n",
            "['try', 'objective', 'oooh']\n",
            "['understand', 'marge', 'buck', 'ride', 'game']\n",
            "['forget', 'big', 'double', 'header', 'action', 'sunday', 'begin', 'eastern', 'spend', 'day']\n",
            "['oh', 'homer', 'promise']\n",
            "['gamble', 'marge', 'lead', 'pipe', 'cinch']\n",
            "['kick', 'wolodarsky', 'take', 'oh', 'fumble']\n",
            "['recover', 'end', 'zone', 'touchdown']\n",
            "['go', 'send', 'standing', 'topsy', 'turvy']\n",
            "['feel', 'like', 'traffic', 'cop', 'sunday', 'morning', 'try', 'little', 'goodness', 'family']\n",
            "['right', 'kogen', 'get', 'wolodarsky', 'open', 'end', 'zone', 'throw']\n",
            "['oh', 'doctor', 'get', 'barn', 'burner']\n",
            "['remarkable', 'comeback', 'lazarus', 'rise', 'dead']\n",
            "[\"c'mon\", 'everybody', 'late', 'bart', 'want', 'promise', 'pay_attention', 'sunday', 'school', 'bart', 'bart', 'bart']\n",
            "['personal', 'stereo', 'go', 'listen', 'rock', 'music', 'sunday', 'school']\n",
            "['believe', 'homer', 'homer', 'homer']\n",
            "['oh', 'stink', 'stink']\n",
            "['homer', 'plan', 'sit', 'car', 'till', 'game']\n",
            "['irreverent', 'attitude', 'bart', 'think', 'sneak', 'headphone', 'sunday', 'school']\n",
            "['time', 'bart', 'yes']\n",
            "['like', 'begin', 'today', 'sermon', 'entitle', 'gamble', 'th', 'deadly', 'sin', 'today', 'sunday', 'lord', 'day', 'moment', 'million', 'americans', 'lord', 'house', 'house', 'worship', 'false', 'idol', 'professional', 'football', 'oh', 'lord']\n",
            "['beautiful', 'sunday', 'perfect', 'football', 'weather', 'incredible', 'game', 'way', 'game', 'bring', 'good', 'people', 'duff', 'beer', 'wonderful', 'duff']\n",
            "['line', 'crucial', 'kick', 'final', 'tick', 'clock', 'remain', 'win', 'cap', 'amazing', 'comeback', 'yard', 'field', 'goal', 'wind']\n",
            "['kick', 'get', 'distance', 'holy', 'toledo', 'good']\n",
            "['good', 'good', 'good']\n",
            "['yeah', 'sit', 'homer']\n",
            "['ventriloquist', 'go', 'heaven', 'dummy']\n",
            "['robot', 'human', 'brain']\n",
            "['know', 'question', 'little', 'blind', 'faith', 'ask']\n",
            "['forget', 'week', 'remember', 'read']\n",
            "['hey', 'guy', 'great', 'stuff']\n",
            "['pleased', 'enjoy', 'strike', 'cord', 'today', 'homer']\n",
            "['oh', 'yeah', 'great']\n",
            "['homer', 'embarrass', 'congregation', 'today', 'sermon', 'listen']\n",
            "['oh', 'chance', 'certain', 'circumstance', 'right']\n",
            "['look', 'want', 'talk', 'anymore', 'kid', 'lisa', 'bart', 'learn', 'sunday', 'school', 'today']\n",
            "['answer', 'deep', 'theological', 'question']\n",
            "['yeah', 'thing', 'ape', 'heaven']\n",
            "['cute', 'little', 'monkey', 'terrible', 'tell']\n",
            "['understand', 'let', 'wild', 'jungle', 'ape', 'smart', 'one', 'live', 'roller', 'skate', 'smoke', 'cigar']\n",
            "['ah', 'cool', 'man', 'space', 'mutant', 'drop', 'drop']\n",
            "['marge', 'space', 'mutant']\n",
            "['um', 'mmm', 'know', 'movie', 'like', 'kill', 'innocent', 'people', 'eat', 'human', 'flesh', 'lot', 'bad', 'idea']\n",
            "['hey', 'dad', 'buck']\n",
            "['hope', 'plan', 'certain', 'movie', 'star', 'certain', 'space', 'mutant', 'certain', 'mother', 'want']\n",
            "['son', 'share', 'wealth']\n",
            "['da_da', 'da_da', 'da_da', 'de', 'de', 'de', 'whoa', 'ugh', 'cowabunga']\n",
            "['hey', 'hot_dog']\n",
            "['nice', 'dismount', 'man']\n",
            "['nah', 'land', 'face', 'end', \"lookin_'\", 'like']\n",
            "['hey', 'man', 'leave', 'kid', 'like']\n",
            "['yeah', 'witty', 'man']\n",
            "['need', 'introduction', 'bad', 'kid', 'school']\n",
            "['psst', 'coast', 'clear']\n",
            "['guy', 'sneakin', \"'\"]\n",
            "['yeah', 'sap', 'pay', 'movie']\n",
            "['hey', 'bart', 'come']\n",
            "['sneak', 'movie', 'practically', 'steal', 'man']\n",
            "['okay', 'want', 'sure', 'delude']\n",
            "['wait', 'think', 'hear']\n",
            "['come', 'loosen', 'baby']\n",
            "['stop', 'think', 'hear', 'human']\n",
            "['little', 'sneak', \"comin_'\"]\n",
            "['time', 'little', 'hoodlum', 'try', 'call', 'parent']\n",
            "['oh', 'yeah', 'want', 'crummy', 'movie']\n",
            "['know', 'bart', 'kick', 'space', 'mutant', 'movie']\n",
            "['jumbo', 'cherry', 'squishee', 'double', 'jumbo', 'original', 'flavor', 'sir']\n",
            "['okay', 'kid', 'watch', 'get', 'eye', 'head']\n",
            "['worry', 'guy', 'share', 'wealth']\n",
            "['yeah', 'thank', 'coverin', \"'\", 'man']\n",
            "['guy', 'found', 'springfield', 'build', 'hospital', 'log', 'mud', 'settler', 'die', 'great', 'blizzard']\n",
            "['watch', 'hit', 'right', 'eye']\n",
            "['hey', 'little', 'respect', 'insolent', 'little', 'thug']\n",
            "['hey', 'hey', 'hey', 'hey']\n",
            "['know', 'look', 'cloud', 'sky', 'start', \"lookin_'\", 'like', 'stuff']\n",
            "['yeah', 'like', 'look', 'like', 'cherry', 'bomb']\n",
            "['hey', 'right', 'look', 'look', 'like', 'guy', 'switchblade', 'stick']\n",
            "['yeah', 'look', 'like', 'school', 'bus', 'go', 'cliff', 'flame', 'kid', 'inside', 'scream']\n",
            "['look', 'like', 'statue', 'town', 'founder', 'jebediah', 'springfield']\n",
            "['mean', 'head', 'course']\n",
            "['wish', 'cut', 'ugly', 'old', 'head']\n",
            "['sure', 'cheese', 'everybody']\n",
            "['guy', 'come', 'remember', 'history', 'class', 'jebediah', 'kill', 'bear', 'bare', 'hand']\n",
            "['forget', 'love', 'jebediah', 'springfield']\n",
            "[\"c'mon\", 'guy', 'knock']\n",
            "['beat', 'simpson', 'man', 'think', 'cool']\n",
            "['beat', 'simpson', 'think', 'cool']\n",
            "['ahead', 'bart', 'tell', 'head', 'jebediah', 'springfield']\n",
            "['wow', 'look', 'bowling', 'ball', 'maggie', 'think', 'well', 'way', 'daddy', 'spend', 'hard', 'win', 'buck']\n",
            "['see', 'black', 'marbleize', 'liquid', 'center', 'stealth', 'bowler', 'pin', 'know', 'hit', '-PRON-']\n",
            "['sure', 'boy', 'mind']\n",
            "['wonder', 'important', 'popular']\n",
            "['glad', 'ask', 'son', 'popular', 'important_thing', 'world']\n",
            "['like', 'stuff', 'think', 'pretty', 'bad', 'kid', 'like', 'better']\n",
            "['run', 'little', 'scamp', 'boy', 'mischief', 'like', 'bowling', 'ball', 'liquid', 'center']\n",
            "['oh', 'yeah', 'world', 'ma']\n",
            "['oooh', 'look', 'hammer', 'thor', 'send', 'pin', 'valhalla', 'lisa']\n",
            "['valhalla', 'viking', 'die']\n",
            "['g', 'o', 'o', 'o', 'd', 'morning', 'everybody']\n",
            "['interrupt', 'mambo', 'morning', 'bring', 'special', 'news', 'bulletin', 'statue', 'jebediah', 'springfield', 'illustrious', 'town', 'founder', 'brutally', 'decapitate', 'night', 'act', 'senseless', 'vandalism', 'police', 'chief_wiggum', 'city', 'hall']\n",
            "['think', 'like', 'present', 'better']\n",
            "['witness', 'suspect', 'lead', 'information', 'dial', 'oh', 'ask', 'police', 'number', 'oh']\n",
            "['stay', 'tune', 'station', 'development', 'break']\n",
            "['statue', 'trailblaze', 'founder', 'town']\n",
            "['statue', 'statue', 'liberty', 'statue', 'lean', 'tower', 'piza', 'statue']\n",
            "['uh', 'oh', 'school', 'bus']\n",
            "[\"c'mon\", 'lis', 'school', 'bus']\n",
            "['lisa', 'get', 'brave', 'like', 'jebediah', 'kill', 'bear']\n",
            "['okay', 'come', 'come', 'everybody', 'get', 'life', 'let', 'try', 'tragedy']\n",
            "['right', 'moe', 'beer', 'sure', 'head']\n",
            "['say', 'hell', 'handbasket', 'hope', 'find', 'punk', 'hope', 'cut', 'head']\n",
            "['say', 'love', 'meet', 'guy', 'cut', 'head', 'statue']\n",
            "['yeah', 'wish', 'right']\n",
            "['yeah', 'break', 'bone', 'stupid', 'little', 'body']\n",
            "['yeah', 'right', 'man', 'limb', 'limb']\n",
            "['yesterday', 'cool', 'cut', 'head', 'cheese', 'everybody']\n",
            "['cloud', 'talk', 'man']\n",
            "['yeah', 'mean', 'throwin', \"'\", 'rock', 'thing', 'cut', 'head', 'guy', 'ice', 'bear', 'bare', 'hand', 'bag', 'bart']\n",
            "['say', 'bag', 'bart']\n",
            "['look', 'want', 'popular', 'hate', 'boy', 'town']\n",
            "['talk', 'overactive', 'imagination']\n",
            "['shut', 'want', 'like']\n",
            "['ummm', 'child', 'rattle']\n",
            "['mr_burns', 'blow', 'sir']\n",
            "['hey', 'bart', 'go']\n",
            "['watch', 'krusty_clown']\n",
            "['krustyland', 'commit', 'atrocity', 'know', 'cut', 'jebediah', 'head', 'care', 'brother', 'sister', 'daddy', 'mommy', 'turn', 'krusty', 'send', 'free', 'slide', 'whistle', 'like', 'sideshow_bob']\n",
            "['wait_minute', 'hope', 'plan', 'think']\n",
            "['know', 'bart', 'find', 'town', 'hero', 'hero', 'young', 'boy', 'courage', 'stand', 'admit', 'mistake']\n",
            "['yeah', 'run', 'little', 'short', 'courage', 'right']\n",
            "['jebediah', 'obediah', 'zachariah', 'jedediah', 'springfield', 'come', 'west']\n",
            "['way', 'meet', 'ferocious', 'bear', 'kill', 'bare', 'b', 'r', 'e', 'hand', 'modern', 'historian', 'recently', 'uncover', 'evidence', 'bear', 'fact', 'probably', 'kill', 'bear', 'kill', 'man', 'man', 'kill', 'bear', 'burgeon', 'town', 'springfield', 'bear']\n",
            "['um', 'hm', 'accident', 'wait', 'happen']\n",
            "['because', 'want', 'bad', 'kid', 'like', 'get', 'idea', 'popular', 'important_thing', 'world']\n",
            "['ridiculous', 'idea', 'like']\n",
            "['lay', 'boy', 'marge', 'good', 'kid', 'quit', 'givin', \"'\", 'degree']\n",
            "['maybe', 'little', 'responsible']\n",
            "[\"c'mon\", 'son', 'let', 'head', 'thing', 'authority']\n",
            "['story', 'want', 'tear', 'apart', 'young', 'sunday', 'school', 'student', 'stand', 'brink', 'salvation', 'await', 'wrath']\n",
            "['feel', 'like', 'kill', 'anymore']\n",
            "['feeling', 'mutual', 'sir']\n",
            "['good', 'go', 'son', 'remember', 'lynch', 'mob', 'nice']\n",
            "['whoops', 'whoops', 'oh', 'whoops', 'whoop']\n",
            "['go_to', 'good', 'birthday', 'breakfast', 'mom']\n",
            "['hey', 'lis', 'think']\n",
            "['hope', 'like', 'present', 'get']\n",
            "['know', 'heimlich', 'maneuver']\n",
            "['know', 'like', 'like', 'bottle', 'real', 'french', 'perfume']\n",
            "['way', 'gay', 'paree', 'buck', 'plus', 'tax']\n",
            "['think', 'go_to', 'like', 'hand', 'birthday', 'card', 'better']\n",
            "['whoa', 'big_deal', 'dry', 'macaroni', 'spray', 'paint', 'glue', 'whoopee']\n",
            "['dibs', 'dibs', 'lick', 'beater']\n",
            "['hep', 'hep', 'lisa', 'ungue', 'stick', 'eater', 'hep', 'hep']\n",
            "['birthday', 'love', 'birthday']\n",
            "['know', 'wife', 'birthday']\n",
            "['course', 'know', 'sure', 'think', 'forget']\n",
            "['oh', 'right', 'dad']\n",
            "['huh', 'thoughtful', 'gift', 'surprise', 'know', 'beautiful', 'morning', 'think', 'little', 'stroll', 'block']\n",
            "['think', 'forget', 'mom']\n",
            "['oh', 'come', 'come', 'open']\n",
            "['good_morning', 'consumer', 'springfield', 'mall', 'open', 'spending', 'need']\n",
            "['hmmm', 'nah', 'corny']\n",
            "['patty', 'buy', 'right']\n",
            "['oh', 'marge', 'get', 'want', 'get']\n",
            "['like', 'tackle', 'box']\n",
            "['remember', 'get', 'tackle', 'box']\n",
            "['surprise', 'connie', 'chung', 'calendar']\n",
            "['homer', 'lovely', 'dining', 'experience', 'chez', 'pierre', 'rusty', 'barnacle', 'nice']\n",
            "['want', 'someplace', 'fun', 'singing', 'sirloin']\n",
            "['place', 'waiter', 'sing']\n",
            "['homer', 'have', 'dinner', 'tonight', 'singing', 'sirloin']\n",
            "['ah', 'sound', 'delightful', 'balladeer']\n",
            "['dance', 'night', 'would']\n",
            "['have', 'baby', 'lovely', 'way', 'love']\n",
            "['nearer', 'god', 'thee', 'nearer', 'thee']\n",
            "['whoa', 'hmmm', 'thank', 'bart']\n",
            "['thirty_year', 'old']\n",
            "['time', 'start', 'new', 'man']\n",
            "['eat', 'mouth', 'shut']\n",
            "['finish', 'steak', 'look', 'wolf', 'gristle']\n",
            "['come', 'put', 'perfume']\n",
            "['yeah', 'hey', 'mom', 'come', 'put', 'perfume']\n",
            "['uh', 'save', 'special', 'occasion']\n",
            "['hell', 'talk', 'gallon']\n",
            "['occasion', 'special', 'special', 'end', 'make', 'special']\n",
            "['gotcha', 'tell', 'like', 'better']\n",
            "['hold', 'hold', 'mother', 'open', 'present']\n",
            "['happy_birthday', 'happy_birthday', 'happy', 'thirty', 'fourth', 'birthday', 'mrs', 'homer_simpson', 'happy_birthday', 'yooooo']\n",
            "['whoop', 'worry', \"frosting'll\", 'come', 'right', 'beauty']\n",
            "['hard', 'judge', 'bowl', 'life']\n",
            "['talk', 'talk', 'right', 'matter', 'fact', 'go', 'stop', 'second', 'marge', 'go_to', 'stop', 'talk']\n",
            "['buy', 'bowling', 'ball']\n",
            "['hole', 'drill', 'finger']\n",
            "['want', 'surprise', 'chop', 'hand', 'bring', 'store']\n",
            "['intend', 'use', 'ball']\n",
            "['homer', 'keep', 'ball']\n",
            "['hmmm', 'use', 'ball']\n",
            "['know', 'bowl', 'whoop']\n",
            "['keep', 'go', 'use', 'thank', 'present', 'homer']\n",
            "['hey', 'wait_wait', 'minute', 'go_to', 'need', 'lane']\n",
            "['okay', 'score', 'size', 'shoe', 'wear']\n",
            "['wear', 'street', 'shoe', 'lane', 'get_to', 'wear', 'bowling', 'shoe', 'size']\n",
            "['little', 'warm', 'moist']\n",
            "['wish', 'people', 'senseless', 'attachment', 'heavy', 'clumsy', 'thing', 'homer']\n",
            "['yes', 'good', 'teacher', 'teach', 'tell', 'little', 'arrow', 'wood', 'floor', 'mean', 'frame', 'beer', 'frame', 'bet', 'know', 'seven', 'split', 'marge']\n",
            "['yell', 'pin', 'cop']\n",
            "['let', 'marge', 'laugh', 'loud', 'laugh', 'loud', 'lose', 'weight']\n",
            "['oh', 'dear', 'realize', 'game', 'charge', 'lesson']\n",
            "['oh', 'right', 'start']\n",
            "['live', 'eh', 'kid', 'hot', 'pizza', 'food', 'king']\n",
            "['scared', 'dad', 'hard', 'take', 'care']\n",
            "['lisa', 'scared', 'think', 'great', 'chance', 'spend', 'time', 'kid', 'mother', 'get', 'turn', 'time', 'drag', 'like']\n",
            "['know', 'lane', 'feel', 'slickness', 'feel', 'satiny', 'finish', 'caress', 'experience', 'smooth']\n",
            "['compliment', 'delivery', 'boy']\n",
            "['okay', 'eat', 'eat', 'let', 'check', 'list', 'mom', 'leave']\n",
            "['eat', 'mm', 'hm']\n",
            "['ooh', 'clean', 'worry', 'everybody', \"this'll\", 'breeze', 'pitch']\n",
            "['right', 'clean', 'maggie', 'bed']\n",
            "['lullaby', 'good', 'night', 'bed', 'sleep', 'tight', 'close', 'eye', 'start', 'yawn', 'pleasant', 'dream', 'dawn']\n",
            "['ahhh', 'ahhh', 'oh', 'bowl']\n",
            "['sport', 'dear', 'sport', 'silly', 'thing']\n",
            "['umm', 'hmm', 'think', 'well', 'tomorrow', 'night']\n",
            "['sure', 'mind', 'take', 'care', 'kid']\n",
            "['oh', 'jacques', 'fit', 'get', 'size']\n",
            "['seventeen', 'enjoy', 'darling']\n",
            "['marge', 'darling', 'want', 'tomorrow', 'barney', 'bowl', 'rama', 'away', 'thunderous', 'folly', 'clatter', 'pin', 'meet', 'tomorrow', 'brunch']\n",
            "['marge', 'darling', 'pin', 'heart', 'knock', 'will', 'pick', 'spare']\n",
            "['oh', 'oh', 'right']\n",
            "['kid', 'special', 'lunch', 'lot', 'good', 'thing', 'grow', 'body', 'treat', 'fun']\n",
            "['whoa', 'aye', 'carumba']\n",
            "['go', 'bowl', 'tonight', 'mom']\n",
            "['hm', 'yes', 'matter', 'fact', 'treat', 'worry', 'dad', 'care', 'dinner']\n",
            "['mmm', 'wednesday', 'hoagie', 'night']\n",
            "['goodbye', 'lisa', 'darle', 'little', 'lisa']\n",
            "['goodbye', 'bart', 'special', 'little', 'guy']\n",
            "['mmmm', 'great', 'lunch', 'eh', 'lis']\n",
            "['oh', 'bart', 'psychologist', 'compensation', 'mom', 'rack', 'guilt', 'marriage', 'fail']\n",
            "['hey', 'rock', 'boat', 'man', 'make', 'like', 'bandit']\n",
            "['bart', 'read', 'happen', 'kid', 'parent', 'longer', 'love', 'cherish', 'separate', 'stage', 'right', 'stage', 'fear', 'stage', 'denial']\n",
            "['mimosa', 'drink', 'orange', 'juice', 'champagne', 'wonderful', 'think', 'offensive']\n",
            "['marge', 'marge', 'simpson', 'remember', 'helen', 'lovejoy', 'gossipy', 'wife', 'minister']\n",
            "['oh', 'yes', 'hello', 'helen']\n",
            "['finish', 'eat', 'leave', 'look', 'way', 'say', 'marge', 'simpson', 'have', 'brunch', 'man', 'husband', 'come', 'hello']\n",
            "['oh', 'squirm', 'account']\n",
            "['give', 'bowling', 'lesson', 'thank']\n",
            "['marge', 'uh', 'pin', 'seven', 'split', 'little', 'piece', 'food', 'ball', 'ball', 'big', 'know']\n",
            "['food', 'good', 'ball']\n",
            "[\"'\", 'bye_bye', 'church', 'sunday', 'marge']\n",
            "['lovely', 'friend', 'let', 'hope', 'run']\n",
            "['away', 'pry', 'eye', 'away', 'helen', 'world', 'apartment', 'fiesta', 'terrace']\n",
            "['wait', 'come', 'captivate']\n",
            "['certainly', 'lot', 'bowling', 'trophy']\n",
            "['like', 'bowling', 'naive', 'lovemake']\n",
            "['cosmic', 'force', 'bring', 'marge']\n",
            "['yes', 'divine', 'pin', 'spotter', 'place']\n",
            "['like', 'fragile', 'bowling', 'pin']\n",
            "['hey', 'dad', 'toss', 'old', 'apple', 'huh', 'sound_like', 'fun']\n",
            "['son', 'know', 'lift', 'head', 'let', 'ball']\n",
            "['aw', 'come', 'dad', 'lead']\n",
            "['simpson', 'check', 'runner', 'cool', 'fine', 'windup', 'pitch']\n",
            "['oh', 'sorry', 'ouch']\n",
            "['lisa', 'lisa', 'think', 'right', 'dad', 'wrong']\n",
            "['frightened', 'bart', 'welcome', 'stage', 'fear']\n",
            "['come', 'get_to', 'man']\n",
            "['sorry', 'bart', 'love', 'help', 'mire', 'stage', 'self', 'pity']\n",
            "['look', 'dad', 'know', 'go', 'give', 'advice', 'help']\n",
            "['give', 'advice', 'outta']\n",
            "['yeah', 'tell', 'bother', 'damn', 'stupid', 'know', 'fool', 'mouth', 'shut', 'way', 'will', 'thing', 'bad']\n",
            "['hmm', 'good', 'advice']\n",
            "['know', 'think', 'make', 'peanut', 'butter', 'jelly', 'sandwich', 'usually', 'jelly', 'drip', 'side', 'guy', 'hand', 'sticky', 'jelly', 'stay', 'right', 'middle', 'suppose', 'know', 'get', 'gift', 'guess', 'think', 'mention', 'time', 'know', 'feel', 'believe', 'keep', 'feeling', 'bottle', 'goodbye', 'wife']\n",
            "['beautiful', 'moment', 'life', 'well', 'deed', 'better', 'memory', 'moment', 'anticipation']\n",
            "['oh', 'jacques', 'handsome', 'devil', 'look', 'go', 'strike', 'tonight']\n",
            "['be', 'hungry', 'homer']\n",
            "['office', 'birthday', 'party']\n",
            "['oh', 'delightful', 'frosting', 'cake', 'thick', 'eugene', 'fisk', 'poor', 'sucker', 'assistant', 'know', 'fruit', 'punch', 'spike', 'ass', 'put', 'move', 'new', 'girl', 'valve', 'maintenance']\n",
            "['pffft', 'warn', 'marge', 'think', 'poor', 'young', 'thing', 'hot', 'truly']\n",
            "['keepin', \"'\", 'toe', 'babe']\n",
            "['thirty', 'pound', 'blimp', 'good', 'thing', 'tasty', 'exercise', 'morning']\n",
            "['blimp', 'homer', 'big', 'cuddly', 'teddy', 'bear']\n",
            "['oh', 'gimme', 'break']\n",
            "['wow', 'cool', 'man']\n",
            "['oh', 'thirty', 'pound', 'whale', 'curse', 'weakness', 'snack', 'treat', 'exercise', 'morning', 'homer']\n",
            "['good', 'idea', 'marge', 'way', 'friday', 'night', 'go_to', 'attend', 'little', 'boy', 'work', 'eugene', 'fisk', 'marry', 'girl', 'valve', 'maintenance']\n",
            "['homer', 'kind', 'stag', 'party']\n",
            "['marge', 'go_to', 'classy', 'tea', 'crumpet', 'kind', 'thing']\n",
            "['eugene', 'fisk', 'assistant']\n",
            "['hey', 'spanish', 'exposition']\n",
            "['uh', 'oh', 'fe', 'mail', 'man']\n",
            "['female', 'carrier', 'bart']\n",
            "['lady', 'spy', 'camera', 'spy', 'camera', 'spy', 'camera', 'lady', 'spy', 'camera', 'spy', 'camera', 'spy', 'camera']\n",
            "['spy', 'camera', 'day', 'month', 'spy', 'camera', 'spy', 'camera', 'spy', 'camera', 'stupid', 'spy', 'camera']\n",
            "['oh', 'thanks', 'man', 'whoa', 'look', 'size', 'thing', 'wonder', 'work']\n",
            "['because', 'get', 'lotta', 'spyin', \"'\"]\n",
            "['sorry', 'dad', 'answer', 'secret']\n",
            "['mom', 'bart', 'take', 'picture', 'butt']\n",
            "['oh', 'sure', 'like', 'go_to', 'picture', 'butt']\n",
            "['stop', 'nice', 'clothe', 'tonight', 'have', 'dinner', 'rusty', 'barnacle']\n",
            "['yay', 'fried', 'shrimp']\n",
            "['aw', 'mom', 'grab', 'burger', 'escape']\n",
            "['father', 'have', 'boy', \"'\", 'night']\n",
            "['ask', 'seven', 'year_old', 'boy', 'money', 'father', 'day', 'present', 'open', 'box', 'inside', 'little', 'eugene', 'baseball', 'glove', 'give', 'thing', 'matter', 'world', 'eugene', 'thing', 'matter', 'world', 'married', 'tomorrow', 'go', 'know', 'feel', 'day']\n",
            "['hey', 'worry', 'thing', 'go_to', 'pick', 'entertainment', 'get']\n",
            "['ahoy', 'spy', 'child', 'menu']\n",
            "['ahoy', 'place', 'bite']\n",
            "['go_to', 'little', 'bucko']\n",
            "['hmmmm', 'let', 'evening', 'shall', 'squid', 'platter']\n",
            "['oh', 'bart', 'excuse', 'sir', 'party', 'door', 'little', 'raucous', 'ask', 'quiet', 'little_bit']\n",
            "['open', 'door', 'lie', 'floor', 'say', 'barnacle', 'bill', 'sailor', 'open', 'door', 'lie', 'floor', 'say', 'barnacle', 'bill', 'sailor']\n",
            "['hey', 'try', 'guy', 'okay']\n",
            "['open', 'door', 'lie', 'floor', 'say', 'barnacle', 'bill', 'sailor']\n",
            "['baby', 'squid', 'platter', 'extra', 'tentacle']\n",
            "['bart', 'quit', 'fool', 'eat', 'dinner']\n",
            "['yeah', 'eat', 'bart']\n",
            "['okay', 'dawdle', 'food', 'cold']\n",
            "['okay', 'eugene', 'taste', 'bachelor', 'freedom']\n",
            "['present', 'princess', 'kashmir', 'queen', 'mysterious', 'east']\n",
            "['tell', 'boy', 'hell']\n",
            "['ooh', 'look', 'squirm']\n",
            "['sorry', 'usually', 'laugh', 'like']\n",
            "['oh', 'fun', 'life']\n",
            "['meeting', 'future', 'photographer', 'america', 'session']\n",
            "['like', 'welcome', 'new', 'member', 'bart_simpson']\n",
            "['oh', 'people', 'people', 'applaud', 'let', 'work']\n",
            "['subtle', 'gray', 'tone', 'recall', 'work', 'helmut', 'newton']\n",
            "['sexy', 'lady', 'bart']\n",
            "['beat', 'guy', 'dance', 'pop']\n",
            "['bring', 'mind', 'later', 'work', 'diane', 'arbus']\n",
            "['bart', 'appreciate', 'print', 'masterwork']\n",
            "['come', 'bart', 'go_to', 'print']\n",
            "['swear', 'let', 'live', 'soul', 'copy', 'photo']\n",
            "['cross', 'heart', 'hope', 'die']\n",
            "['stick', 'needle', 'eye']\n",
            "['jam', 'dagger', 'thigh']\n",
            "['eat', 'horse', 'manure', 'pie']\n",
            "['psst', 'look', 'get']\n",
            "['woo', 'get', 'copy']\n",
            "['hey', 'bart', 'come', 'milhouse', 'get', 'copy', 'girlie', 'picture', 'think', 'friend']\n",
            "['son', 'waste', 'time', 'sleazy', 'trash']\n",
            "['wait', \"'\", 'till', 'guy', 'work', 'little', 'doozy']\n",
            "['mike', 'al', 'want', 'thank', 'informative', 'memo', 'fax', 'whoop', 'come', 'boss', 'get_to']\n",
            "['reverend', 'lovejoy', 'wife', 'confiscate', 'boy', 'choir']\n",
            "['sheep', 'stray', 'flock']\n",
            "['homer_simpson', 'sir', 'low', 'level', 'employee', 'sector', 'g']\n",
            "['simpson', 'eh', 'family', 'man']\n",
            "['wife', 'kid', 'sir']\n",
            "['like', 'self', 'style', 'valentino', 'tomorrow', 'morning', 'smither']\n",
            "['glaze', 'scratch', 'win']\n",
            "['look', 'familiar', 'sir', 'television']\n",
            "['sorry', 'buddy', 'get', 'confused', 'fred', 'flintstone']\n",
            "['oooh', 'liberty', 'bell', 'liberty', 'bell', 'millionaire', 'come', 'liberty', 'bell', 'purple', 'fruit', 'thing', 'yesterday']\n",
            "['hey', 'hey', \"lookin_'\", 'good']\n",
            "['hey', 'mister', 'doo_doo', 'doo_doo', 'doo_doo', 'dee', 'doo', 'dee', 'doo', 'dee', 'doo']\n",
            "['doo', 'dee', 'doo_doo', 'pint', 'size']\n",
            "['man', 'lot', 'nutcase']\n",
            "['sir', 'see', 'thing', 'imagine']\n",
            "['hear', 'ya', 'buddy', 'whew', 'moon']\n",
            "['meaningless', 'marge', 'attempt', 'find', 'meaning', 'princess', 'kashmir']\n",
            "['look', 'marge', 'honey', 'baby', 'doll']\n",
            "['homer', 'want', 'look', 'right']\n",
            "['suggestion', 'sleep', 'filth', 'create']\n",
            "['aw', 'know', 'come']\n",
            "['soul', 'leave', 'need', 'know']\n",
            "['matter', 'homer', 'hot', 'lady', 'night', 'month', 'check', 'action']\n",
            "['oh', 'moe', 'wife', 'give', 'old', 'heave', 'ho', 'lousy', 'picture']\n",
            "['stay', 'tonight', 'homer']\n",
            "['oh', 'pal', 'go_to', 'stay', 'dingy', 'flophouse']\n",
            "['hungry', 'middle', 'night', 'open', 'beer', 'fridge']\n",
            "['look', 'barney', 'row', 'tiny', 'light', 'middle', 'house', 'leave', 'porch', 'light']\n",
            "['hey', 'rough', 'pal']\n",
            "['hello', 'marge', 'leave', 'damn', 'porch', 'light']\n",
            "['homer', 'money', 'know']\n",
            "['homer', 'yo', 'overwrought', 'unwind', 'little_bit', 'party', 'hall', 'know', 'apartment', 'complex', 'cater', 'upscale', 'young', 'single', 'like']\n",
            "['barn', 'want', 'crawl', 'bed']\n",
            "['suit', 'homer', 'nighty', 'night']\n",
            "['wonder', 'dad', 'come', 'home']\n",
            "['homer_simpson', 'homer_simpson', 'report', 'mr_burns', \"'\", 'office']\n",
            "['blue', 'blaze', 'think', 'simpson']\n",
            "['plant', 'employee', 'carry', 'like', 'oversexed', 'orangutan', 'heat', 'family', 'nuclear_power', 'plant', 'simpson', 'research', 'indicate', 'percent', 'power', 'woman', 'offend', 'customer', 'bawdy', 'shenanigan']\n",
            "['will', 'happen', 'sir', 'promise', 'sight']\n",
            "['second', 'simpson', 'smither', 'leave', 'room', 'minute']\n",
            "['simpson', 'measure', 'successful', 'man', 'wealth', 'power', 'dream', 'clock', 'punching', 'ilk', 'lead', 'solitary', 'life', 'fair', 'sex', 'remain', 'mystery', 'way', 'woman', 'certain', 'shall', 'animal', 'magnetisme', 'help', 'simpson', 'tell', 'secret']\n",
            "['uh', 'mr_burns', 'spite', 'everybody', 'think', 'lover', 'boy']\n",
            "['simpson', 'ask', 'nicely']\n",
            "['uh', 'wine', '-PRON-', 'dine', '-PRON-', 'bring', '-PRON-', 'flower', 'write', '-PRON-', 'love', 'poetry', 'sir']\n",
            "['course', 'simplicity', 'will', 'forget', 'simpson', 'return', 'work', 'tell', 'transpire']\n",
            "['yeah', 'good_luck', 'man']\n",
            "['oh', 'thanks', 'boy']\n",
            "['hello', 'marge', 'homer']\n",
            "['mad', 'mad', 'need', 'love', 'husband', 'read', 'like', 'book', 'milk']\n",
            "['look', 'drink', 'carton', 'come', 'marge', 'forgive', 'sorry', 'sorry']\n",
            "['homer', 'know', 'apologize']\n",
            "['yes', 'hungry', 'clothe', 'smelly', 'tired']\n",
            "['think', 'homer', 'know', 'bother', 'thing', 'teach', 'bart', 'bad', 'lesson', 'boy', 'idolize']\n",
            "['yes', 'homer', 'see', 'treat', 'woman', 'object', 'go', 'think', 'okay', 'owe', 'son', 'better', 'homer']\n",
            "['think', 'bart', 'meet', 'exotic', 'belly', 'person', 'want', 'real', 'human', 'real', 'thought', 'real', 'feeling', 'want', 'bart', 'apologize', 'way', 'treat']\n",
            "['okay', 'wish', 'command', 'little']\n",
            "['princess', 'kashmir', 'mean', 'april', 'flower', 'work', 'girlesque']\n",
            "['try', 'teach', 'son', 'treat', 'woman', 'object']\n",
            "['good', 'idea', 'april', 'foxy', 'boxing', 'tonight']\n",
            "['let', 'honor', 'springfield', 'number', 'swinger']\n",
            "['forget', 'teach', 'boy', 'lesson']\n",
            "['nahhh', 'try', 'club', 'mud']\n",
            "['marge', 'marge', 'go_to', 'try', 'place', 'sapphire', 'lounge', 'bart', 'say', 'look', 'floor']\n",
            "['hey', 'princess', 'guy', 'snap', 'shot']\n",
            "['oh', 'oh', 'hi']\n",
            "['place', 'lady', 'place', 'little', 'cooperation', 'showtime']\n",
            "['look', 'want', 'apologize', 'treat', 'like', 'object']\n",
            "['want', 'boy', 'find', 'belly', 'want', 'meet', 'woman', 'spangle', 'glitter', 'find', 'thought', 'feeling']\n",
            "['oh', 'okay', 'quick']\n",
            "['nice', 'meet', 'madam']\n",
            "['um', 'real', 'shawna', 'tifton', 'pet', 'peeve', 'rude', 'people', 'turn', 'on', 'include', 'silk', 'sheet', 'warm', 'fire', 'place']\n",
            "['hear', 'say', 'love', 'wife', 'oh', 'think', 'foolish', 'man', 'heart', 'stone']\n",
            "['cage', 'boss', 'freak']\n",
            "['oh', 'love', 'million', 'girl', 'girl', 'yeah', 'love', 'chinese', 'girl', 'eskimo', 'fin']\n",
            "['ooh', 'ahh', 'ooh', 'ahh', 'ahh', 'ahh', 'ohh']\n",
            "['hey', 'guy', 'picture']\n",
            "['sorry', 'partner', 'recognize', 'lady_gentleman', 'honor', 'real', 'swinging', 'cat', 'tonight', 'homer_simpson', 'party', 'guy']\n",
            "['mister', 'mistro', 'oh', 'love', 'million', 'girl', 'girl', 'yeah', 'love', 'chinese', 'girl', 'eskimo', 'fin', 'dig', 'deuchland', 'chick', 'girl', 'golden', 'curl', 'fact', 'think', 'love']\n",
            "['hep', 'heyyy', 'whoooo', 'look', 'yeah', 'da_da', 'da_da', 'da']\n",
            "['love', 'machine', 'sir']\n",
            "['uh', 'oh', 'wait_minute', 'wait_minute', 'stop', 'music', 'quiet', 'quiet']\n",
            "['oh', 'sink', 'lower']\n",
            "['wife', 'get', 'cut', 'little', 'thing', 'right', 'smile']\n",
            "['know', 'mom', 'sound', 'little', 'day', 'better']\n",
            "['right', 'folk', 'folk', 'sick', 'people', 'want', 'folk', 'kiss']\n",
            "['hi', 'little', 'fella', 'get', 'nice', 'juicy', 'fly', 'ya']\n",
            "['jeez', 'louise', 'look', 'mess']\n",
            "['tell', 'boy', 'billion', 'time', 'pick', 'jun']\n",
            "['like', 'play', 'like', 'play', 'like', 'play']\n",
            "['oh', 'maggie', 'poor']\n",
            "['like', 'play', 'like', 'play', 'like', 'play', 'wit', 'youuu', 'lik', 'pl', 'wi', 'youuu']\n",
            "['boy', 'bring', 'boy']\n",
            "['bart', 'clean', 'room', 'ask', 'father', 'trick', 'align', 'pick', 'mess', 'right']\n",
            "['clumsy', 'homer', 'fault', 'watch', 'go']\n",
            "['cherry', 'bomb', 'think', 'blow', 'guy']\n",
            "['people', 'people', 'rough', 'housing', 'monkey', 'bar', 'tuck', 'shirt', 'watch', 'see']\n",
            "['certainly', 'awfully', 'spanky']\n",
            "['mother', 'spanky', 'school', 'ground']\n",
            "['wow', 'cherry', 'bomb']\n",
            "['go_to', 'bart']\n",
            "['watch', 'bart', 'skinner']\n",
            "['good_morning', 'mr', 'skinner']\n",
            "[\"'\", 'morning', 'boy']\n",
            "['introduce', 'student', 'spanky']\n",
            "['mother', 'like', 'meet', 'milhouse', 'lewis', 'richard', 'bart_simpson']\n",
            "['bart_simpson', 'talk']\n",
            "['simpson', 'let', 'mother', 'shall']\n",
            "[\"'\", 'bye', 'spanky']\n",
            "['go_to', 'flush']\n",
            "['get', 'weakness', 'classic']\n",
            "['think', 'need', 'stop', 'little_girl', 'room']\n",
            "['okay', 'mother', 'way']\n",
            "['oh', 'marge', 'hurt', 'marge', 'marge']\n",
            "['oh', 'homer', 'time', 'fluff', 'pillow']\n",
            "['actually', 'wonder', 'grill', 'cheese', 'sandwich']\n",
            "['sure', 'squish', 'flat', 'crunchy', 'outside']\n",
            "['know', 'like', '-PRON-', 'homer']\n",
            "['maybe', 'little', 'wiener', 'come', 'oh', 'fruit', 'cocktail', 'heavy', 'syrup']\n",
            "['marge', 'marge', 'marge', 'door']\n",
            "['hello', 'mrs_simpson', 'afraid', 'disturbing', 'incident', 'school', 'today']\n",
            "['homer', 'principal_skinner']\n",
            "['oh', 'hello', 'principal_skinner', 'boy', 'cripple']\n",
            "['mmm_hmm', 'understand', 'completely', 'disturbing', 'incident', 'refer', 'happen', 'morning', 'son', 'flush', 'explosive', 'device', 'boy', \"'\", 'lavatory']\n",
            "['unfortunately', 'moment', 'mother', 'girl', \"'\", 'lavatory', 'make', 'use', 'facility']\n",
            "['mr', 'mrs_simpson', 'transcend', 'incorrigible', 'think', 'suspension', 'expulsion', 'trick', 'think', 'behoove', 'consider', 'deportation']\n",
            "['deportation', 'mean', 'kick', 'bart', 'country']\n",
            "['tad', 'glib', 'let', 'explain', 'elementary', 'school', 'participate', 'foreign', 'exchange', 'program', 'normally', 'student', 'select', 'basis', 'academic', 'excellence', 'intelligence', 'bart', 'case', 'prepared', 'big', 'exception', 'willing', 'play', 'spend', 'month', 'study', 'far', 'far', 'away']\n",
            "['sound', 'great', 'kid', 'learn', 'month']\n",
            "['homer', 'ask', 'bart', 'go']\n",
            "['actually', 'stay', 'france', 'lovely', 'chateau', 'heart', 'wine', 'country']\n",
            "['bart', 'speak', 'french']\n",
            "['oh', 'totally', 'immerse', 'foreign', 'language', 'average', 'child', 'fluent', 'week']\n",
            "['sure', 'pick', 'thing', 'will', 'cost', 'dime', 'long', 'willing', 'student']\n",
            "['wait_minute', 'skinner', 'know', 'principal', 'france', 'pull', 'scam']\n",
            "['thing', 'get', 'french', 'boy', 'get', 'albanian']\n",
            "['mean', 'white', 'pink', 'eye']\n",
            "['student', 'albania', 'country', 'adriatic', 'sea']\n",
            "['go', 'france', 'sound_like', 'fantastic', 'opportunity', 'think', 'bart']\n",
            "['aah', 'life', 'frog', 'life']\n",
            "['bart', 'like', 'spend', 'month', 'live', 'france']\n",
            "['make', 'crazy', 'month', 'year', 'summer']\n",
            "['mmm_hmm', 'bart', 'enthusiastic', 'idea']\n",
            "['bon', 'voyage', 'boy']\n",
            "['goodbye', 'special', 'special', 'little', 'guy', 'write', 'will']\n",
            "['go_to', 'miss', 'son', 'listen', 'see', 'great', 'sight', 'remember', 'represent', 'country', 'guess', 'say', 'mess', 'france', 'way', 'mess', 'room']\n",
            "['go', 'charter', 'flight']\n",
            "['mmm_hmm', 'come']\n",
            "[\"'\", 'bye', 'bart']\n",
            "[\"'\", 'bye', 'miss']\n",
            "['life', 'jacket', 'seat']\n",
            "['goodbye', 'adil', 'write']\n",
            "['hey', 'man', 'watch']\n",
            "['hey', 'man', 'bart_simpson']\n",
            "['okay', 'kid', 'let']\n",
            "['little', 'breeze', 'whisper', 'louise', 'bird', 'tree', 'louise', 'la_la', 'la_la', 'la_la', 'la_la', 'ooo', 'la_la', 'long', 'sir']\n",
            "['cha', 'teau', 'ma', 'son']\n",
            "['ah', 'maurice', 'american', 'boy', 'get', 'day', 'endless', 'break', 'labor']\n",
            "['know', 'albania', 'unit', 'currency', 'call', 'lek']\n",
            "['get_to', 'kiddin', \"'\", 'lek']\n",
            "['national', 'flag', 'head', 'eagle', 'red', 'field']\n",
            "['old', 'star', 'stripe']\n",
            "['main', 'export', 'furious', 'political', 'thought']\n",
            "['trans', 'albanian', 'airlines', 'flight', 'number', 'tirana', 'springfield', 'arrive', 'gate']\n",
            "['welcome', 'new', 'home', 'escape', 'impossible', 'cesar', 'nephew', 'ugolin', 'find', 'life', 'chateau', 'hard', 'shut', 'exactly', 'time', 'pass', 'quickly']\n",
            "['guess', 'month', 'yes', 'mother']\n",
            "['lisa', 'maggie', 'new', 'father', 'homer']\n",
            "['affectionate', 'little', 'albanian']\n",
            "['cesar', 'look', 'rich']\n",
            "['will', 'fit', 'sell']\n",
            "['red', 'hat', 'maurice']\n",
            "['hey', 'come', 'guy', 'quit', 'grabby']\n",
            "['sorry', 'man', 'guest']\n",
            "['find', 'accent', 'peculiar', 'certain', 'aspect', 'culture', 'absurd', 'offensive', 'urge', 'little', 'adil', 'benefit', 'doubt', 'way', 'way', 'hope', 'better', 'understand', 'backward', 'neighbor', 'world']\n",
            "['thank', 'principal_skinner', 'thank', 'fellow', 'student', 'country', 'day', 'find', 'americans', 'trust', 'officially', 'require', 'hate', 'want', 'know', 'feel', 'heart']\n",
            "['hurry', 'boy', 'grape', 'wait', 'water']\n",
            "['defend', 'country', 'percent', 'people', 'control', 'ninety', 'percent', 'wealth']\n",
            "['defend', 'country', 'people', 'think', 'act', 'worship', 'way', 'want']\n",
            "['kid', 'stop', 'fight', 'maybe', 'lisa', 'right', 'america', 'land', 'opportunity', 'maybe', 'adil', 'point', 'machinery', 'capitalism', 'oil', 'blood', 'worker']\n",
            "['father', 'right', 'fight', 'friend']\n",
            "['settle', 'clear', 'dish']\n",
            "['mrs_simpson', 'oppress', 'today', 'clear', 'dish']\n",
            "['know', 'marge', 'way', 'want', 'fully', 'function', 'family', 'unit', 'blame', 'guess', 'pretty', 'clear', 'cylinder', 'fire']\n",
            "['paper', 'thin', 'commitment', 'child', 'send', 'shiver', 'spine', 'excuse']\n",
            "['oh', 'jealous', 'exchange']\n",
            "['mmm', 'good', 'sausage']\n",
            "['yes', 'pass', 'wine']\n",
            "['quiet', 'work', 'like', 'man', 'feed', 'like']\n",
            "['hey', 'hey', 'come', 'pal']\n",
            "['leave', 'maurice', 'floor', 'good', 'sleep']\n",
            "['nice', 'cozy', 'adil']\n",
            "['yes', 'thank', 'father']\n",
            "['look', 'adil', 'dad']\n",
            "['aww', 'call', 'dad']\n",
            "['dad', 'think', 'come', 'visit', 'nuclear_power', 'plant']\n",
            "['biological', 'kid', 'want', 'work']\n",
            "['pull', 'string', 'boy', 'security', 'sure', 'bet']\n",
            "['watch', 'grab', 'grape', 'thumb', 'forefinger', 'gently', 'twist', 'drop', 'bucket']\n",
            "['good', 'million', 'time']\n",
            "['american', 'donut', 'glaze', 'powdered', 'raspberry', 'fill', 'freedom', 'choice']\n",
            "['dad', 'think', 'plutonium', 'isolation', 'module']\n",
            "['uh', 'maybe', 'hold', 'second']\n",
            "['hey', 'lenny', 'place', 'plutonium', 'isolation', 'deal']\n",
            "['floor', 'candy', 'machine']\n",
            "['ungrateful', 'swine', 'food', 'shelter', 'repay']\n",
            "['ugh', 'ugh', 'ugh', 'stu', 'pid', 'grape', 'bunch', 'creep', 'hate', 'france', 'ugh']\n",
            "['sure', 'take', 'shine', 'little', 'adil']\n",
            "['sure', 'make', 'life', 'lot', 'easy', 'admit']\n",
            "['okay', 'admit', 'love', 'bart']\n",
            "['okay', 'okay', 'love', 'bart']\n",
            "['oh', 'adil', 'sweet', 'boy']\n",
            "['sparrow', 'nest', 'sparrow', 'nest', 'stand', 'transmission']\n",
            "['tell', 'sparrow', 'fail']\n",
            "['dear', 'bart', 'france', 'know', 'write', 'guess', 'have', 'fun']\n",
            "['united_states', 'fine', 'think', 'maggie', 'word', 'day', 'lisa', 'get', 'math', 'mention', 'news', 'put', 'father', 'night', 'go', 'sleep', 'talk', 'love']\n",
            "['remember', 'dress', 'warm', 'try', 'helpful', 'adopted', 'parent']\n",
            "['hi', 'sideshow_bob']\n",
            "['find', 'faith', 'high', 'power', 'shake', 'think', 'miracle', 'anti', 'freeze', 'poison', 'right', 'give', 'wine', 'right', 'kick', 'mais', 'dan', 'le', 'proportion', 'voulue', 'donne', 'du', 'corps', 'au', 'vin']\n",
            "['second', 'thought', 'bart', 'bart', 'come', 'watch', 'bet', 'will', 'blind']\n",
            "['worry', 'france', 'customary', 'child', 'little', 'wine']\n",
            "['yeah', 'get', 'anti', 'freeze']\n",
            "['see', 'buy', 'case', 'anti', 'freeze']\n",
            "['rain', 'outside', 'let', 'wine', 'tomorrow']\n",
            "['sorry', 'speak', 'english']\n",
            "['got_to', 'help', 'guy', 'stay', 'work', 'day', 'night', 'feed', 'sleep']\n",
            "['little', 'boy', 'piece', 'candy', 'tien', 'petit', 'garcon', 'voila', 'un', 'bonbon']\n",
            "['want', 'piece', 'candy', 'need', 'hel']\n",
            "['come', 'mister', 'help']\n",
            "['aw', 'forget', 'stupid', 'anybody', 'learn', 'dumb', 'language', 'listen', 'french', 'past', 'deux', 'mois', 'et', 'je', 'ne', 'sais', 'pas', 'un', 'mot', 'eh', 'mais', 'je', 'parle', 'francois', 'maintenant', 'incroyable']\n",
            "['hey', 'monsieur', 'aidez', 'moi', 'ce', 'deux', 'type', 'chez', 'qui', \"j'habite\", 'fait', 'travailler', 'jour', 'et', 'nuit', 'ils', 'ne', 'donnent', 'pas', 'manger', 'il', 'fait', 'dormir', 'sur', 'la', 'terre', 'ils', 'mettent', \"d'antigel\", 'dans', 'le', 'vin', 'et', 'ils', 'sont', 'donne', 'mon', 'chapeau', 'rouge', \"l'ane\"]\n",
            "['anti', 'freeze', 'wine', 'crime', 'come', 'boy', 'fear']\n",
            "['mon', 'sauveteur', 'vous', 'aurez', 'toujours', 'une', 'place', 'dan', 'mon', 'coeur']\n",
            "['oh', 'blueprint', 'adil', 'want', 'tell', 'curious', 'little', 'dicken', 'bet', 'build', 'nuclear_power', 'plant', 'want']\n",
            "['right', 'sparrow', 'know', 'minute', 'surrender']\n",
            "['ooh', 'trouble', 'neighborhood', 'let', 'check']\n",
            "['sir', 'sir', 'trail', 'spy', 'transmit', 'highly', 'confidential', 'information', 'unfriendly', 'nation']\n",
            "['mmm_hmm', 'use', 'radio', 'triangulation', 'track', 'exactly', 'point']\n",
            "['right', 'country', 'start', 'letter']\n",
            "['time', 'sparrow', 'come']\n",
            "['gee', 'whiz', 'adil', 'kick', 'see']\n",
            "['ouch', 'watch', 'hey', 'ow', 'ouch']\n",
            "['participate', 'student', 'exchange', 'program']\n",
            "['au', 'revoir', 'sucker']\n",
            "['arrange', 'exchange', 'man', 'catch', 'albania']\n",
            "['yes', 'think', 'get', 'old', 'game']\n",
            "['okay', 'kid', 'let', 'hurry']\n",
            "['goodbye', 'simpson', 'thank', 'hospitality', 'hope', 'experience', 'sour', 'student', 'exchange', 'program']\n",
            "['goodbye', 'adil', 'pleasure']\n",
            "['goodbye', 'adil', 'nice', 'trip']\n",
            "['goodbye', 'adil', 'send', 'civil', 'defense', 'plan', 'want']\n",
            "['air', 'france', 'flight', 'dix', 'neuf', 'cent', 'quatre', 'vingt', 'huit', 'paris', 'springfield', 'arrive']\n",
            "['oh', 'bart', 'baby', 'boy', 'welcome', 'home']\n",
            "['hey', 'big', 'guy']\n",
            "['need', 'hey', 'boy']\n",
            "['bring', 'gift', 'unselfish', 'act']\n",
            "['basically', 'meet', 'nice', 'french', 'person']\n",
            "['bart', 'go_to', 'bother', 'good']\n",
            "['homer', 'love', 'glass', 'wine', 'bart', 'bring']\n",
            "['sorry', 'marge', 'wiseguy', 'stick', 'cork', 'bottle']\n",
            "['hear', 'marge', 'boy', 'speak', 'french']\n",
            "['hey', 'kid', 'love']\n",
            "['sideshow_bob', 'brittany', 'today', 'birthday']\n",
            "['happy_birthday', 'brittany', 'want', 'celebrate', 'want', 'sing', 'birthday', 'song']\n",
            "['want', 'shoot', 'sideshow_bob', 'cannon']\n",
            "['cannon', 'cannon', 'cannon', 'cannon']\n",
            "['sorry', 'sideshow_bob', 'special', 'birthday', 'wish']\n",
            "['doom', 'sideshow_bob']\n",
            "['know', 'luck', 'shoot', 'cannon', 'maybe', 'gun', 'powder']\n",
            "['comedy', 'thy', 'krusty']\n",
            "['hey', 'kid', 'time', 'itchy_scratchy']\n",
            "['fight', 'bite', 'bite', 'fight', 'bite', 'bite', 'bite', 'bite', 'fight', 'fight', 'fight', 'itchy_scratchy']\n",
            "['senseless', 'violence', 'understand', 'appeal']\n",
            "['cartoon', 'mean', 'adult', 'prime', 'time']\n",
            "['hello', 'homie', 'hope', 'pick', 'half', 'gallon', 'premium', 'ice_cream', 'way', 'home', 'work']\n",
            "['oooh', 'premium', 'wait_minute']\n",
            "['patty_selma', 'come', 'slide', 'trip', 'yucatan']\n",
            "['yoo', 'hoo', 'anybody', 'home']\n",
            "['ooo', 'get', 'homer', 'sister']\n",
            "['oh', 'carousel', 'real', 'treat']\n",
            "['hello', 'steady', 'customer', 'evening', 'sir']\n",
            "['mmm', 'chocolate', 'oooh', 'double', 'chocolate', 'new', 'flavor', 'triple', 'chocolate']\n",
            "['little', 'trip', 'cash', 'register']\n",
            "['matter', 'sir', 'see', 'look', 'unhappy', 'purchase', 'large', 'quantity', 'ice_cream']\n",
            "['reason', 'look', 'unhappy', 'tonight', 'slide', 'star', 'wife', 'sister', 'gruesome', 'twosome']\n",
            "['ow', 'foot', 'lousy', 'stupid', 'clumsy']\n",
            "['hand', 'money', 'paper', 'bag']\n",
            "['yes_yes', 'know', 'procedure', 'armed', 'robbery', 'work', 'convenience', 'store', 'know']\n",
            "['emerge', 'chip', 'opportunity', 'prove', 'hero', 'long', 'go']\n",
            "['mexican', 'delicacy', 'call', 'taco', 'platter', 'hmmm', 'delicious']\n",
            "['selma', 'take', 'siesta']\n",
            "['big', 'big', 'red', 'hair', 'come', 'yeah', 'yeah', 'like']\n",
            "['simple', 'charcoal', 'rendering', 'man']\n",
            "['yeah', 'wait_minute', 'guy', 'tv', 'kid', 'hero', 'cruddy', 'crummy', 'krusty_clown']\n",
            "['hey', 'hey', 'go']\n",
            "['uh', 'm', 'maybe', 'better', 'run', 'bed']\n",
            "['krusty_clown', 'arrest', 'armed', 'robbery', 'right', 'remain', 'silent', 'blah_blah', 'blah_blah', 'blah_blah', 'blah_blah', 'blah']\n",
            "['crime', 'make', 'laugh', 'guilty']\n",
            "['oh', 'definitely', 'number', 'heh_heh']\n",
            "['mail', 'await', 'return']\n",
            "['selma', 'drop', 'vacation', 'film', 'develop']\n",
            "['conclude', 'mexican', 'odyssey']\n",
            "['oh', 'goody', 'gumdrop']\n",
            "['miss', 'slide', 'homer']\n",
            "['oh', 'fantastic', 'marge', 'go_to', 'believe', 'happen', 'kwik_e', 'mart', 'mind', 'business', 'oooh', 'oooh', 'ooh', 'news']\n",
            "['springfield', 'number', 'news', 'team', 'emmy', 'award', 'win', 'anchorman', 'kent_brockman']\n",
            "['good', 'evening', 'scott', 'christian', 'kent_brockman', 'tonight', 'clown', 'cross', 'road', 'rob', 'kwik_e', 'mart']\n",
            "['news', 'story', 'enigmatic', 'half', 'joke', 'right', 'commercial', 'message']\n",
            "['wait_minute', 'bart', 'know', 'guy', 'lunch', 'box']\n",
            "['oh', 'mean', 'krusty_clown']\n",
            "['kid', 'idol', 'base', 'life', 'krusty', 'teaching']\n",
            "['krusty_clown', 'bar', 'tonight', 'daring', 'twilight', 'robbery', 'local', 'kwik_e', 'mart']\n",
            "['earlier', 'evening', 'springfield', 'swat', 'team', 'apprehend', 'tv', 'clown', 'appear', 'rival', 'station', 'opposite', 'emmy', 'award', 'win', 'hobo', 'hank']\n",
            "['actual', 'footage', 'crime', 'take', 'kwik_e', 'mart', 'security', 'camera']\n",
            "['oh', 'oh', 'krusty']\n",
            "['know', 'look', 'bad', 'honey', 'know', 'maybe', 'turn', 'innocent']\n",
            "['earth', 'marge', 'earth', 'marge', 'clown', 'g', 'l', 'l', 't', 'y']\n",
            "['good', 'evening', 'springfield', 'krusty_clown', 'beloved', 'idol', 'countless', 'tot', 'common', 'alleged', 'criminal', 'trial', 'begin', 'tomorrow', 'take', 'center', 'ring', 'national', 'media', 'circus', 'child', 'age', 'eighty', 'hang', 'new', 'development', 'like', 'rumanian', 'trapeze', 'artist']\n",
            "['humble', 'beginning', 'street', 'mime', 'tupelo', 'mississippi']\n",
            "['krusty_clown', 'way', 'personal', 'mini', 'empire']\n",
            "['dozen', 'endorsement', 'include', 'line', 'pork', 'product', 'lead', 'television', 'good', 'loved', 'bloopers', 'krusty', 'near', 'fatal', 'air', 'heart', 'attack']\n",
            "['sorry', 'son', 'understand', 'day']\n",
            "['great', 'itchy_scratchy', 'cartoon', 'kid', 'get', 'come', 'right', 'get', 'hankerin', \"'\", 'pork', 'product']\n",
            "['mmmm', 'look', 'plump', 'succulent', 'sausage', 'honey', 'smoke', 'bacon', 'glisten', 'sizzling']\n",
            "['quick', 'triple', 'bypass', 'pacemaker', 'later', 'krusty', 'bounce', 'change', 'clown', 'condemn', 'parent', 'educator', 'alike', 'simple', 'minded', 'tv', 'mayhem']\n",
            "['new', 'krusty', 'devote', 'small', 'portion', 'stamp', 'illiteracy', 'today', 'thrill', 'youth']\n",
            "['hoot', 'read', 'book']\n",
            "['krusty', 'arrest', 'send', 'shock', 'wave', 'springfield', 'pack', 'church', 'synagogue', 'mosque', 'disillusioned', 'citizenry', 'walk', 'life']\n",
            "['urge', 'halfway', 'decent', 'member', 'community', 'gather', 'merchandise', 'bear', 'likeness', 'krusty_clown', 'prince', 'corruption', 'join', 'public', 'burning']\n",
            "['krusty_clown', 'trade', 'baggy', 'pant', 'relatively', 'snug', 'uniform', 'springfield', 'penitentiary', 'find', 'tomorrow', 'trial', 'begin']\n",
            "['kind', 'gun', 'use']\n",
            "['look', 'clothe', 'drab']\n",
            "['face', 'flesh', 'colored', 'sad']\n",
            "['client', 'comment', 'time']\n",
            "['krusty_clown', 'plead']\n",
            "['plead', 'guilty', 'honor']\n",
            "['uh', 'mean', 'guilty', 'opening', 'night', 'jitter', 'honor']\n",
            "['like', 'stand', 'homer', 'j', 'simpson']\n",
            "['innocent', 'tell', 'krusty', 'like', 'ah', 'come', 'dad', 'get_to', 'listen']\n",
            "['mr_simpson', 'take', 'cowardly', 'dive', 'display', 'heavily', 'salted', 'snack', 'treat']\n",
            "['hmmm', 'hmmm', 'recognize', 'gunman', 'courtroom', 'today']\n",
            "['let', 'record', 'witness', 'eventually', 'point', 'krusty_clown']\n",
            "['toy', 'adorable', 'guess', 'inspire', 'insane', 'criminal', 'genius']\n",
            "['dad', 'give', 'mob', 'mentality']\n",
            "['hop', 'bandwagon', 'come', 'son', 'win', 'team']\n",
            "['hey', 'right', 'krusty', 'souvenir', 'buy', '-PRON-', 'burn', '-PRON-', 'right']\n",
            "['good', 'people', 'happy', 'tonight', 'word', 'caution', 'go', 'set', 'pile', 'evil', 'ablaze', 'child', 'toy', 'fire', 'spread', 'quickly', 'stand', 'try', 'inhale', 'toxic', 'fume']\n",
            "['krusty', 'turn', 'attention', 'exhibit', 'b', 'tell']\n",
            "['read', 'write', 'admit', 'totally', 'illiterate', 'happy']\n",
            "['champion', 'child', 'literacy', 'read']\n",
            "['yeah', 'al', 'koholic']\n",
            "['right', 'right', 'krusty', \"'\", 'b', \"'\", 'exhibit', 'b', 'betting', 'slip', 'obtain', 'court', 'indicate', 'lose', 'substantial', 'sum', 'money', 'sport', 'gambling']\n",
            "['crime', 'bet', 'sport', 'event']\n",
            "['foreperson', 'reach', 'verdict']\n",
            "['yes', 'honor', 'find', 'defendant', 'krusty_clown', 'guilty']\n",
            "['know', 'happen', 'time']\n",
            "['young', 'friend', 'year', 'silent', 'save', 'crude', 'glissandos', 'primitive', 'wind', 'instrument', 'destiny', 'thrust', 'center', 'ring', 'come', 'week', 'notice', 'sweeping', 'change', 'program', 'alarm', 'itchy_scratchy', 'home', 'learn', 'nutrition', 'self', 'esteem', 'etiquette', 'lively', 'art']\n",
            "['watch', 'sideshow_bob', 'know', 'lot', 'patronizing', 'krusty']\n",
            "['snap', 'bart', 'face', 'fact', 'hour', 'spend', 'stare', 'krusty', 'stare', 'crook']\n",
            "['look', 'lisa', 'know', 'krusty', 'innocent', 'ask', 'feeling']\n",
            "['come', 'lisa', 'think', 'prove', 'krusty', 'innocent', 'need', 'help']\n",
            "['oh', 'come', 'lis', 'know']\n",
            "['forgive', 'make', 'smart']\n",
            "['okay', 'okay', 'try', 'funny', 'armed', 'tooth']\n",
            "['come', 'bart', 'tape', 'show', 'robber', 'heat', 'burrito']\n",
            "['remember', 'card', 'send', 'krusty', 'heart', 'attack', 'pacemaker']\n",
            "['wait_minute', 'krusty', 'read']\n",
            "['okay', 'okay', 'poor', 'guy', 'read']\n",
            "['bart', 'krusty', 'read', 'magazine', 'read']\n",
            "['hey', 'hey', 'lending', 'library', 'go', 'buy', 'thing', 'blow', 'head']\n",
            "['bart', 'start', 'think', 'right', 'krusty', 'frame', 'enemy']\n",
            "['know', 'know', 'krusty', 'good_friend', 'world', 'sideshow_bob']\n",
            "['volley', 'musketry', 'flame', 'thunder', 'roar', 'profound', 'silence', 'follow', 'break', 'approach', 'footstep', 'brigade']\n",
            "['week', 'chapter', 'thirty', 'man', 'iron', 'mask', 'death', 'titan']\n",
            "['kid', 'day', 'word', 'mr', 'cole', 'porter']\n",
            "['time', 'goodbye', 'die', 'little', 'time', 'goodbye', 'wonder', 'little', 'time', 'goodbye', 'goodbye']\n",
            "['great', 'sideshow', 'switchboard', 'jam', 'kid', 'love']\n",
            "['thank', 'te', 'glad', 'finally', 'dispel', 'myth', 'uptown', 'tot', 'help', 'think', 'poor', 'krusty']\n",
            "['face', 'key', 'chain']\n",
            "['water', 'action', 'pen']\n",
            "['snow', 'dome']\n",
            "['exciting', 'think', 'explore', 'upscale', 'market', 'instance', 'sideshow_bob', 'limited', 'edition', 'print', 'collector', 'plate', 'commemorative', 'coin']\n",
            "['kid', 'sideshow_bob', 'important']\n",
            "['ah', 'sign', 'contract', 'tomorrow']\n",
            "['certainly', 'great', 'pride', 'able', 'sign']\n",
            "['sideshow_bob', 'ask']\n",
            "['forgive', 'child', 'sideshow_bob', 'love', 'chat', 'start', 'moment', 'ticket', 'guest']\n",
            "['come', 'come', 'let', 'run']\n",
            "['hello', 'child', 'love']\n",
            "['come', 'bart', 'flow']\n",
            "['zillionth', 'love', 'krusty']\n",
            "['today', 'promise', 'marvelous', 'celebration', 'human', 'spirit', 'regret', 'youngster', 'look', 'troubled']\n",
            "['bart_simpson', 'sir']\n",
            "['mmm', 'shed', 'light', 'problem', 'new', 'segment', 'exploring', 'pre', 'adolescent', 'turmoil', 'choice']\n",
            "['mind', 'bart', 'bet', 'child', 'accept']\n",
            "['true', 'sideshow_bob', 'bother', 'sister', 'little', 'investigating', 'look', 'like', 'krusty', 'frame']\n",
            "['videotape', 'show', 'thief', 'microwave', 'oven', 'kwik_e', 'mart', 'krusty', 'near', 'thing', 'pacemaker']\n",
            "['know', 'bart', 'love', 'krusty', 'doctor', \"'\", 'order', 'seriously']\n",
            "['maybe', 'krusty', 'illiterate', 'guy', 'rob', 'store', 'read', 'springfield', 'review', 'book']\n",
            "['fact', 'able', 'read', 'enjoy', 'springfield']\n",
            "['review', 'book', 'look', 'amusing', 'caricature', 'gore', 'vidal', 'susan', 'sontag']\n",
            "['yeah', 'guess', 'kinda', 'funny']\n",
            "['bart', 'child', 'sordid', 'affair', 'shock', 'life', 'let', 'try', 'remember', 'krusty', 'hardened', 'criminal', 'lovable', 'jester', 'honk', 'horn', 'putter', 'little', 'car']\n",
            "['shoot', 'cannon', 'yes', 'forget', 'bart', 'open', 'heart', 'admit', 'mighty', 'big', 'shoe', 'fill', 'chance', 'promise', 'will', 'disap']\n",
            "['big', 'shoe', 'fill', 'big', 'shoe', 'fill', 'big', 'shoe', 'fill']\n",
            "['know', 'ancient', 'greece', 'school', 'thought', 'call', 'stoicist']\n",
            "['attention', 'fellow', 'child', 'krusty', 'rob', 'store', 'sideshow_bob', 'frame', 'get', 'proof']\n",
            "['krusty', 'wear', 'big', 'floppy', 'shoe', 'get', 'little', 'foot', 'like', 'good', 'hearted', 'people']\n",
            "['sideshow_bob', 'fill', 'shoe', 'big', 'ugly', 'foot']\n",
            "['duff', 'boy', 'studio']\n",
            "['yes', 'admit', 'hate', 'hackneyed', 'shenanigan', 'rob', 'dignity', 'year', 'play', 'buffoon', 'squander', 'fortune', 'vulgar', 'appetite', 'frame', 'krusty', 'get', 'away', 'meddle', 'kid']\n",
            "['treat', 'kid', 'equal', 'people', 'smart', 'think', 'smart', 'catch']\n",
            "['krusty', 'man', 'admit', 'wrong', 'sorry', 'finger', 'court', 'sincerely', 'hope', 'horrible', 'story', 'hear', 'go', 'prison', 'exaggerated']\n",
            "['important_thing', 'regain', 'trust', 'child', 'boy', 'trust', 'bart']\n",
            "['pie', 'sky', 'bill', 'pie', 'kbbl', 'traffic', 'copter', 'come', 'bill']\n",
            "['bad_news', 'driver', 'overturn', 'melon', 'truck', 'interstate', 'oh', 'mess', 'lot', 'rubbernecking', 'melon', 'rustle', 'go', 'expect', 'delay', 'hour']\n",
            "['hey', 'cool', 'jet', 'man', \"comin_'\"]\n",
            "['forgot', 'special', 'lunch']\n",
            "['bill', 'pie', 'pie', 'sky', 'say', 'goodbye']\n",
            "['k', 'b', 'b', 'l', 'k', 'babble', 'talk', 'hour', 'day', 'like', 'share', 'embarrassing', 'problem', 'listening', 'audience', 'invite', 'therapist', 'airwaves', 'dr', 'marvin', 'monroe', 'number', 'pain']\n",
            "['hello', 'like', 'talk', 'dr', 'monroe']\n",
            "['marge', 'thirty', 'problem', 'husband', 'listen', 'appreciate', 'know']\n",
            "['hey', 'lady', 'save', 'whining', 'air', 'okay']\n",
            "['marge', 'thirty', 'trap', 'loveless', 'sham', 'marriage']\n",
            "['hey', 'turn', 'love', 'hear', 'whack', 'os']\n",
            "['tell', 'husband', 'marge']\n",
            "['date', 'sweet', 'romantic', 'pound', 'thin', 'hair', 'eat', 'utensil']\n",
            "['hey', 'wife', 'homer']\n",
            "['ridiculous', 'wife', 'worship', 'ground', 'walk']\n",
            "['marge', 'harsh', 'reality', 'time']\n",
            "['oh', 'okay', 'thank']\n",
            "['hang', 'pig', 'mother', 'hot', 'love', 'object', 'deserve']\n",
            "['sure', 'sure', 'voice', 'annoy', 'marge', 'tonight', 'second', 'come', 'door', 'get', 'tell', 'feed', 'start', 'love', 'leave']\n",
            "['tell', 'right', 'come', 'home', 'work']\n",
            "['oh', 'come', 'bart']\n",
            "['aw', 'sense', 'humor']\n",
            "['phone', 'al', 'al', 'koholic', 'al', 'koholic']\n",
            "['wait_minute', 'listen', 'little', 'yellow', 'belly', 'rat', 'jackass', 'find', 'kill', 'ya']\n",
            "['hope', 'find', 'punk', 'someday', 'moe', 'fill', \"'\", 'er']\n",
            "['okay', 'homer', 'usually', 'quick', 'peanut', 'hunka', 'beef', 'jerky', 'couple', 'pickle', 'egg', 'outta']\n",
            "['let', 'feel', 'like', 'go', 'home', 'tonight', 'jar']\n",
            "['hey', 'level', 'get', 'domestic', 'situation']\n",
            "['wife', 'go_to', 'leave', 'because', 'think', 'pig']\n",
            "['marge', 'right', 'pig', 'ask', 'bar']\n",
            "['hey', 'barney', 'pig']\n",
            "['pig', 'barney', 'pig', 'larry', 'pig', 'pig', 'difference', 'crawl', 'slop', 'hose', 'act', 'like', 'human', 'being', 'homer', 'buy', 'wife', 'flower', 'night', 'town', 'candle', 'tablecloth', 'yard']\n",
            "['gee', 'romantic', 'evening', 'nah', 'smart', 'fall']\n",
            "['dinner', 'go', 'check', 'fancy', 'motel', 'town', 'check', 'morning', 'drift']\n",
            "['read', 'loud', 'clear']\n",
            "['wow', 'quarter', 'past', 'keep', 'dad']\n",
            "['yeah', 'possibly', 'late', 'meat', 'loaf', 'night']\n",
            "['uh', 'like', 'flower']\n",
            "['uh', 'know', 'pretty', 'one', 'like']\n",
            "['beautiful', 'long', 'stem', 'rose', 'dollar', 'dozen']\n",
            "['pig', 'mother', 'mother', 'mother']\n",
            "['hot', 'love', 'object', 'deserve', 'deserve', 'deserve', 'deserve']\n",
            "['start', 'love', 'leave', 'leave', 'leave']\n",
            "['little', 'pre', 'dinner', 'entertainment']\n",
            "['oliver', 'klozoff', 'oliver', 'klozoff']\n",
            "['reservation', 'chez', 'paree']\n",
            "['matter', 'mon', 'frere', 'dessert', 'adjourn', 'second', 'floor', 'room', 'ramp', 'inn']\n",
            "['oh', 'oh', 'homer', 'feel', 'giddy', 'wait', 'babysitter']\n",
            "['listen', 'lousy', 'bum', 'hold', 'swear', 'cut', 'belly', 'open']\n",
            "['goodness', 'cross', 'wire']\n",
            "['rubber', 'baby', 'buggy', 'bumper', 'babysitte', 'service']\n",
            "['marge', 'simpson', 'like', 'babysitter', 'evening']\n",
            "['wait_minute', 'simpson']\n",
            "['lady', 'get_to', 'kid']\n",
            "['hello', 'mr', 'sampson']\n",
            "['wife', 'second', 'ago']\n",
            "['say', 'sampson', 'simpson']\n",
            "['thank_god', 'simpson', 'bunch', 'savage', 'especially', 'big', 'ape', 'father']\n",
            "['mom', 'look', 'glamorous']\n",
            "['tonight', 'special', 'night', 'father', 'take', 'dinner', 'dancing']\n",
            "['ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba']\n",
            "['ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba_ba', 'ba_ba']\n",
            "['work', 'body', 'homer']\n",
            "['know', 'day', 'learn', 'like', 'old_man']\n",
            "['son', 'woman', 'alive', 'resist', 'man', 'know', 'mambo']\n",
            "['precious', 'think', 'hear', 'doorbell']\n",
            "['think', 'right', 'dumplin', \"'\"]\n",
            "['aye', 'aye', 'mambo', 'man']\n",
            "['yes', 'ms', 'botz']\n",
            "['stand', 'boy', 'help', 'miss', 'botz', 'suitcase']\n",
            "['thank', 'come', 'short', 'notice', 'ms', 'botz']\n",
            "['phone', 'number', 'restaurant', 'dine', 'motel', 'spend', 'night', 'maggie', 'bed', 'bart', 'lisa', 'stay', 'hour', 'watch', 'tape', 'video', 'library']\n",
            "['oh', 'boy', 'happy', 'little', 'elf', 'meet', 'curious', 'bear', 'cub']\n",
            "['oh', 'elve', 'elf']\n",
            "['bye', 'kid', 'watch', 'boy']\n",
            "[\"'\", 'bye', 'good', 'get_to']\n",
            "['come', 'child', 'let', 'watch', 'happy', 'little', 'elf']\n",
            "['look', 'lady', 'see', 'crappy', 'little', 'elf', 'fourteen', 'billion', 'time', 'maybe', 'watch', 'real', 'tv']\n",
            "['say', 'go_to', 'watch', 'tape']\n",
            "['awww', 'merely', 'suggest', 'view', 'matter', 'lady', 'mom', 'let', 'watch', 'hell', 'want']\n",
            "['say', 'go_to', 'watch', 'tape', 'go_to', 'go_to', 'know', 'everybody']\n",
            "['look', 'tasty', 'think', 'eat', 'right']\n",
            "['pick', 'little', 'frisky', 'sir']\n",
            "['choose', 'float', 'upside', 'somewhat', 'defeat', 'purpose', 'select', 'live', 'lobster']\n",
            "['oh', 'okay', 'beady', 'eye']\n",
            "['excellent', 'choice', 'sir', 'lead', 'table']\n",
            "['oui', 'oui', 'see', 'later']\n",
            "['get', 'save', 'bubble']\n",
            "['oh', 'man', 'anymore']\n",
            "['know', 'happen', 'find', 'captain', 'kook', 'treasure', 'elf', 'dance', 'like', 'little', 'green', 'idiot', 'puke', 'end']\n",
            "['bart', 'like', 'chilly', 'elf', 'love']\n",
            "['right', 'america', 'armed', 'dangerous']\n",
            "['oh', 'bart', 'nightmare']\n",
            "['relax', 'cinema', 'verite', 'brutal', 'slow', 'motion', 'killing', 'start', 'tell', 'shut', 'eye']\n",
            "['cue', 'ball', 'killer', 'consider', 'extremely', 'armed', 'dangerous', 'think', 'see', 'u', 'squeal']\n",
            "['homer', 'look', 'like', 'little', 'boy']\n",
            "['ooop', 'time', 'fill', 'gar', 'bottle', 'second', 'expensive', 'champagne']\n",
            "['defenseless', 'youngster', 'tie', 'gag', 'living', 'room', 'bandit', 'roam', 'house', 'steal', 'valuable', 'object', 'take', 'family', 'lifetime', 'shop']\n",
            "['know', 'marge', 'like', 'date']\n",
            "['babysitter', 'bandit', 'leave', 'trail', 'daring', 'nighttime', 'robbery', 'continental', 'united_states', 'lurk', 'descend', 'house', 'unsuspecting', 'dupe']\n",
            "['moment', 'picture', 'real', 'babysitter', 'bandit', 'miss', 'lucille', 'botzucowski', 'remember', 'clever', 'alia']\n",
            "['consider', 'armed', 'dangerous']\n",
            "['forget', 'tell', 'ramp']\n",
            "['bart', 'bart', 'bart', 'bart', 'hmm', 'time', 'brush', 'tooth', 'wash', 'face', 'prayer']\n",
            "['oh', 'homemade', 'pickle', 'beet']\n",
            "['thing', 'hurt', 'think', 'silly', 'dwell']\n",
            "['hello', 'vigilant', 'viewer', 'reach', 'america', 'armed', 'dangerous']\n",
            "['call', 'report', 'babysitter', 'bandit', 'house', 'right']\n",
            "['come', 'marge', 'let', 'carry', 'threshold']\n",
            "['okay', 'watch', 'slam', 'head', 'like', 'time']\n",
            "['sheesh', 'year_ago', 'forget']\n",
            "['know', 'ms', 'botz', 'ms', 'botzucowski', 'babysitter', 'bandit']\n",
            "['smart', 'young_man', 'bart', 'hope', 'smart', 'mouth', 'shut']\n",
            "['crazy', 'think', 'go_to', 'away', 'lady']\n",
            "['bad', 'person', 'finish', 'guy', 'watch', 'rest', 'favorite', 'video', 'casette']\n",
            "['quiet', 'bart', 'let', 'good']\n",
            "['maybe', 'slip', 'little', 'comfortable']\n",
            "['ooh', 'blue', 'thing', 'thing']\n",
            "['shake', 'leg', 'mama']\n",
            "['kid', 'stuff', 'hardly', 'worth', 'lotta', 'junk', 'soil', 'stupid', 'sampson']\n",
            "['maggie', 'wanna', 'watch', 'happy', 'little', 'elf']\n",
            "['oh', 'get', 'crib', 'guess', 'need', 'tie']\n",
            "['homer', 'spoil', 'mood', 'call', 'home', 'know', 'check', 'kid']\n",
            "['homer', 'wake', 'answer', 'home']\n",
            "['worried', 'think', 'home']\n",
            "['right', 'suppose', 'work']\n",
            "['hello', 'vigilant', 'viewer', 'help']\n",
            "['catch', 'catch', 'babysitter', 'bandit', 'tie', 'house', 'right']\n",
            "['reward', 'convict', 't_shirt']\n",
            "['ms', 'botz', 'ms', 'botz']\n",
            "['good_lord', 'little', 'hellion']\n",
            "['oh', 'thing', 'heavy']\n",
            "['hard', 'feeling', 'double', 'pay', 'triple']\n",
            "['mr', 'sampson', 'bit', 'advice']\n",
            "['turn', 'boy', 'second']\n",
            "['be', 'truth', 'know', 'time']\n",
            "['way', 'scene', 'crime', 'man', 'get', 'tie', 'den']\n",
            "['minute', 'young_man', 'know', 'kind', 'shenanigan', 'pull', 'time', 'untie', 'babysitter', 'pay']\n",
            "['excuse', 'sir', 'say', 'world', 'aid', 'abet', 'escape', 'notorious', 'babysitter', 'bandit']\n",
            "['uh', 'uh', 'sure', 'microphone', 'work', 'uh', 'aid', 'right', 'actually', 'struggle']\n",
            "['see', 'kung', 'fu', 'movie', 'like', 'know', 'move', 'listen', 'lady', 'better', 'think', 'long', 'hard', 'try', 'like', 'homer_simpson']\n",
            "['lord', 'help', 'bright']\n",
            "['oh', 'homer', 'way', 'raise', 'child', 'knock', 'hog', 'tie', 'perfect', 'stranger', 'right']\n",
            "['interruption', 'martin', 'book', 'report']\n",
            "['kill', 'fish', 'see', 'great', 'noble', 'thing', 'brother']\n",
            "['come', 'kill', 'care', 'kill']\n",
            "['catch', 'fish', 'kill', 'bull', 'love', 'woman', 'live', 'thank']\n",
            "['little', 'ketchup', 'bun', 'papa']\n",
            "['ready', 'ha', 'question', 'fellow', 'student', 'prepare', 'dazzle', 'mrs_krabappel', 'mention', 'book', 'read', 'treasure', 'island']\n",
            "['pirate', 'pirate', 'patch', 'eye', 'shiny', 'gold', 'tooth', 'green', 'bird', 'shoulder']\n",
            "['mention', 'book', 'write', 'guy', 'name', 'robert', 'louis', 'stevenson', 'publish', 'good', 'people', 'mcgraw', 'hill']\n",
            "['conclusion', 'simpson', \"'\", 'scale', 'high', 'low', 'average', 'book']\n",
            "['mrs_krabappel', 'insult', 'book', 'report', 'witch', 'hunt']\n",
            "['blackbeard', 'captain', 'nemo', 'captain', 'hook', 'long', 'john', 'silver', 'peg', 'leg', 'pete', 'bluebeard']\n",
            "['blah_blah', 'blah_blah', 'blah_blah', 'blah_blah', 'blah']\n",
            "['uhhh', 'straighten', 'fly', 'right']\n",
            "['whoa', 'granny', 'oh', 'hide', 'closet', 'oh', 'deadly', 'mothball']\n",
            "['ooo', 'granny', 'kill']\n",
            "['reach', 'level', 'ungrateful', 'grandchild', 'try', 'dare', 'heh_heh', 'heh']\n",
            "['heh_heh', 'heh', 'couple', 'game', 'hit', 'book']\n",
            "['soup', 'hurry', 'icky', 'skin']\n",
            "['eww', 'hate', 'icky', 'soup', 'skin']\n",
            "['okay', 'right', 'dinner', 'business']\n",
            "['mmmm', 'marge', 'beer']\n",
            "['second', 'homer', 'lisa', 'good', 'news']\n",
            "['sure', 'want', 'beer', 'care', 'marge']\n",
            "['homer', 'ahead', 'lisa']\n",
            "['okay', 'get', 'vocabulary', 'test']\n",
            "['oh', 'glorious', 'day', 'lisa', 'hand', 'paper']\n",
            "['go_to', 'refrigerator', 'hmmm', 'long', 'kill', 'bird', 'stone']\n",
            "['big', 'idea', 'cover', 'paper']\n",
            "['look', 'funny', 'little', 'whisker', 'oooo', 'remind', 'big', 'gorilla', 'week', 'million_dollar', 'movie', \"c'mon\", 'boy']\n",
            "['oooh', 'gorilla', 'conqueror', 'granddaddy']\n",
            "['ah', 'maybe', 'hour']\n",
            "['time', 'hit', 'book']\n",
            "['burn', 'candle', 'end', 'eh', 'boy', '-PRON-']\n",
            "['right', 'okay', 'let', 'care', 'business', 'chapter', 'dream', 'freedom', 'september', 'fifteenth', 'sixteen', 'puritan', 'separatist', 'church', 'england', 'live', 'holland', 'leave', 'plymouth', 'england', 'destination']\n",
            "['psst', 'marge', 'come', 'look']\n",
            "['oh', 'little', 'tiger', 'try', 'hard', 'fail']\n",
            "['little', 'dim', 'guess']\n",
            "['bart', 'honey', 'go', 'miss', 'bus']\n",
            "['hey', 'bart', 'dude', 'whoa', 'look', 'freak']\n",
            "['hey', 'otto', 'man', 'get', 'big', 'test', 'ready', 'crash', 'bus']\n",
            "['oh', 'sorry', 'little', 'buddy', 'purpose', 'hey', 'maybe', 'lucky']\n",
            "['okay', 'reason', 'panic', 'find', 'egghead', 'pump', 'answer', 'boom', 'easy', 'street']\n",
            "['look', 'bet', 'study']\n",
            "['go_to', 'try', 'kiss', 'answer']\n",
            "['good_morning', 'girl']\n",
            "['good_morning', 'bart']\n",
            "['little', 'cram', 'session', 'pilgrim', 'boat']\n",
            "['spirit', 'st', 'louis']\n",
            "['cool', 'history', 'come', 'alive']\n",
            "['natural', 'enemy', 'know', 'care', 'information', 'pertain', 'america', 'colonial', 'period', 'receive', 'erroneous']\n",
            "['blindfolded', 'chimp', 'pencil', 'tooth', 'well', 'chance', 'pass', 'test']\n",
            "['thank', 'pep', 'talk']\n",
            "['sharp', 'stabbing', 'pain', 'stomach']\n",
            "['oh', 'dear', 'hear']\n",
            "['feel', 'shoot', 'pain', 'arm']\n",
            "['temporary', 'loss', 'vision']\n",
            "['say', 'come', 'closer']\n",
            "['uh', 'maybe', 'uh', 'dish', 'double', 'cappuccino', 'chocolate', 'fudge']\n",
            "['oooh', 'bowl', 'think', 'mend']\n",
            "['bring', 'television', 'bart', 'get', 'vision']\n",
            "['wish', 'amoria', 'phlebitis']\n",
            "['know', 'fake', 'bart']\n",
            "['better', 'mouth', 'shut']\n",
            "['go_to', 'fail', 'history', 'test', 'sooner', 'later']\n",
            "['get', 'basis', 'cover']\n",
            "['hey', 'milhouse', 'miss', 'school', 'today']\n",
            "['lewis', 'richard', 'laugh', 'milk', 'nose']\n",
            "['oh', 'history', 'test', 'huh', 'piece', 'cake', 'huh', 'listen', 'number', 'uh_huh', 'number', 'oh', 'yeah', 'sound', 'right']\n",
            "['mrs_krabappel', 'think', 'pleasantly', 'surprised']\n",
            "['hey', 'dr', 'j']\n",
            "['think', 'hand', 'classic', 'case', 'layman', 'refer', 'fear', 'failure', 'result', 'bart', 'underachiever', 'proud']\n",
            "['problem', 'short', 'attention', 'span', 'lead']\n",
            "['blah_blah', 'blah_blah', 'blah_blah', 'blah']\n",
            "['student', 'class', 'show', 'form', 'improvement', 'continue', 'struggle']\n",
            "['okay', 'okay', 'dance', 'obvious', 'know', 'know', 'dumb', 'okay', 'dumb', 'post', 'think', 'happy']\n",
            "['bart', 'late', 'bloomer']\n",
            "['oh', 'wish', 'simple', 'shameful', 'emotionally', 'crippling', 'afraid', 'recommendation', 'bart_simpson', 'repeat', 'fourth_grade']\n",
            "['hold', 'well', 'promise']\n",
            "['maybe', 'help', 'leave', 'will', 'bad', 'bart']\n",
            "['mean', 'hold', 'swear', 'go_to', 'well', 'look', 'eye', 'sincerity', 'conviction', 'fear', 'god', 'witness', 'pass', 'fourth_grade']\n",
            "['bus', 'forever', 'hold', 'peace', 'little', 'dude']\n",
            "['otto', 'know', 'respect', 'mean', 'let', 'throw', 'stuff', 'car', 'try', 'tip', 'bus', 'sharp', 'turn']\n",
            "['damn', 'thing', 'go']\n",
            "['head', 'little', 'man']\n",
            "['fail', 'lot', 'test', 'recently']\n",
            "['talk', 'hold', 'fourth_grade', 'shape']\n",
            "['hey', 'relax', 'man', 'end', 'good', 'thing', 'happen', 'get', 'hold', 'fourth_grade', 'twice', 'look', 'man', 'drive', 'school', 'bus']\n",
            "['afraid', 'recommendation', 'bart_simpson', 'repeat', 'fourth_grade', 'repeat', 'fourth_grade', 'repeat', 'fourth_grade', 'repeat', 'fourth_grade']\n",
            "['look', 'lady', 'get', 'peptic', 'ulcer', 'wife', 'hock', 'new', 'car', 'need', 'root', 'canal', 'quit', 'bug', 'stupid', 'pirate']\n",
            "['long', 'john', 'silver', 'dad']\n",
            "['thank', 'lot', 'son']\n",
            "['yo', 'little', 'help']\n",
            "['say', 'little', 'help', 'throw', 'ball', 'poindexter']\n",
            "['oh', 'sorry', 'bart', 'unfamiliar', 'rule', 'sport', 'want', 'interfere', 'ball', 'play']\n",
            "['hm', 'hey', 'martin']\n",
            "['hair', 'look', 'look']\n",
            "['need', 'help', 'pass', 'grade']\n",
            "['need', 'help', 'pass', 'grade', 'know']\n",
            "['laugh', 'consider', 'popular']\n",
            "['speed', 'number', 'year', 'service', 'hall', 'monitor', 'prize', 'win', 'diaramas', 'thing', 'mean']\n",
            "['righty', 'let', 'look', 'study', 'area']\n",
            "['yes', 'sanctuary', 'hurly', 'burly', 'modern', 'life']\n",
            "['oh', 'will', 'go_to', 'clean', 'room', 'clearly', 'need', 'fern', 'study', 'area', 'complete', 'adequate', 'plant', 'life']\n",
            "['geek', 'sit', 'seat', 'sit', 'row', 'bus', 'go', 'school', 'church']\n",
            "['oooh', 'think', 'understand', 'potential', 'mischief', 'vary', 'inversely', 'proximity', 'authority', 'figure']\n",
            "['pretty', 'soon', 'ready', 'try', 'real', 'book']\n",
            "['hold', 'truth', 'self', 'evident', 'hold', 'truth', 'self', 'evident']\n",
            "['think', 'push', 'boy', 'girl', \"'\", 'lavatory', 'thrill', 'scream', 'humiliation', 'fact', 'feel', 'alive']\n",
            "['great', 'martin', 'big', 'test', 'tomorrow', 'start', 'study']\n",
            "['care', 'test', 'life', 'short', 'test']\n",
            "['hey', 'think', 'deal']\n",
            "['martin', 'prince', 'deal', 'longer', 'exist', 'come', 'fellow', 'arcade']\n",
            "['bart', 'past', 'bedtime']\n",
            "['old', 'timer', 'guess', 'end', 'road', 'know', 'good', 'kid', 'school', 'tomorrow', 'fail', 'test', 'hold', 'need', 'day', 'study', 'lord', 'need', 'help']\n",
            "['prayer', 'refuge', 'scoundrel']\n",
            "['teacher', 'strike', 'power', 'failure', 'blizzard', 'cancel', 'school', 'tomorrow', 'know', 'ask', 'lot', 'thank', 'advance', 'pal', 'bart_simpson']\n",
            "['wake', 'bart', 'rise', 'shine', 'little', 'guy', 'time', 'wake']\n",
            "['wake', 'look', 'snow']\n",
            "['huh', 'whoa', 'good_morning', 'world']\n",
            "['rise', 'shine', 'springfield', 'resident', 'bill', 'marty', 'bill']\n",
            "['look', 'like', 'get', 'snowformation', 'flake', 'lover']\n",
            "['springfield', 'electric', 'gas', 'water', 'plant', 'closed', 'day']\n",
            "['oh', 'forget', 'nuclear_power', 'plant', 'bill', 'close']\n",
            "['whoo', 'hoo', 'right']\n",
            "['meet', 'alley', 'minute', 'come']\n",
            "['youngster', 'toddler', 'wait', 'springfield', 'county', 'school', 'read', 'excited']\n",
            "['oh', 'oh', 'springfield', 'county', 'school', 'close']\n",
            "['remember', 'break', 'arm', 'numb']\n",
            "['hear', 'night', 'bart', 'pray', 'prayer', 'answer', 'theologian', 'know', 'god', 'exactly', 'know', 'force', 'powerful', 'mom_dad', 'owe', 'big']\n",
            "['right', 'ask', 'miracle', 'get', 'get_to', 'study', 'man']\n",
            "[\"missin'anythe\", 'frozen', 'earlobe', 'trudge', 'stupid', 'sled', 'hill', 'good']\n",
            "['get', 'ya', 'burnsie']\n",
            "['young', 'ragamuffin', 'away', 'snowball', 'fight', 'smither', 'fire']\n",
            "['declare', 'day', 'snow', 'day', 'funn', 'day', 'history', 'springfield']\n",
            "['sleigh', 'bell', 'ring', 'listenin', \"'\", 'sleigh', 'bell', 'ring', 'listenin']\n",
            "['lane', 'snow', 'glistenin', \"'\"]\n",
            "['beautiful', 'sight', 'happy', 'tonight', 'walkin', \"'\", 'winter', 'wonderland']\n",
            "['go', 'away', 'bluebird', 'stay', 'go', 'away', 'bluebird', 'stay']\n",
            "['get_to', 'study', 'get_to', 'study', 'get_to', 'study']\n",
            "['chapter', 'day', 'philadelphia', 'continental', 'congress', 'face', 'difficult', 'job', 'delegate', 'agree', 'recommendation', 'americans', 'support', 'chapter', 'day', 'philadelphia', 'continental', 'congress', 'face', 'difficult', 'job', 'delegate', 'agree', 'recommendation', 'americans', 'support']\n",
            "['man', 'create', 'equal']\n",
            "['equal', 'creation', 'derive', 'right', 'inherent', 'inalienable']\n",
            "['hey', 'look', 'everybody', 'snow']\n",
            "['fella', 'invent', 'fun', 'sled']\n",
            "['hey', 'look', 'everybody', 'john', 'hancock', 'write', 'snow']\n",
            "['want', 'hold', 'grade', 'concentrate', 'man']\n",
            "['later', 'mrs', 'k']\n",
            "['understand', 'try', 'time', 'try']\n",
            "['kid', 'failure', 'oh', 'know', 'george', 'washington', 'feel', 'surrender', 'fort', 'necessity', 'french']\n",
            "['oh', 'know', 'famous', 'defeat', 'french']\n",
            "['dear', 'god', 'bald', 'guy', 'break', 'amen']\n",
            "['pass', 'get', 'd', 'minus', 'pass', 'right']\n",
            "['pass', 'pass', 'pass', 'pass', 'get', 'd', 'minus', 'pass', 'get', 'd', 'minus', 'pass', 'get', 'd', 'minus', 'pass', 'pass', 'kiss', 'teacher', 'peh', 'peh', 'peh', 'peh']\n",
            "['thanks', 'dad', 'd', 'minus', 'belong', 'god']\n",
            "['okay', 'capital', 'north', 'dakota', 'name', 'german', 'ruler']\n",
            "['hitler', 'north', 'dakota']\n",
            "['hey', 'beat', 'boy']\n",
            "['okay', 'color', 'italian', 'flag', 'red', 'white']\n",
            "['okay', 'right', 'grade', 'school', 'challenge', 'important', 'message']\n",
            "['think', 'lose', 'hair', 'inevitable', 'tide', 'find', 'dimoxinil', 'new', 'miracle', 'breakthrough', 'hair', 'regrowth']\n",
            "['miracle', 'breakthrough', 'miracle', 'breakthrough']\n",
            "['odd', 'dimoxinil', 'help', 'grow', 'little', 'hair', 'want', 'hey', 'today', 'go_to']\n",
            "['free', 'brochure', 'send', 'dollar', 'dimoxinil', 'hair', 'plaza', 'hair', 'city', 'utah']\n",
            "['hair', 'hair', 'like', 'everybody']\n",
            "['know', 'woman', 'find', 'bald', 'man', 'virile']\n",
            "['marge', 'listen', 'miracle', 'breakthrough', 'cheapo', 'sucker', 'deal']\n",
            "['allow', 'present', 'dimoxinil', 'action', 'set', 'entirety', 'month', 'supply', 'drug', 'gravity', 'boot', 'scalp', 'massager', 'tee', 'shirt']\n",
            "['great', 'great', 'great']\n",
            "['thousand', 'buck', 'afford']\n",
            "['hmmm', 'product', 'price', 'range', 'assure', 'hair', 'growth', 'experience', 'purely', 'coincidental']\n",
            "['thousand', 'buck', 'rip', 'screw', 'job', 'gyp', 'joint', 'forget', 'pal', 'thank']\n",
            "['forget', 'pal', 'thank', 'storm', 'right', 'outta']\n",
            "['ah', 'ha', 'tell', 'homer']\n",
            "['portion', 'hey', 'lenny', 'go_to', 'use', 'tartar', 'sauce', 'dry', 'fish', 'stick', 'suck']\n",
            "['quit', 'complain', 'chrome', 'dome']\n",
            "['homer', 'sap', 'life', 'fill', 'medical', 'insurance', 'form', 'creatively', 'charge', 'dimoxinil', 'stuff', 'company']\n",
            "['thousand', 'buck', 'burn', 'butt', 'time', 'flat']\n",
            "['ooooh', 'thousand', 'buck', 'mr_burns', 'ivory', 'scratcher']\n",
            "['yeah', 'pay', 'money', 'insurance', 'fund', 'week']\n",
            "['exactly', 'guy', 'lose', 'finger', 'hit', 'jackpot']\n",
            "['uh', 'like', 'charge', 'dimoxinil', 'stuff', 'health', 'insurance']\n",
            "['look', 'buddy', 'know', 'insurance', 'plan', 'state', 'cover', 'frivolous', 'dimoxinil']\n",
            "['good_morning', 'springfield', 'good_morning', 'mr', 'mrs', 'winfield']\n",
            "['good_morning', 'moe', 'tavern']\n",
            "['good_morning', 'everybody', 'good_morning', 'springfield']\n",
            "['homer_simpson', 'year', 'hey', 'get', 'rid', 'sideburn']\n",
            "['happy', 'work', 'girl', 'frisky', 'year']\n",
            "['daddy', 'home', 'sugar']\n",
            "['ah', 'dinner', 'beautiful', 'woman', 'heaven']\n",
            "['patty', 'stop', 'drool', 'huh']\n",
            "['hey', 'different', 'homer', 'lose', 'weight']\n",
            "['yeah', 'look', 'like', 'get', 'tan']\n",
            "['know', 'new', 'tie']\n",
            "['moron', 'pathetic', 'moron', 'employ', 'steal', 'precious', 'money', 'hopeless', 'cretin', 'deserve', 'promotion']\n",
            "['union', 'contract', 'sir', 'token', 'promotion', 'year']\n",
            "['wait', 'young', 'getter']\n",
            "['sort', 'look', 'like', 'homer_simpson', 'dynamic', 'resourceful']\n",
            "['simpson', 'eh', 'hmmm', 'unspoiled', 'lump', 'clay', 'mold', 'image', 'new', 'junior', 'executive', 'bring']\n",
            "['attention', 'homer_simpson', 'promote', 'executive', 'minute', 'goodbye', 'friend', 'report', 'room', 'reassignment', 'well', 'life']\n",
            "['resume', 'order', 'typing', 'stuff', 'qualification', 'know']\n",
            "['great', 'rub', 'harry', 'executive', 'let']\n",
            "['fine', 'thank', 'goodbye']\n",
            "['hello', 'homie', 'big', 'important', 'executive']\n",
            "['oh', 'marge', 'woman', 'n', 't', 'e', 'rview', 'secretary', 'job', 'make', 'kissy', 'face']\n",
            "['hello', 'mr_simpson', 'karl']\n",
            "['sound', 'good', 'hire']\n",
            "['simpson', 'm', 'e', 'eting', 'board', 'room', 'tomorrow', 'sit', 'mouth', 'shut', 'get']\n",
            "['yes', 'mr', 'smithers']\n",
            "['belong', 'fraud', 'phony', 'matter', 'time', 'find']\n",
            "['tell', 'way', 'slump', 'shoulder', 'way', 'talk', 'chest', 'way', 'smother', 'bargain', 'basement', 'lime', 'green', 'polyester', 'want', 'deserve', 'love', 'nature', 'great', 'miracle', 'ahead']\n",
            "['nature', 'great', 'miracle']\n",
            "['need', 'week', 'vacation', 'move', 'expense']\n",
            "['man', 'suit', 'feel', 'like', 'prince', 'cry', 'world', 'judge', 'love']\n",
            "['stand', 'naturally', 'mr_simpson', 'let', 'hang']\n",
            "['mom_dad', 'smooch']\n",
            "['get_to', 'run', 'marge', 'late']\n",
            "['happy', 'anniversary', 'homer']\n",
            "['worry', 'homie', 'year', 'excuse', 'remember', 'job']\n",
            "['happy', 'anniversary', 'mrs', 'homer_simpson', 'beautiful', 'yeah', 'beautiful']\n",
            "['yes', 'sir', 'hope', 'overstep', 'bound']\n",
            "['love', 'karl', 'marge']\n",
            "['issue', 'sir', 'low', 'productivity', 'record', 'high', 'worker', 'accident', 'rate']\n",
            "['round', 'layoff', 'wake', 'idiot']\n",
            "['caffeine', 'water', 'cooler']\n",
            "['idea', 'people', 'think', 'regurgitate', 'promote', 'touch', 'worker']\n",
            "['think', 'mean', 'sir']\n",
            "['improve', 'worker', 'situation']\n",
            "['sir', 'thing', 'problem', 'tuesday', 'cafeteria', 'serve', 'fish', 'stick']\n",
            "['fish', 'stick', 'blaze', 'talk']\n",
            "['sir', 'cut', 'head', 'fish', 'chop', 'rest', 'stick', 'season', 'bread', 'crumb']\n",
            "['know', 'fish', 'stick', 'point']\n",
            "['tiny', 'little', 'cup', 'tartar', 'sauce', 'dip', 'run']\n",
            "['stop', 'waste', 'time', 'simpson']\n",
            "['shut', 'smither', 'say', 'happy', 'worker', 'busy', 'worker', 'cent', 'worth', 'tartar', 'sauce', 'save', 'thousand', 'man', 'hour', 'labor', 'like', 'cut', 'jib', 'simpson', 'let', 'fool', 'tar', 'tar', 'sauce']\n",
            "['enjoy', 'tartar', 'sauce', 'boy', 'enjoy', 'plate', 'crowd', 'plenty', 'everybody']\n",
            "['hmmm', 'brilliant', 'imagine', 'simpson', 'sweeping', 'reform', 'pay', 'quickly']\n",
            "['know', 'sir', 'accident', 'decrease', 'exactly', 'number', 'simpson', 'know', 'suspect', 'cause', 'month', 'output', 'level', 'high', 'simpson', 'vacation']\n",
            "['dear', 'tired', 'old', 'smither', 'detect', 'note', 'jealousy']\n",
            "['time', 'simpson', 'key']\n",
            "['mr_simpson', 'sit', 'filthy', 'thing', 'second', 'longer', 'give', 'key']\n",
            "['stun', 'absolutely', 'stunning']\n",
            "['oh', 'hey', 'ho', 'man', 'know', 'watch', 'dumont', 'night', 'happen', 'catch', 'fascinating', 'documentary', 'rommel', 'desert', 'fox', 'man', 'thing']\n",
            "['sure', 'thing', 'mr_burns']\n",
            "['simpson', 'walk', 'hallway']\n",
            "['thousand_dollar', 'dimoxinil', 'brain', 'freeze', 'get', 'simpson']\n",
            "['homer', 'hair', 'care', 'product', 'new', 'wardrobe', 'save', 'rainy', 'day']\n",
            "['rainy', 'day', 'go_to', 'rainy', 'day', 'marge', 'cloud', 'simpson', 'sky', 'little_girl', 'want']\n",
            "['absence', 'mood', 'swing', 'stability', 'life']\n",
            "['yea', 'eh', 'pony']\n",
            "['want', 'weave', 'patent', 'simpson', 'magic', 'executive', 'short', 'speech', 'work', 'work', 'work', 'know']\n",
            "['uh', 'okay', 'hey']\n",
            "['excellent', 'set', 'task', 'simpson']\n",
            "['mr_burns', 'sad', 'duty', 'report', 'executive', 'bilk', 'company', 'insurance', 'plan', 'thousand_dollar']\n",
            "['blast', 'hide', 'hades', 'go', 'buy', 'ivory', 'scratcher']\n",
            "['charge', 'company', 'dimoxinil', 'baldness', 'cure']\n",
            "['thank', 'professor', 'science', 'know', 'dimoxinil', 'example', 'hooligan']\n",
            "['karl', 'got_to', 'help', 'mr_burns', 'want', 'speech', 'executive', 'want']\n",
            "['oh', 'think', 'drop', 'tell', 'fire']\n",
            "['company', 'look', 'kindly', 'thousand_dollar', 'worth', 'insurance', 'fraud', 'clean', 'desk', 'noon', 'simpson']\n",
            "['wait', 'mr', 'smithers', 'homer_simpson', 'innocent']\n",
            "['mr_simpson', 'unaware', 'impropriety', 'responsibility']\n",
            "['hey', 'care', 'guy', 'bald']\n",
            "['extraordinary', 'today', 'bear', 'good', 'soldier', 'live', 'grenade', 'threaten', 'commander', 'throw', 'bore', 'terrible', 'brunt']\n",
            "['thanks', 'karl', 'know']\n",
            "['bye', 'karl', 'go_to', 'miss']\n",
            "['bye', 'mr_simpson']\n",
            "['oh', 'mr_simpson', 'bring', 'umbrella', 'today']\n",
            "['hey', 'happenin', \"'\", 'hip', 'cat']\n",
            "['get_to', 'fake']\n",
            "['like', 'realsville', 'daddy', 'o']\n",
            "['dirty', 'trick', 'okay', 'go_to', 'kill', 'go_to', 'tell', 'thing', 'go_to', 'haunt', 'rest', 'day', 'ruin', 'father', 'cripple', 'family', 'baldness', 'hereditary']\n",
            "['thousand', 'buck', 'marge', 'squirrele', 'away', 'save', 'rainy', 'day', 'say', 'right', 'right', 'right']\n",
            "['dad', 'take', 'heroic', 'fashion']\n",
            "['get', 'big', 'speech', 'minute', 'simpson', 'huh', 'go_to', 'hang']\n",
            "['dear', 'mr_simpson', 'take', 'liberty', 'prepare', 'speech', 'enclose', 'number', 'card', 'big', 'word', 'spell', 'phon', 'et', 'ic', 'al', 'ly', 'god_bless', 'springfield', 'special', 'creature', 'obedient', 'servant', 'karl', 'good_luck', 'sir']\n",
            "['karl', 'sweet', 'voice', 'hear', 'inside', 'head']\n",
            "['come', 'goodbye', 'gal', 'typing', 'pool']\n",
            "['yeah', 'thank', 'speech', 'karl', 'look']\n",
            "['tartar', 'sauce', 'bathroom', 'key', 'dry', 'boss', 'hand', 'hair', 'believe']\n",
            "['mother', 'teach', 'kiss', 'fool']\n",
            "['fresh', 'insight', 'rise', 'young', 'star', 'nuclear', 'family', 'homer_simpson']\n",
            "['blaze', 'old', 'geezer', 'homer_simpson']\n",
            "['lot', 'think', 'crazy']\n",
            "['power_plant', 'hour', 'day', 'bloated', 'inventory', 'outmode', 'production', 'method', 'save', 'company', 'million_dollar', 'year', 'jiko', 'kanri', 'japanese', 'art', 'self', 'management', 'west', 'long', 'term', 'benefit', 'offset', 'time', 'cost', 'net', 'saving']\n",
            "['thousand', 'mean', 'lot', 'money']\n",
            "['mr_burns', \"'\", 'office', 'right']\n",
            "['dead', 'man', \"comin_'\"]\n",
            "['dash', 'young', 'junior', 'executive', 'hollow', 'mockery', 'morning', 'meeting', 'simpson', 'fire', 'spot', 'go']\n",
            "['simpson', 'old', 'think']\n",
            "['eighty', 'find', 'hard', 'believe', 'salad', 'day', 'crowning', 'glory', 'bright', 'shock', 'strawberry', 'blond', 'curl']\n",
            "['ooh', 'big', 'man', 'campus', 'senior', 'year', 'bald', 'pluck', 'chicken', 'simpson', 'know', 'sting', 'male', 'pattern', 'baldness', 'give', 'old', 'job']\n",
            "['oh', 'thank', 'thank', 'thank']\n",
            "['oh', 'better', 'hurry']\n",
            "['kid', 'stick', 'dead', 'end', 'job', 'kid', 'go_to', 'hate', 'cause', 'buy', 'stuff', 'promise', '-PRON-', 'go_to', 'love', 'cause', 'ugly', 'bald']\n",
            "['oh', 'homer', 'job', 'food', 'table', \"kids'll\"]\n",
            "['oh', 'homer', 'honey', 'come']\n",
            "['come', 'beautiful', 'beautiful', 'hope']\n",
            "['hello', 'know', 'halloween', 'strange', 'holiday', 'personally', 'understand', 'kid', 'worship', 'ghost', 'pretend', 'devil', 'thing', 't', 'v', 'completely', 'inappropriate', 'young', 'viewer', 'thing', 'like', 'follow', 'half', 'hour', 'bother', 'kid', 'tonight', 'totally', 'wash', 'hand', 'scary', 'sensitive', 'child', 'maybe', 'tuck', 'bed', 'early', 'tonight', 'instead', 'write', 'angry', 'letter', 'tomorrow', 'thank', 'attention']\n",
            "['oooo', 'haul', 'year', 'love', 'halloween']\n",
            "['wait_minute', 'let', 'kid']\n",
            "['policeman', 'end', 'phone', 'say', 'trace', 'come', 'floor', 'house', 'late', 'end', 'story']\n",
            "['yawn', 'hear', 'grade', 'scary']\n",
            "['fine', 'tell', 'scarier']\n",
            "['bad', 'dream', 'house']\n",
            "['buck', 'glad', 'curse', 'place']\n",
            "['motivated', 'seller', 'marge']\n",
            "['certainly', 'motivate', 'prime', 'location', 'eighteen', 'bedroom', 'moat', 'able', 'afford']\n",
            "['get', 'good', 'deal', 'quit', 'fight']\n",
            "['ow', 'mom', 'bart', 'throw', 'book']\n",
            "['probably', 'house', 'settle']\n",
            "['hmmm', 'kitchen', 'certainly', 'use', 'woman', 'touch']\n",
            "['homer', 'thing', 'corner']\n",
            "['look', 'like', 'vortex', 'gateway', 'dimension']\n",
            "['hey', 'pretty', 'slick']\n",
            "['quit', 'throw', 'garbage', 'dimension']\n",
            "['mom_dad', 'help']\n",
            "['okay', 'boy', 'let', 'talk']\n",
            "['feel', 'evil', 'presence', 'house']\n",
            "['quiet', 'lisa', 'scare', 'mother']\n",
            "['child', 'coat', 'leave', 'house', 'right']\n",
            "['wait_minute', 'marge', 'natural', 'thing', 'wrong', 'old', 'house', 'like', 'fixer', 'upper', 'problem', 'bunch', 'priest']\n",
            "['go', 'live', 'house', 'evil', 'save', 'dollar']\n",
            "['stubborn', 'talk', 'dollar', 'talk', 'thousand_dollar']\n",
            "['get', 'great', 'high', 'ceiling']\n",
            "['tell', 'let', 'sleep', 'okay']\n",
            "['bart', 'kill', 'die']\n",
            "['liiii', 'saaa', 'liii', 'saaa', 'butcher', 'knife', 'lisa']\n",
            "['marge', 'oh', 'marge']\n",
            "['die', 'die', 'everybody', 'die']\n",
            "['go', 'homer', 'bart', 'lisa', 'maggie', 'stop']\n",
            "['sorry', 'sorry', 'bart', 'sorry', 'mom', 'sorry', 'maggie', 'sorry', 'lisa']\n",
            "['child', 'dress', 'leave']\n",
            "['aw', 'come', 'marge', 'say', 'sleep']\n",
            "['care', 'say', 'family', 'difference', 'squabble', 'knife', 'fight', 'blame', 'house']\n",
            "['mom_dad', 'look']\n",
            "['ancient', 'indian', 'burial', 'ground']\n",
            "['man', 'place', 'get']\n",
            "['mr', 'ploot', 'homer_simpson', 'sell', 'house', 'forgot', 'mention', 'little', 'thing', 'tell', 'build', 'indian', 'burial', 'ground', 'recollection', 'yeah', 'right', 'goodbye', 'say', 'mention', 'time']\n",
            "['aw', 'gee', 'marge']\n",
            "['worry', 'turn', 'trusty', 'bug', 'zapper']\n",
            "['shush', 'shut', 'quit', 'try', 'push', 'stop', 'say', 'horrible', 'thing', 'manner']\n",
            "['look', 'angry', 'hand', 'shake']\n",
            "['well', 'eye', 'burst', 'ewww']\n",
            "['hey', 'man', 'let', 'blood']\n",
            "['come', 'man', 'blood', 'thing', 'come']\n",
            "['try', 'scare', 'try', 'get', 'close', 'maybe', 'love']\n",
            "['hey', 'listen', 'lady']\n",
            "['oh', 'lady', 'marge', 'simpson', 'family', 'go', 'go', 'live', 'better']\n",
            "['hmmm', 'life', 'simpson', 'choice']\n",
            "['choose', 'destroy', 'live', 'help', 'feel', 'little', 'reject']\n",
            "['oh', 'yeah', 'sever', 'finger']\n",
            "['eww', 'baby', 'spit']\n",
            "['story', 'warm', 'macabre', 'tale', 'hungry', 'damned']\n",
            "['oooo', 'big', 'mama', 'heh_heh', 'heh']\n",
            "['man', 'alive', 'well', 'hamburger', 'grill', 'perfection']\n",
            "['greeting', 'earthling', 'kang', 'frighten', 'mean', 'harm']\n",
            "['actually', 'speak', 'rigelian', 'astonishing', 'coincidence', 'language', 'exactly']\n",
            "['go_to', 'man']\n",
            "['kodos', 'take', 'rigel', 'world', 'infinite', 'delight', 'tantalize', 'sense', 'challenge', 'intellectual', 'limitation']\n",
            "['look', 'know', 'simpson', 'low', 'order', 'life', 'face', 'prejudice', 'day', 'life', 'happy', 'little', 'planet', 'throw', 'mercy', 'return']\n",
            "['hey', 'load', 'spread']\n",
            "['earthling', 'want', 'eat']\n",
            "['pronouce', 'correctly', 'pull', 'tongue']\n",
            "['smothered', 'pork_chop']\n",
            "['look', 'homer', 'radish', 'rosette', 'hard', 'advanced', 'race']\n",
            "['come', 'earthling', 'eat', 'grow', 'large', 'food']\n",
            "['girl', 'right', 'let', 'applesauce', 'pork_chop']\n",
            "[\"lookin_'\", 'buddy']\n",
            "['great', 'pleasure', 'provide', 'unlimited', 'entertainment', 'intergalactic', 'journey', 'cable', 'system', 'receive', 'million', 'channel', 'furth', 'reach', 'galaxy']\n",
            "['crowning', 'achievement', 'amusement', 'technology', 'electronic', 'version', 'table', 'tennis', 'primitive', 'paddle', 'replace', 'electronic']\n",
            "['marge', 'play', 'old', 'game', 'marry']\n",
            "['build', 'space', 'ship', 'know']\n",
            "['species', 'master', 'intergalactic', 'travel', 'raise', 'hand']\n",
            "['sorry', 'game', 'nice']\n",
            "['hey', 'come', 'guy', 'eat']\n",
            "['oh', 'want', 'spoil', 'appetite', 'great', 'feast', 'land', 'rigel']\n",
            "['oh', 'feast', 'feeling', 'guest', 'honor']\n",
            "['arrive', 'plenty', 'time', 'chew', 'fat']\n",
            "['good', 'earth', 'boy']\n",
            "['excellent', 'mr_simpson', 'excellent']\n",
            "['human', 'perfect', 'flavor']\n",
            "['happen', 'fatten', 'eat']\n",
            "['believe', 'look', 'book', 'find']\n",
            "['human', 'stop', 'eat']\n",
            "['listen', 'big', 'stupid', 'space', 'creature', 'eat', 'simpson']\n",
            "['play', 'dumb', 'find', 'book']\n",
            "['mean', 'harmless', 'cookbook', 'little', 'dusty']\n",
            "['wait', 'space', 'dust']\n",
            "['let', 'straight', 'think']\n",
            "['think', 'go', 'eat']\n",
            "['good', 'god', 'kind', 'joke']\n",
            "['try', 'eat', 'time']\n",
            "['eat', 'merely', 'provide', 'sumptuous', 'banquet', 'frankly', 'people', 'pig']\n",
            "['slave', 'kitchen', 'day', 'people']\n",
            "['want', 'serak', 'preparer', 'cry', 'mission', 'accomplish']\n",
            "['being', 'emotion', 'know']\n",
            "['offer', 'paradise', 'experience', 'emotion', 'time', 'great', 'love', 'thousand', 'time', 'great', 'fun', 'treat', 'like', 'god', 'live', 'forever', 'beauty', 'distrustful', 'nature']\n",
            "['superior', 'race', 'rub']\n",
            "['monster', 'ship', 'truly']\n",
            "['lisa', 'mean', 'smart', 'good']\n",
            "['yeah', 'thanks', 'lisa']\n",
            "['hello', 'scary', 'happening']\n",
            "['hey', 'poindexter', 'halloween', 'book', 'away']\n",
            "['information', 'read', 'classic', 'tale', 'terror', 'edgar', 'allan', 'poe']\n",
            "['wait_minute', 'schoolbook']\n",
            "['worry', 'bart', 'will', 'learn']\n",
            "['ponder', 'weak', 'weary']\n",
            "['quaint', 'curious', 'volume', 'forget', 'lore', 'nod', 'nearly', 'nap', 'suddenly', 'come', 'tapping']\n",
            "['gently', 'rap', 'rapping', 'chamber', 'door']\n",
            "[\"'_tis\", 'visitor']\n",
            "['bart', 'establish', 'mood']\n",
            "['sorrow', 'lost', 'lenore']\n",
            "['rare', 'radiant', 'maiden', 'angel', 'lenore', 'nameless', 'evermore']\n",
            "['chamber', 'turn', 'soul', 'burn', 'soon', 'hear', 'tap', 'loud']\n",
            "['mr_burns', 'year', 'see', 'shoddy', 'deplorable']\n",
            "['thy', 'crest', 'shorn', 'shave', 'thou']\n",
            "['art', 'sure', 'craven', 'ghastly', 'grim', 'ancient', 'raven', 'wander', 'nightly', 'shore', 'tell', 'tell', 'thy', 'lordly', 'night', 'plutonian', 'shore']\n",
            "['bart', 'stop', 'say', 'nevermore']\n",
            "['methought', 'air', 'grow', 'denser', 'perfume', 'unseen', 'censer']\n",
            "['swung', 'seraphim', 'foot', 'fall', 'tinkle', 'tufted', 'floor']\n",
            "['thy', 'god', 'hath', 'lend', 'thee', 'angel', 'hath', 'send', 'thee', 'respite', 'nepenthe', 'thy', 'memory', 'lenore', 'quaff', 'oh', 'quaff', 'kind', 'nepenthe', 'forget', 'lost', 'lenore']\n",
            "['word', 'sign', 'part', 'bird', 'fiend']\n",
            "['thee', 'temp', 'night', 'plutonian', 'shore', 'oh', 'leave', 'black', 'plume', 'token', 'lie', 'thy', 'soul', 'hath', 'spoken', 'leave', 'loneliness', 'unbroken', 'quit', 'bust', 'door', 'thy', 'beak', 'heart', 'thy', 'form', 'door']\n",
            "['thy', 'beak', 'heart', 'thy', 'form', 'door']\n",
            "['nevermore', 'nevermore', 'nevermore', 'nevermore', 'nevermore']\n",
            "['lisa', 'scary', 'poem']\n",
            "['write', 'maybe', 'people', 'easy', 'scare']\n",
            "['yeah', 'like', 'look', 'friday', 'th', 'pretty', 'tame', 'today', 'standard']\n",
            "['guess', 'trouble', \"gettin_'\", 'sleep', 'tonight']\n",
            "['oh', 'marge', 'come']\n",
            "['homer', 'sleep', 'light', 'child', 'story', 'hurt']\n",
            "['oh', 'oh', 'hate', 'halloween']\n",
            "['uh_huh', 'ah', 'bait']\n",
            "['brother', 'worm', 'feel', 'tranquility', 'far', 'outweigh', 'actual', 'catching', 'fish']\n",
            "['dave', 'shutton', 'investigative', 'reporter', 'road', 'lot', 'uh', 'day', 'talk', 'way', 'elder']\n",
            "['right', 'eat', 'tonight']\n",
            "['leave', 'good', 'old', 'mary', 'bailey', 'finally', 'step', 'hideous', 'genetic', 'mutation']\n",
            "['mary', 'bailey', 'governor', 'sure', 'find', 'well', 'thing', 'time']\n",
            "['like', 'get', 'washington', 'birthday', 'lincoln', 'birthday', 'separate', 'pay', 'holidays', 'president', 'day', 'pfft', 'rip', 'bust', 'butt', 'day', 'day']\n",
            "['late', 'work', 'homer']\n",
            "['try', 'spill', 'dad']\n",
            "['mutant', \"comin_'\", 'homer']\n",
            "['oh', 'man', 'plain', 'cake', 'donut', 'thank', 'take', 'fancy', 'guy', 'time']\n",
            "['hi', 'ho', 'faceless', 'employee', 'moment', 'government', 'inspection', 'team', 'tour', 'plant', 'look', 'busy', 'mouth', 'shut']\n",
            "['uh', 'oh', 'come']\n",
            "['okay', 'man', 'geiger', 'counter']\n",
            "['suppose', 'normal', 'background', 'radiation', 'kind', 'find', 'maintain', 'nuclear', 'facility', 'matter', 'playground', 'hospital']\n",
            "['gum', 'seal', 'crack', 'cool', 'tower']\n",
            "['plutonium', 'rod', 'paperweight']\n",
            "['uh', 'uh', 'rest', 'eye']\n",
            "['ah', 'rest', 'employee', 'vigilant', 'employee']\n",
            "['monitoring', 'station', 'unmanned']\n",
            "['look', 'inspector', 'speak', 'privately', 'office']\n",
            "['oh', 'look', 'careless', 'person', 'leave', 'thousand', 'thousand_dollar', 'lie', 'coffee', 'table', 'uh', 'smither', 'leave', 'room', 'hopefully', 'return', 'pile', 'money', 'go']\n",
            "['look', 'smither', 'money', 'stupid', 'man']\n",
            "['burn', 'know', 'better', 'think', 'try', 'bribe']\n",
            "['mr_burns', 'go', 'overlook', 'felony', 'overlook', 'violation', 'observe', 'plant', 'today', 'bring', 'place', 'code', 'shut', 'good', 'day']\n",
            "['oh', 'little', 'dab', 'paint', 'little', 'spackle', 'possibly', 'cost', 'fix', 'place']\n",
            "['hmmm', 'approximately', 'million_dollar', 'sir']\n",
            "['oh', 'strength', 'smither']\n",
            "['build', 'railroad', 'run', 'race', 'time', 'build', 'railroad', 'brother', 'spare', 'dime', 'half', 'million', 'boot', 'go', 'slog', 'hell', 'kid', 'drum']\n",
            "['ah', 'uh', 'rest', 'eye', 'holy', 'moly', 'thirty']\n",
            "['hello', 'marge', 'sorry', 'madhouse', 'yeah', 'hour', 'day', 'killin', \"'\"]\n",
            "['hey', 'remember', 'call', 'al', 'al', 'time', 'hey', 'remember', 'pal', 'buddy', 'spare', 'dime']\n",
            "['huh', 'th', 'uh', 'mr_burns']\n",
            "['sorry', 'sir', 'homer_simpson', 'right']\n",
            "['work', 'late', 'simpson']\n",
            "['uh', 'uh', 'yes', 'sir']\n",
            "['die', 'breed', 'simpson', 'go', 'share', 'hop']\n",
            "['homer', 'try', 'shut']\n",
            "['know', 'tell', 'wife', 'governor', 'thing', 'lot', 'differently']\n",
            "['oh', 'soapbox', 'simpson', 'realize', 'cost', 'run', 'office', 'honest', 'man', 'afford']\n",
            "['uh', 'wrong', 'mean', 'honest', 'man', 'mean', 'afford', 'run', 'governor', 'feel', 'like', \"'\", 'course', 'ramble', 'uh', 'stare', 'like', 'true', 'mean', 'governor', 'decide', 'safe']\n",
            "['create', 'new', 'well', 'world']\n",
            "['way', 'drop', 'house']\n",
            "['homer', 'mary', 'bailey', 'family']\n",
            "['mary', 'bailey', 'go', 'fire', 'vote', 'monty', 'burn']\n",
            "['oooo', 'political', 'discussion', 'table', 'feel', 'like', 'kennedy']\n",
            "['frankly', 'despicable', 'man', 'live', 'chance', 'mary', 'bailey', 'beloved', 'governor', 'great', 'state', 'know']\n",
            "['problem', 'governor', 'bailey', 'beloved', 'ninety', 'percent', 'voter', 'rate', 'despicable', 'bad', 'assemble', 'fine', 'campaign', 'team', 'money', 'buy', 'speech', 'writer']\n",
            "['job', 'turn', 'mr_burns']\n",
            "['tooth', 'show', 'like']\n",
            "['ah', 'excellent', 'exactly', 'kind', 'trickery', 'pay', 'turn', 'average', 'joe', 'sixpack', 'mary', 'bailey']\n",
            "['team', 'investigator', 'muckraker']\n",
            "['job', 'turn', 'mary', 'bailey']\n",
            "['visual', 'aids', 'help', 'thank']\n",
            "['burning', 'issue', 'need', 'address', 'neutralize', 'immediately']\n",
            "['thank', 'watch', 'movie', 'dreary', 'afternoon', 'stay', 'tune', 'pay', 'political', 'announcement', 'bring', 'friend', 'montgomery_burn']\n",
            "['burn', 'change', 'channel']\n",
            "['fine', 'jerk', 'sit', 'watch']\n",
            "['oh', 'election', 'deal', 'close', 'bar']\n",
            "['wonder', 'go', 'horrible', 'fish']\n",
            "['oh', 'marge', 'big_deal', 'bet', 'paper', 'blow', 'proportion', 'know', 'eye', 'fish']\n",
            "['thirty', 'second', 'air', 'mr_burns']\n",
            "['go', 'sore', 'tomorrow']\n",
            "['mr', 'burn', 'rest']\n",
            "['time', 'pay', 'political', 'announcement', 'johnny', 'lunchpail', 'stupid', 'state', 'eat', 'hand']\n",
            "['oh', 'hello', 'friend', 'montgomery_burn', 'governor', 'talk', 'little', 'friend', 'blinky']\n",
            "['consider', 'hideous', 'genetic', 'mutation', 'truth', 'word', 'let', 'ask', 'actor', 'portray', 'charles', 'darwin', 'think']\n",
            "['oh', 'hello', 'charles', 'good', 'fellow', 'tell', 'viewer', 'theory', 'natural', 'selection']\n",
            "['glad', 'mr_burns', 'mother', 'nature', 'change', 'animal', 'give', 'big', 'tooth', 'sharp', 'claw', 'long', 'leg', 'case', 'eye', 'variation', 'turn', 'improvement', 'new', 'animal', 'thrive', 'multiply', 'spread', 'face', 'earth']\n",
            "['say', 'fish', 'advantage', 'fish', 'fact', 'kind', 'super', 'fish']\n",
            "['mind', 'have', 'eye']\n",
            "['friend', 'anti', 'nuclear', 'naysayer', 'choose', 'sider', 'come', 'elephant', 'frolicking', 'water', 'nuclear_power', 'plant', 'probably', 'blame', 'ridiculous', 'nose', 'nuclear', 'bogeyman']\n",
            "['truth', 'fish', 'miracle', 'nature', 'taste', 'beat', 'mmmm', 'mmmm', 'summarize', 'want', 'sling', 'arrow', 'stop', 'slander', 'poor', 'defenseless', 'blinky', 'good', 'night', 'god_bless']\n",
            "['moron', 'cast', 'vote', 'monty', 'burn']\n",
            "['wow', 'super', 'fish']\n",
            "['burns', 'state', 'need', 'young', 'blood']\n",
            "['hope', 'burns', 'count', 'support', 'honey']\n",
            "['homer', 'bailey', 'booster']\n",
            "['congratulation', 'mr', 'burn', 'late', 'poll', 'point']\n",
            "['worthy', 'opponent', 'think', 'voter', 'state', 'gullible', 'fool', 'prefer', 'rely', 'intelligence', 'good', 'judgment']\n",
            "['find', 'dirt', 'mary', 'bailey']\n",
            "['far', 'negative', 'thing', 'find', 'guy', 'date', 'sixteen']\n",
            "['go_to', 'send', 'message', 'bureaucrat', 'state', 'capital']\n",
            "['voter', 'imperial', 'god', 'like']\n",
            "['downside', 'late', 'poll', 'indicate', 'danger', 'lose', 'touch', 'common', 'man']\n",
            "['oh', 'dear', 'heaven', 'forefend']\n",
            "['night', 'election', 'want', 'dinner', 'home', 'worker']\n",
            "['oh', 'angle', 'joe', 'meatball', 'sally', 'housecoat', 'god', 'forsaken', 'state', 'hunker', 'chow', 'eddie', 'punchclock', 'medium', 'field', 'day']\n",
            "['question', 'find', 'common']\n",
            "['ah', 'great', 'toast', 'marge', 'hmmm', 'oh', 'way', 'night', 'election', 'mr_burns', 'come', 'dinner']\n",
            "['reporter', 'camera', 'crew', 'need', 'feed']\n",
            "['cool', 'man', 'medium', 'circus']\n",
            "['huh', 'uh', 'go', 'ring', 'doorbell', 'mary', 'bailey', 'night']\n",
            "['kid', 'leave', 'room', 'want']\n",
            "['hope', 'child', 'pop', 'question', 'upcoming', 'election', 'little_girl', 'think', 'memorize', 'dinner', 'time', 'tomorrow']\n",
            "['mr', 'burn', 'campaign', 'momentum', 'runaway', 'freight', 'train', 'popular']\n",
            "['hmmm', 'long', 'ask', 'ask', 'assuage', 'fear', 'contaminate', 'planet', 'manner', 'day', 'render', 'uninhabitable']\n",
            "['dear', 'card', 'question', 'fine']\n",
            "['think', 'non', 'card', 'question', 'valid']\n",
            "['marge', 'worry', 'daughter', 'bright', 'sure', 'able', 'memorize', 'question', 'dinner', 'time', 'tomorrow']\n",
            "['innocent', 'child', 'away', 'blasphemy', 'god_bless', 'amen']\n",
            "['finally', 'mr_burns', 'want', 'appear', 'affectionate', 'remind', 'hate', 'touch']\n",
            "['wrong', 'want', 'snuggle']\n",
            "['feel', 'like', 'snuggle']\n",
            "['want', 'snuggle', 'anybody', 'let', 'express']\n",
            "['express', 'lovely', 'home', 'food', 'serve']\n",
            "['okay', 'homer', 'fair', 'get', 'right', 'good', 'go_to', 'express', 'right', 'goodnight']\n",
            "['hey', 'hello', 'handsome']\n",
            "['hey', 'stuff', 'face', 'dinner', 'common', 'man', 'tyrone', 'power']\n",
            "['late', 'poll', 'dead', 'cornball', 'stunt', 'go_to']\n",
            "['hello', 'homer', 'marge', 'look', 'dazzle', 'oh', 'look', 'bring', 'noodle', 'kugel']\n",
            "['bad', 'dog', 'bad', 'neighbor', 'dog', 'let', 'help', 'mr_burns']\n",
            "['love', 'dog', 'baby']\n",
            "['aaaah', 'kitty', 'kitty']\n",
            "['right', 'mr_burns']\n",
            "['oh', 'course', 'little', 'roughhousing', 'pet', 'good', 'man', 'appetite']\n",
            "['late', 'poll', 'statesman', 'like', 'way', 'handle', 'pet', 'incident', 'ahead', 'congratulation', 'mr', 'governor']\n",
            "['bart', 'like', 'grace']\n",
            "['dear', 'god', 'pay', 'stuff', 'thank', 'nothing']\n",
            "['smokin', \"'\", 'smokin', \"'\"]\n",
            "['know', 'mr_burns', 'family', 'feel', 'taxis', 'high', 'stand', 'highly', 'controversial', 'issue']\n",
            "['goodness', 'realize', 'casual', 'dinner', 'go', 'turn', 'charge', 'political', 'debate']\n",
            "['homer', 'agree', 'elect', 'governor', 'lower', 'taxis', 'bureaucrat', 'state', 'capital', 'like']\n",
            "['lisa', 'question', 'like', 'ask', 'uncle', 'montgomery']\n",
            "['yes', 'sir', 'inane', 'mr', 'burn', 'campaign', 'momentum', 'runaway', 'freight', 'train', 'popular']\n",
            "['oooh', 'tough', 'question', 'fair', 'lisa', 'single', 'answer', 'voter', 'respond', 'integrity', 'impressed', 'incorruptibility', 'determination', 'lower', 'taxis', 'bureaucrat', 'state', 'capital', 'pipe', 'smoke']\n",
            "['oh', 'mom', 'feel', 'awful']\n",
            "['sorry', 'dear', 'soon']\n",
            "['mom', 'tool', 'evil']\n",
            "['lisa', 'learn', 'lesson', 'tonight', 'mother', 'benefit', 'doubt']\n",
            "['fair', 'shake', 'square', 'deal', 'ummmm', 'smell', 'delightful']\n",
            "['right', 'eyed', 'fish']\n",
            "['plate', 'mr_burns']\n",
            "['ruin', 'hit', 'ground']\n",
            "['headline', 'phil', 'burns', 'swallow', 'story']\n",
            "['late', 'poll', 'indicate', 'burn', \"'\", 'popularity', 'plummet', 'earth', 'like', 'half', 'chew', 'fish']\n",
            "['trick', 'leave', 'sleeve', 'smither', 'boil', 'coffee', 'lick']\n",
            "['yes', 'come', 'boy', 'old', 'guy', 'finish']\n",
            "['wait', 'come', 'charles', 'montgomery', 'burns']\n",
            "['smither', 'tip', 'table']\n",
            "['homer', 'homer', 'stop']\n",
            "['uh', 'mr_burns', 'uh', 'mr_burns']\n",
            "['mr_burns', 'hardly', 'destroy', 'meager', 'possession', 'go', 'accomplish']\n",
            "['right', 'home', 'smither', 'destroy', 'tasteful']\n",
            "['ironic', 'smither', 'anonymous', 'clan', 'slack', 'jaw', 'troglodyte', 'cost', 'election', 'kill', 'jail', 'democracy']\n",
            "['noble', 'poetic', 'defeat', 'sir']\n",
            "['simpson', 'shall', 'focus', 'remaining', 'year', 'dream', 'unfulfilled']\n",
            "['uh', 'oh', 'bust', 'dad']\n",
            "['oh', 'dream', 'unfulfilled', 'oh', 'like', 'sound', 'bit', 'mean', 'hope', 'marge', 'better', 'well', 'huh']\n",
            "['homer', 'man', 'big', 'dream', 'include', 'second', 'dessert', 'occasional', 'snuggling', 'sleep', 'till', 'noon', 'weekend', 'man', 'destroy']\n",
            "['homer', 'happen', 'capitol', 'city']\n",
            "['come', 'homer', 'dyin', \"'\", 'curiosity']\n",
            "['look', 'thing', 'bad', 'loser', 'guy', 'sit', 'bar', 'tell', 'story', 'loser', 'want', 'happen']\n",
            "['okay', 'start', 'nuclear_plant', 'employee', 'spouse', 'child', 'night', 'springfield', 'stadium']\n",
            "['oooh', 'think', 'lose', '-PRON-', 'hey', 'ball', 'park', 'right', 'bird', 'stone', 'okay', 'everybody']\n",
            "['hey', 'bus', 'dancin', \"'\", 'homer']\n",
            "['know', 'boy', 'player', 'tonight', 'big', 'league', 'day']\n",
            "['go_to', 'washed', 'major', 'leaguer']\n",
            "['sure', 'nice', 'mix']\n",
            "['think', 'well', 'place', 'spend', 'balmy', 'summer', 'night', 'old', 'ball', 'yard', 'green', 'grass', 'outfield', 'crushed', 'brick', 'infield', 'white', 'chalk', 'line', 'divide', 'man', 'little', 'boy']\n",
            "['lisa', 'honey', 'forget', 'beer', 'come', 'seventy', 'ounce', 'tub']\n",
            "['hope', 'space', 'tub', 'year', 'homer']\n",
            "['year', 'get', 'little', 'rambunctious', 'moon', 'poor', 'umpire']\n",
            "['marge', 'ticket', 'seat', 'give', 'right', 'duty', 'complete', 'ass']\n",
            "['ah', 'gammill', 'good']\n",
            "['inspiration', 'waste', 'management', 'sir']\n",
            "['mind', 'contaminate', 'night', 'hot_dog']\n",
            "['little', 'smile', 'card', 'smither']\n",
            "['uh', 'simp', 'son', 'sir']\n",
            "['huh', 'hmmm', 'oh', 'oh', 'yes', 'homer', 'marge', 'simpson', 'oh', 'bart', 'lisa', 'uh', 'expect']\n",
            "['card', 'need', 'update', 'sir']\n",
            "['oh', 'okay', 'baby', 'important', 'let', 'marge']\n",
            "['oh', 'wow', 'flash', 'bailor', 'get_to', 'autograph', 'star']\n",
            "['hey', 'flash', 'ya', 'sign', 'ball']\n",
            "['lousy', 'wash', 'break', 'old', 'tub', 'gut', 'think']\n",
            "['fine', 'role', 'model', 'bart', 'ball']\n",
            "['hey', 'flash', 'check', 'mature', 'quail', 'headin', \"'\", 'way']\n",
            "['hey', 'little', 'lady', 'flash', 'ya']\n",
            "['hmmm', 'springfield', 'kozy', 'kort', 'motel', 'room', 'about', 'flash']\n",
            "['wow', 'flash', 'bailor', 'come', 'wife', 'get', 'magic', 'marge']\n",
            "['hey', 'dad', 'look', 'jumbovision']\n",
            "['hey', 'everybody', 'do', 'look', 'homer_simpson', 'heh_heh']\n",
            "['homer', 'homer', 'x', 'y', 'z']\n",
            "['examine', 'zipper', 'whoop']\n",
            "['lady_gentleman', 'throw', 'tonight', 'ball', 'man', 'synonymous', 'nation', 'safe', 'clean', 'energy', 'source', 'mr', 'montgomery', 'burns']\n",
            "['ah', 'love', 'sir']\n",
            "['heh_heh', 'know', 'smither', 'young', 'buck', 'patent', 'fadeaway', 'pitch', 'compare', 'trouble', 'ball', 'late', 'great', 'satchel', 'paige', 'spit', 'smither']\n",
            "['hocker', 'come', 'sir']\n",
            "['actually', 'hear', 'air', 'tear', 'sir']\n",
            "['hey', 'burn', 'hey', 'rag', 'arm']\n",
            "['throw', 'like', 'sister', 'man']\n",
            "['yeah', 'throw', 'like']\n",
            "['lady_gentleman', 'honor', 'america', 'rise', 'national', 'anthem', 'sing', 'tonight', 'springfield', 'rhythm', 'n', \"'\", 'blue', 'sensation', 'bleed', 'gum', 'murphy']\n",
            "['hi', 'de', 'hi', 'springfield', 'dan', 'hoard', 'mikeside', 'tonight', 'isotope', 'pesky', 'shelbyville', 'shelbyvillian', \"'\", 'tope', 'look', 'snap', 'darn', 'game', 'lose', 'streak', 'longest', 'professional', 'baseball', 'about', 'sleepy', 'town', 'record', 'book']\n",
            "['ah', 'sit', 'employee', 'guess', 'prove', 'friend', 'aisle', 'smither', 'want', 'surround']\n",
            "['let', 'sa', 'winggg', 'batter']\n",
            "['want', 'pitcher', 'belly', 'itcher']\n",
            "['want', 'catcher', 'belly', 'scratcher']\n",
            "['oh', 'marge', 'sit', 'boss', 'good', 'night', 'year', 'ruin', 'lousy', 'rotten', 'stink']\n",
            "['mean', 'wave', 'fanny', 'public']\n",
            "['beeer', 'heah', 'duff', 'beeer']\n",
            "['heah', 'beer', 'right', 'beer', 'didja', 'hear']\n",
            "['duff', 'beer', 'marge']\n",
            "['delicious', 'frosty', 'beer', 'fat', 'lot', 'good', 'sit', 'old_man', 'burn']\n",
            "['suppose', 'want', 'beer']\n",
            "['sir', 'oh', 'chance', 'idiot', 'drink', 'beer']\n",
            "['actually', 'wonder', 'join', 'treat']\n",
            "['ohhh', 'stature', 'enjoy', 'beer', 'maybe', 'turn', 'subject', 'wait_minute', 'have', 'drug', 'test', 'tomorrow']\n",
            "['hitter', 'rocker', 'kiss', 'betty', 'crocker']\n",
            "['oh', 'rile', 'late', 'great', 'connie', 'mack', 'old', 'shibe', 'park']\n",
            "['little', 'baby', 'batter', 'control', 'bladder']\n",
            "['shut', 'try', 'think']\n",
            "['hmmm', 'crude', 'like', 'freshen', 'little', 'drinkie', 'poo']\n",
            "['basis', 'load', \"'\", 'tope', 'pitch', 'swing', 'miss', 'strike', 'course']\n",
            "['damnation', 'banjos', 'carry', 'pie', 'traynor', 'glove']\n",
            "['big', 'bill', 'mccloskey', 'come', 'soon', 'pop', 'right', 'post', 'game']\n",
            "[\"c'mon\", 'need', 'grand', 'slam']\n",
            "['game', 'year', 'ruin', 'pathetic', 'incompetence']\n",
            "['wrong', 'people', 'let', 'spirit', 'come']\n",
            "['team', 'need', \"c'mon\"]\n",
            "['get', 'feel', 'intoxication', 'alcohol', 'intoxication', 'public', 'spectacle']\n",
            "['nut', 'right', 'field', 'dancin', \"'\", 'storm', 'get', 'crowd', 'go', 'let', 'shake', 'mediocre', 'slugger', 'big', 'bill', 'mccloskey']\n",
            "['swung', 'belt', 'deep', 'left', 'field', 'go', 'go']\n",
            "['go', 'outta', 'oh_god', 'isotope', 'win', 'game', 'isotope', 'win', 'game', 'isotope', 'win', 'game']\n",
            "['yes', 'unfortunately', 'homer_simpson', 'shameless', 'display', 'exhibitionism', 'taint', 'entire', 'evening', 'want', 'ban', 'life', 'company', 'outing']\n",
            "['thank', 'kind', 'glad', 'enjoy', 'credit', 'batter']\n",
            "['excuse', 'sir', 'dancing', 'fella', 'antoine', 'tex', \"o'hara\", 'isotope', 'interested', 'official', 'mascot']\n",
            "['m', 'mascot', 'bush', 'league', 'team']\n",
            "['sleep', 'stare', 'blankly', 'unable', 'think', 'nickname', 'life', 'spare']\n",
            "['oh', 'oh', 'hey', 'cool', 'man']\n",
            "['life', 'take', 'odd', 'turn']\n",
            "['team', 'ask', 'dress', 'like', 'homer']\n",
            "['nope', 'bright', 'idea', \"c'mon\", 'get_to', 'hurry', 'fill', 'vegetable', 'kid', 'save', 'room', 'nachos']\n",
            "['time', 'life', 'people', 'laugh', 'laugh']\n",
            "[\"'\", 'tope', 'win', \"'\", 'tope', 'win', 'row', 'row']\n",
            "['simpson', 't_shirt', 'think', 'day']\n",
            "['oooh', 'boogie', 'boogie', 'boogie', 'boogie', 'boogie', 'woo', 'boogie', 'boogie', 'boogie', 'boogie', 'boogie', 'boogie']\n",
            "['hey', 'knock', 'stick', 'bat', 'sun', 'shine']\n",
            "['oh', 'yeah', 'oh']\n",
            "['helen', 'caribbean', 'mood', 'tonight', 'about', 'give', 'baby', 'elephant', 'walk', 'little', 'reggae', 'kinda', 'beat']\n",
            "['dancin', \"'\", 'homer', 'git', 'man', 'git']\n",
            "['lively', 'dancin', \"'\", 'homer']\n",
            "['basis', 'load', 'out', 'good', 'guy', 'trail', 'run']\n",
            "['pitch', 'swing', 'miss', 'strike', \"'\", 'tope', 'lose', \"'\", 'tope', 'lose', \"'\", 'tope', 'lose']\n",
            "['homer', 'know', 'begin', 'go_to', 'forever']\n",
            "['oh', 'oh', 'oh', 'fire', 'player', 'fire', 'mascot', 'sick']\n",
            "['homer', 'fire', 'get', 'word', 'call', 'capital_city']\n",
            "['wait_minute', 'capital_city', 'mascot', 'great', 'mascot', 'capital_city', 'goofball']\n",
            "['yeah', 'get', 'year', 'need', 'fill', 'couple', 'inning', 'night', 'big', 'opportunity']\n",
            "['big', 'decision', 'simpson', 'face', 'listen', 'kid', 'instead', 'big', 'dumb', 'wife']\n",
            "['call', 'bite', 'tongue', 'bite', 'tongue', 'oooh']\n",
            "['leave', 'springfield', 'bear', 'think', 'die']\n",
            "['will', 'bad', 'die', 'someplace']\n",
            "['phfft', 'new', 'well', 'friend']\n",
            "['dad', 'simple', 'people', 'simple', 'value', 'capital_city', 'big', 'complex', 'springfield', 'know', 'forgive']\n",
            "['homer', 'lie', 'scare', 'little', 'call', 'reason', 'almighty', 'earth', 'dance', 'dugout']\n",
            "['yeah', 'let', 'blow', 'pop', 'stand', 'look']\n",
            "['simple', 'get', 'convince', 'supervisor', 'leave', 'absence']\n",
            "['sure', 'like', 'year', 'year']\n",
            "['simpson', 'move', 'capital_city']\n",
            "['uh_huh', 'stuff', 'sale', 'huh', 'know', 'know']\n",
            "['oh', 'knock', 'flander', 'start', 'blubber', 'go_to', 'miss']\n",
            "['know', 'bart', 'mean', 'go_to', 'miss']\n",
            "['come', 'milhouse', 'way', 'friend', 'forever']\n",
            "['go_to', 'miss', 'spit', 'brother']\n",
            "['help', 'feel', 'get', 'know', 'better', 'leaving', 'actually', 'mean']\n",
            "['quick', 'stop', 'capital_city']\n",
            "['believe', 'baby', 'sister', 'big', 'city']\n",
            "['look', 'use', 'horn']\n",
            "['give', 'bad', 'break', 'life', 'little', 'education', 'bald', 'cue', 'ball', 'year', 'job', 'salary', 'today', 'leave', 'capital_city', 'consider', 'lucky', 'mascot', 'face', 'earth']\n",
            "['fickle', 'fan', 'forget', 'ready', 'big', 'step', 'life']\n",
            "['kid', 'capital_city']\n",
            "['look', 'crosstown', 'bridge']\n",
            "['swingin', \"'\", 'town', 'know', 's', 'swingin', 'town', 'know']\n",
            "['call', 'capital_city']\n",
            "['people', 'stop', 'scream', 'hello', 'people', 'stop', 'scream', 'hello']\n",
            "['kid', 'look', 'street', 'crime']\n",
            "['kind', 'place', 'make', 'kind', 'place', 'make']\n",
            "['bum', 'feel', 'like', 'king']\n",
            "['make', 'king', 'feel', 'like', 'make', 'king', 'feel', 'like']\n",
            "['nutty', 'koo', 'koo', 'super', 'king']\n",
            "['look', 'tony', 'bennett']\n",
            "['law', 'frown', 'law', 'frown']\n",
            "['capital_city', 'caper', 'like', 'stupid', 'clown', 'chance']\n",
            "['fourth', 'street', 'd']\n",
            "['fourth', 'street', 'd', 'yeah', 'whiff', 'want', 'roam']\n",
            "['capital_city', 'home', 'sweet', 'home', 'capital_city', 'happytown', 'city', 'capital_city', 'home', 'sweet', 'swingin', \"'\", 'home']\n",
            "['capital_city', 'yeah']\n",
            "['awww', 'come', 'bed', 'homie']\n",
            "['sorry', 'honey', 'little', 'nervous']\n",
            "['talk', 'time', 'life', 'marge', 'fall_asleep']\n",
            "['okay', 'ticket', 'suppose', 'good', 'sit', 'player', 'wife', 'forget', 'cheer']\n",
            "['game', 'big', 'star']\n",
            "['bart', 'strangely', 'quiet', 'later', 'explain', 'confuse', 'feeling', 'respect']\n",
            "['omigod', 'believe', 'capital_city', 'goofball']\n",
            "['hello', 'dancin', \"'\", 'homer', 'glad', 'aboard', 'squeeze', 'wheeze']\n",
            "['inning', 'wish', 'zipper', 'thing', 'know', 'mean']\n",
            "['right', 'mr', 'goofball']\n",
            "['hey', 'plain', 'old', 'goof', 'exactly', 'plan']\n",
            "['dance', 'spell', 'city', 'tune', 'baby', 'elephant', 'walk']\n",
            "['aah', 'mancini', 'mascot', 'good_friend', 'field', 'set', '-PRON-', 'knock', '-PRON-']\n",
            "['hello', 'everybody', 'dave', 'glass', \"talkin_'\", 'ya', 'get', 'great', 'weather', 'tonight', 'dome']\n",
            "['let', 'upper', 'upper', 'upper', 'mezzanine', 'hmmm', 'yes']\n",
            "['think', 'player', 'wife', 'little', 'closer', 'action']\n",
            "['actually', 'section', 'player', 'ex', 'wife']\n",
            "['find', 'bimbo', 'kansas', 'city']\n",
            "['think', 'free', 'ticket', 'big', 'league', 'park', 'tense', 'enjoy', 'game', 'ounce', 'concentration', 'possess', 'focus', 'task', 'hand']\n",
            "['red', 'hot', 'read', 'hot']\n",
            "['oooh', 'red', 'hots']\n",
            "['lady', 'gentlemen', 'capital_city', 'new', 'sensation', 'dancin', \"'\", 'homer']\n",
            "['mmm', 'taste', 'better', 'ballpark', 'uh', 'oh']\n",
            "['graceful', 'witty', 'brother', 'something']\n",
            "['people', 'sit', 'hand']\n",
            "['quiet', 'hear', 'individual', 'smart', 'ass', 'remark']\n",
            "['guy', 'want', 'cheer']\n",
            "['gee', 'pity', 'make', 'fool', 'people']\n",
            "['cornball', 'antic', 'play', 'stick', 'capital_city']\n",
            "['applause', 'get', 'drag', 'carcass']\n",
            "['hey', 'mr', 'showmanship', 'owner', 'want', 'office', 'right']\n",
            "['guess', 'good', 'old', 'springfield']\n",
            "['like', 'fruit', 'juice']\n",
            "['see', 'bright', 'light', 'capital_city', 'wither', 'die', 'like', 'hothouse', 'flower']\n",
            "['stop', 'look', 'sure', 'hard', 'father']\n",
            "['wife', 'kid', 'stand', 'way', 'home', 'realize', 'little', 'help']\n",
            "['costume', 'bury', 'son', 'sad', 'ape', 'like', 'dude']\n",
            "['hey', 'guy', 'hang', 'word', 'center', 'attention']\n",
            "['okay', 'wonder', 'story', 'degradation', 'humiliation', 'popular']\n",
            "['bust', 'hump', 'week', 'stupid', 'grass', 'suppose', 'boy', 'job']\n",
            "['homer', 'bart', 'busy', 'work', 'science', 'project']\n",
            "['hear', 'lady', 'homer', 'mow', 'quietly', 'genius', 'work']\n",
            "[\"o'clock\", 'potato', 'oclock', 'potato']\n",
            "['hey', 'neighbor', 'lord', 'certainly', 'give', 'beautiful', 'day', 'today', 'huh']\n",
            "['little', 'yard', 'work', 'huh']\n",
            "['tell', 'marge', 'beer']\n",
            "['simpson', 'get', 'time', 'release', 'granule', 'rid', 'crabgrass', 'half', 'jif']\n",
            "['ooh', 'uh', 'big', 'patch']\n",
            "['wrong', 'crabgrass', 'bad', 'love', 'cute', 'like', 'uh', 'elfgrass']\n",
            "['help', 'overhear', 'simpson', 'get', 'ice', 'cold', 'sud', 'rumpus', 'room', 'like', 'join']\n",
            "['uh', 'okay', 'heck', 'earn', 'little', 'break']\n",
            "['holy', 'moly', 'beautiful']\n",
            "['right', 'visit', 'flander', 'homestead']\n",
            "['neighbor', 'uh', 'year']\n",
            "['little', 'popcorn', 'ball', 'kissy', 'kissy']\n",
            "['hello', 'sponge', 'cake', 'think', 'boy', 'hungry', 'whip', 'club', 'sandwich']\n",
            "['be', 'wonderful', 'simpson']\n",
            "['yeah', 'yeah', 'yeah', 'forget', 'flander']\n",
            "['oh', 'beer', 'uh', 'draft', 'okay', 'tap', 'week']\n",
            "['heh_heh', 'tasty', 'little', 'lager', 'come', 'way', 'holland']\n",
            "['hey', 'dad', 'thank', 'help', 'science', 'project']\n",
            "['pleasure', 'study', 'buddy']\n",
            "['get', 'good', 'dad', 'world']\n",
            "['oh', 'know', 'embarrass']\n",
            "['know', \"t'oodley\", 'doodley']\n",
            "['ah', 'kid', 'trial']\n",
            "['uh', 'knock', 'simpson']\n",
            "['rub', 'nose', 'get', 'family', 'well', 'family', 'beer', 'come', 'farther', 'away', 'beer', 'son', 'like', 'wife', 'butt', 'high', 'wife', 'butt', 'sick']\n",
            "['simpson', 'afraid', 'go', 'ask', 'leave', 'hope', 'understand']\n",
            "['homie', 'quit', 'toss']\n",
            "['play', 'lay', 'homer']\n",
            "['sorry', 'marge', 'steam', 'jerk', 'flander', 'lousy', 'bragging', 'know']\n",
            "['say', 'say', 'say', 'say']\n",
            "['okay', 'okay', 'say', 'message', 'loud', 'clear', 'family', 'stink']\n",
            "['homer', 'good_friend', 'get_to', 'see', 'perfect', 'neighbor']\n",
            "['marge', 'backpedal', 'right', 'time', 'perfect', 'perfect', 'way']\n",
            "['go_to', 'walk', 'block', 'calm', 'get', 'little', 'excited', 'perfect', 'like', 'ned_flander']\n",
            "['neddie', 'toss', 'matter']\n",
            "['forget', 'thing', 'little', 'well', 'simpson', 'drag', 'beer', 'blame', 'erupt']\n",
            "['turn', 'snarl', 'beast', 'talk', 'flunk', 'old', 'turn', 'cheek', 'test']\n",
            "['ned', 'maybe', 'talk']\n",
            "['hello', 'reverend', 'lovejoy']\n",
            "['mrs', 'lovejoy', 'minute', 'honey', 'honey', 'wake', 'sound_like', 'ned_flander', 'have', 'sort', 'crisis']\n",
            "['ugh', 'probably', 'step', 'worm', 'hello', 'ned']\n",
            "['hey', 'homer_simpson', 'oh', 'perfect', 'opportunity', 'follow', 'letter']\n",
            "['reverend', 'sorry', 'bother', 'hour', 'throw', 'man', 'house', 'today', 'feel', 'like', 'violate', 'matthew']\n",
            "['love', 'thy', 'neighbor']\n",
            "['oh', 'oh', 'matthew', 'yeah', 'right', 'right', 'know', 'ned', 'good', 'book', 'say', 'gentle', 'answer', 'turneth', 'away', 'wrath']\n",
            "['gentle', 'answer', 'jim', 'dandy', 'idea', 'bless', 'reverend']\n",
            "['blame', 'upset', 'homer', 'want', 'letter', 'leave']\n",
            "['brother', 'love', 'feel', 'great', 'sadness', 'bosom']\n",
            "['think', 'terrible', 'man', 'open', 'heart', 'fun']\n",
            "['neighbor', 'forever', 'oh', 'ned_flander']\n",
            "['read', 'bosom', 'dad']\n",
            "['wish', 'family', 'close', 'flander']\n",
            "['okay', 'okay', 'right', 'right', 'right', 'let', 'miniature', 'golf', 'follow', 'round', 'frosty', 'chocolate', 'milkshake']\n",
            "['hmmm', 'go', 'wash', 'hair']\n",
            "['study', 'math', 'fair', 'win', 'bring', 'home', 'brand', 'new', 'protractor']\n",
            "['bad', 'live', 'farm', 'let', 'boy']\n",
            "['heh_heh', 'heh_heh']\n",
            "['practice', 'shot', 'boy']\n",
            "['homeboy', 'stroke', 'limit']\n",
            "['know', 'know', 'come', 'baby', 'pleeze', 'pleeze', 'pleeze']\n",
            "['hi', 'simpson', 'have', 'fun']\n",
            "['ah', 'play', 'little', 'mini', 'golf', 'todd', 'meister']\n",
            "['right', 'fun', 'oh', 'look', 'like', 'have', 'little', 'trouble']\n",
            "['shot', 'impossible', 'jack', 'nicholson']\n",
            "['difficult', 'mr_simpson', 'good', 'strategy', 'play', 'conservatively', 'hug', 'rail', 'will', 'set', 'easy', 'deuce']\n",
            "['oh', 'huh', 'go']\n",
            "['good', 'shot', 'toddsky']\n",
            "['final', 'score', 'bart', 'homer', 'let', 'plus', 'plus', 'plus', 'plus', 'plus']\n",
            "['wow', 'prize', 'dollar']\n",
            "['wow', 'free', 'balloon', 'enter']\n",
            "['little', 'bartley', 'thinking', 'enter', 'tournament']\n",
            "['yeah', 'enter', 'go', 'win', 'boy']\n",
            "['hey', 'like', 'confidence', 'hope', 'put', 'pressure', 'boy', 'todd', 'awfully', 'good']\n",
            "['oh', 'yeah', 'think', 'fruit', 'loin', 'beat', 'fruit', 'loin', 'day', 'week']\n",
            "['dad', 'win', 'life']\n",
            "['son', 'time', 'go_to', 'okay', 'lose']\n",
            "['stay', 'stay', 'good', 'dog', 'head']\n",
            "['talk', 'boy', 'head', 'follow']\n",
            "['okay', 'work', 'time', 'head', 'follow']\n",
            "['putter', 'bat', 'baseball', 'player', 'violin', 'guy', 'tha', 'violin', 'guy', \"c'mon\", 'putter']\n",
            "['wanna', 'try', 'little', 'hard', 'son', 'come', 'girl']\n",
            "['picture', 'enemy', 'todd', 'flander', 'day', 'want', 'spend', 'minute', 'stare', 'concentrate', 'hate', 'glorious', 'charlene', 'annihilate']\n",
            "['charlene', 'start', 'hate']\n",
            "['homer', 'help', 'overhear', 'warp', 'bart', 'mind']\n",
            "['worried', 'make', 'big_deal', 'silly', 'little', 'kiddie', 'golf', 'tournament']\n",
            "['marge', 'big', 'chance', 'flanders']\n",
            "['way', 'feel', 'good', 'make', 'look', 'bad', 'tired', 'make', 'people', 'feel', 'good']\n",
            "['lis', 'guy', 'chess', 'matter']\n",
            "['blockade', 'bishop', 'little', 'value', 'think', 'refer', 'pawn']\n",
            "['know', 'time', 'like', 'thankful', 'dad', 'little', 'interest', 'bart', 'think', 'help']\n",
            "['journey', 'begin', 'library']\n",
            "['hi', 'mrs', 'norton']\n",
            "['hey', 'gang', 'okay', 'bart', 'card', 'catalog']\n",
            "['let', 'golf', 'anecdote', 'eisenhower', 'fashion', 'humor', 'japanese', 'obsession', 'ah', 'put']\n",
            "['finally', 'important', 'book', 'tao', 'te', 'ching', 'lao', 'tzu']\n",
            "['lisa', 'afford', 'book']\n",
            "['bart', 'go_to', 'borrow']\n",
            "['want', 'shut', 'logical', 'mind']\n",
            "['like', 'uncarved', 'stone']\n",
            "['bart', 'pretend', 'know', 'talk']\n",
            "['bart', 'riddle', 'sound', 'hand', 'clapping']\n",
            "['bart', 'thousand', 'year_old', 'riddle', 'answer', 'suppose', 'clear', 'mind', 'conscious', 'thought']\n",
            "['answer', 'lisa', 'listen']\n",
            "['let', 'try', 'tree', 'fall', 'wood', 'sound']\n",
            "['bart', 'sound', 'exist', 'hear']\n",
            "['basis', 'game', 'simple', 'geometry', 'hit', 'ball']\n",
            "['believe', 'actually', 'find', 'practical', 'use', 'geometry']\n",
            "['flander', 'care', 'look', 'like', 'bart', 'go_to', 'mop', 'floor', 'son', 'ugly', 'butt']\n",
            "['sir', 'good', 'man', 'win']\n",
            "['ah', 'good', 'man', 'win', 'mating', 'loser']\n",
            "['minute', 'simpson', 'think', 'son', 'good', 'chance']\n",
            "['oh', 'yeah', 'wanna', 'bet']\n",
            "['yeah', 'bet', 'man']\n",
            "['right', 'wager', 'batch', 'wife', 'delicious', 'blueberry', 'muffin', 'wife', 'homemade', 'wind', 'chime']\n",
            "['afraid', 'real', 'bet']\n",
            "['know', 'simpson', 'start', 'annoy']\n",
            "['henny', 'penny', 'bart', 'win', 'tomorrow', 'mow', 'lawn']\n",
            "['right', 'todd', 'win', 'mow', 'lawn', 'decent', 'job', 'change']\n",
            "['better', 'mow', 'lawn', 'wife', 'sunday', 'dress']\n",
            "['father', 'loser', 'mow', 'lawn']\n",
            "['eh', 'eh', 'minute', 'loser', 'harsh', 'word', 'boy', 'win']\n",
            "['oh', 'man', 'fine']\n",
            "['father', 'boy', 'win', 'mow', 'lawn', 'wife', 'sunday', 'dress']\n",
            "['suppose', 'sign', 'hope', 'blood', 'will', 'necessary']\n",
            "['left', 'arm', 'straight', 'bart', 'rotate', 'shoulder']\n",
            "['look', 'son', 'ask', 'try']\n",
            "['anybody', 'try', 'want', 'win']\n",
            "['marge', 'honest', 'opinion']\n",
            "['good_morning', 'son', 'oh', 'way', 'today', 'day', 'big', 'tournament', 'better', 'win']\n",
            "['heh_heh', 'crazy', 'marmaduke']\n",
            "['aim', 'octopus', \"'\", 'tentacle']\n",
            "['bank', 'pink', 'tombstone']\n",
            "['state', 'bliss', 'attain', 'extinction', 'self']\n",
            "['bart', 'lumberjack', 'breakfast', 'little', 'golfer']\n",
            "['mom', 'bart', 'strict', 'diet', 'complex', 'carbohydrate', 'steak', 'logy']\n",
            "['ohhh', 'will', 'logy']\n",
            "['oats', 'champion', 'thoroughbred', 'eat', 'win', 'kentucky', 'derby']\n",
            "['news', 'flash', 'lisa', 'bart', 'horse', 'eat', 'steak', 'boy']\n",
            "['good', 'afternoon', 'everybody', 'welcome', 'finale', 'stirring', 'afternoon', 'miniature', 'golf', 'cream', 'rise', 'wheat', 'bid', 'farewell', 'chaff', 'approach', 'championship', 'match', 'warrior', 'remain', 'heretofore', 'unknown', 'bart_simpson', 'todd', 'flander', 'skilled', 'year_old', 'blade']\n",
            "['bart', 'have', 'receive', 'word', 'encouragement', 'sure', 'suppose', 'sound', 'go', 'believe']\n",
            "['hey', 'flander', 'use', 'pray', 'thing', 'win']\n",
            "['actually', 'simpson', 'pray', 'get', 'hurt']\n",
            "['oh', 'flan', 'der', 'matter', 'time', 'tomorrow', 'wear', 'high', 'heel']\n",
            "[\"'\", 'fraid', 'infinity']\n",
            "[\"'\", 'fraid', 'infinity', 'plus']\n",
            "['young', 'flander', 'honor', 'tee']\n",
            "['get', 'chance', 'yes', 'sir']\n",
            "['tree', 'fall', 'wood', 'tree', 'fall', 'wood', 'tree', 'fall']\n",
            "['battle', 'truly', 'join']\n",
            "['woo_hoo', 'hoo']\n",
            "['mercy', 'weak', 'todd']\n",
            "['look', 'courage', 'oxford', 'english', 'dictionary', 'come', 'photo', 'gladiator', 'approach', 'final', 'hole', 'shadow', 'great', 'emancipator', 'deadlocke', 'stroke', 'happy', 'par', 'soon', 'man', 'emerge', 'triumphant', 'drink', 'naught', 'champagne', 'opponent', 'taste', 'bitter', 'defeat', 'oft', 'cruel', 'game']\n",
            "['okay', 'son', 'recover']\n",
            "['come', 'bart', 'remember', 'vince', 'lombardi', 'say', 'lose', 'family']\n",
            "['man', 'show', 'good', 'form', 'sort', 'pressure', 'unhinge', 'steeli', 'competitor']\n",
            "['pretty', 'tense', 'todd']\n",
            "['yeah', 'knee', 'shake', 'get', 'butterfly', 'stomach', 'guess', 'build', 'character']\n",
            "['want', 'build', 'character', 'let', 'quit']\n",
            "['decide', 'equally', 'good']\n",
            "['want', 'draw', 'man']\n",
            "['lady_gentleman', 'draw']\n",
            "['forgive', 'old', 'brit', 'crying', 'stirring', 'display', 'gallantry', 'sportsmanship', 'mountbatten', 'give', 'india', 'punjabs']\n",
            "['homer', 'kid', 'show', 'today', 'huh', 'work', 'winner', 'thank', 'heaven', 'silly', 'wager', \"'\", 'er', 'pal']\n",
            "['ohhh', 'go_to', 'welch', 'bet']\n",
            "['talk', 'boy', 'lose']\n",
            "['get', 'right', 'writing']\n",
            "['small', 'price', 'pay', 'humiliate']\n",
            "['oh', 'good', 'dress']\n",
            "['feeling', 'someday', 'describe', 'psychiatrist']\n",
            "['listen', '-PRON-', 'laugh', 'humiliating', 'go_to', 'live', 'damn', 'flander']\n",
            "['halftime', 'marge', 'halftime']\n",
            "[\"y'know\", 'simpson', 'feel', 'kinda', 'silly', 'hay', 'know', 'kinda', 'remind', 'good', 'ole', \"'\", 'fraternity', 'day']\n",
            "['oh_god', 'enjoy']\n",
            "['bart', 'stop', 'fight', 'sister']\n",
            "['bart', 'family', 'glue']\n",
            "['stop', 'thanksgive', 'glue', 'friendly', 'glue', 'away', 'glue', 'glue']\n",
            "['dad', 'glue', 'territoriality', 'want', 'glue']\n",
            "['hey', 'man', 'want', 'stupid', 'glue']\n",
            "['uh', 'oh', 'come', 'friend', 'bullwinkle', 'j', 'moose']\n",
            "['heh_heh', 'heh', 'bullwinkle', 'antler', 'spring', 'leak']\n",
            "['know', 'hurt', '-PRON-', 'use', 'cartoon', 'year']\n",
            "['son', 'tradition', 'start', 'build', 'balloon', 'flash', 'pan', 'cartoon', 'character', 'turn', 'parade', 'farce']\n",
            "['maggie', 'unveil', 'centerpiece', 'family']\n",
            "['homer', 'promise', 'nice', 'sister']\n",
            "['tribute', 'trailblaze', 'woman', 'country', 'great', 'georgia', \"o'keefe\", 'susan', 'b', 'anthony', 'marjorie', 'stoneman', 'douglas', 'sure', 'hear', 'work', 'life', 'preserve', 'florida', 'everglade']\n",
            "['simpson', 'woman', 'like', 'contribute']\n",
            "['okay', 'let', 'cranberry', 'sauce']\n",
            "['second', 'drawer', 'right']\n",
            "['oh', 'get', 'ya']\n",
            "['break', 'mom', 'mom', 'break', 'mom', 'break', 'mom', 'break', 'mom', 'break', 'mom', 'break']\n",
            "['think', 'break', 'honey', 'let', 'try']\n",
            "['ah', 'cranberry', 'sauce', 'la', 'bart']\n",
            "['stick', 'refrigerator', 'bart', 'bart']\n",
            "['maggie', 'silver', 'blue', 'guy', 'dallas', 'cowboy', 'daddy', 'favorite', 'team', 'want', 'lose', 'half', 'point', 'understand']\n",
            "['oh', 'kogen', 'get', 'wolodarsky', 'open', 'way', 'field', 'complete', 'ooooh', 'hit']\n",
            "['oh', 'yeah', 'cold', 'gil']\n",
            "['oh', 'yes', 'sir', 'look', 'like', 'feed', 'thanksgive', 'dinner', 'tube']\n",
            "['heh_heh', 'hope', 'fit', 'turkey']\n",
            "['homer', 'pick', 'grampa']\n",
            "['thing', 'swedish', 'meatball']\n",
            "['mmm', 'hmmm', 'trout', 'almondine']\n",
            "['people', 'find', 'turkey', 'little', 'dry']\n",
            "['mmm_hmm', 'want', 'option']\n",
            "['hi', 'patty', 'hi', 'selma']\n",
            "['good', 'ya', 'get_to', 'pick', 'old_man', \"'\", 'bye']\n",
            "['set', 'fabulous', 'half', 'time', 'feature', 'groom', 'young', 'getter', 'hurray']\n",
            "['oh', 'love', 'kid', 'get', 'great', 'attitude']\n",
            "['lady_gentleman', 'hurray', 'invite', 'join', 'salute', 'great', 'hemisphere', 'earth', 'western', 'hemisphere', 'dancin', \"'\", 'est', 'hemisphere']\n",
            "['sit', 'delicious', 'turkey', 'puree', 'happy', 'news', 'follow', 'people', 'relative', 'wish', 'today', 'antonowski', 'conroy', 'falcone', 'martin', 'thorsen', 'walsh']\n",
            "['oh', 'mrs', 'spencer']\n",
            "['oh', 'know', 'forget']\n",
            "['come', 'dad', 'let', 'outta']\n",
            "['slow', 'boy', 'hurry']\n",
            "['oh', 'sure', 'blast', 'let']\n",
            "['laryngitis', 'hurt', 'talk', 'thing', 'right']\n",
            "['silverdome', 'ablaze', 'flashbulb', 'hurray', 'leave', 'field', 'course', 'stadium', 'big', 'flash', 'picture', 'work', 'care']\n",
            "['way', 'lay', 'fire', 'kindling']\n",
            "['thing', 'go_to', 'roar', 'time']\n",
            "['caveman', 'start', 'fire']\n",
            "['dinner', 'dinner', 'time', 'everybody', 'dinner']\n",
            "['okay', 'lisa', 'ready', 'centerpiece']\n",
            "['lisa', 'goodness', 'impressive']\n",
            "['holy', 'moly', 'big', 'see']\n",
            "['say', 'gift', 'definitely', 'family', 'right', 'mom']\n",
            "['tell', 'hour', 'labor', 'love', 'homage', 'american', 'hero', 'fight', 'war']\n",
            "['da_da', 'daah', 'da_da', 'dah', 'daaahhh']\n",
            "['speak', 'hero', 'tom', 'turkey']\n",
            "['take', 'valuable', 'real', 'estate']\n",
            "['hey', 'bart', 'stop']\n",
            "['wait_minute', 'sure', 'room']\n",
            "['baaart', 'wreck', 'let', 'work', 'forever']\n",
            "['hey', 'get', \"'\", 'er', 'go']\n",
            "['right', 'bart', 'room']\n",
            "['okay', 'white', 'meat', 'stuffing', 'send', 'pumpkin', 'pie', 'minute']\n",
            "['yes', 'hope', 'happy', 'bart', 'ruin', 'thanksgive']\n",
            "['ruin', 'thanksgiving', 'buncha', 'jerks', 'blame']\n",
            "['lord', 'especially', 'thankful', 'nuclear_power', 'clean', 'safe', 'energy', 'source', 'solar', 'pipe', 'dream', 'like', 'thank', 'occasional', 'moment', 'peace', 'love', 'family', 'experienced', 'today', 'see', 'happen', 'oh', 'lord', 'honest', 'pathetic', 'family', 'universe']\n",
            "['worry', \"marge'll\", 'fix']\n",
            "['honey', 'food', 'get', 'cold']\n",
            "['lisa', 'sorry', 'happen']\n",
            "['mom', 'pour', 'heart', 'centerpiece', 'thing', 'like', 'happen', 'family']\n",
            "['notice', 'feel', 'like', 'come']\n",
            "['bart', 'come', 'dinner', 'soon', 'ready', 'apologize', 'sister', 'go', 'real', 'apology', 'everybody', 'mean']\n",
            "['apologize', 'clear', 'table', 'have', 'sense', 'humor', 'think', 'starve', 'apology', 'ha']\n",
            "['uh', 'oh', 'mean', 'good']\n",
            "['hey', 'drop', 'drumstick', 'bad', 'dog', 'bad', 'santa_little', 'helper', 'come', 'gimme', 'gimme']\n",
            "['hey', 'boy', 'come', 'good', 'dog', 'come', 'need', 'thanksgive', 'dinner']\n",
            "['wow', 'swan', 'ky']\n",
            "['mmmm', 'delicious', 'smither', 'year', 'outstrip', 'succulence']\n",
            "['thank', 'sir', 'oh', 'like', 'candied', 'yam']\n",
            "['oh', 'eat', 'bite', 'dispose', 'save', 'room', 'special', 'pumpkin', 'pie']\n",
            "['cool', 'windowsill', 'sir']\n",
            "['mmmm', 'stay', 'boy']\n",
            "['mr_burns', 'base', 'command']\n",
            "['intruder', 'appear', 'young', 'male', 'age']\n",
            "['see', 'good', 'meal', 'generation', 'destroy', 'madness', 'brother', 'soul', 'carve', 'slice', 'spikey', 'haired', 'demon']\n",
            "['worry', 'boy', 'grub', 'pay']\n",
            "['cool', 'wrong', 'track']\n",
            "['buck', 'hey', 'bleed']\n",
            "['hey', 'got_to', 'eighteen', 'sell', 'blood', 'let', 'd']\n",
            "['hmmm', 'okay', 'homer', 'relax']\n",
            "['risk', 'lose', 'voice', 'let', 'thing', 'sorry', 'come']\n",
            "['boy', 'go', 'apologize']\n",
            "['homer', 'stubborn', 'fold', 'instantly', 'true', 'homer']\n",
            "['buck', 'free', 'cookie', 'country']\n",
            "['cute', 'little', 'guy']\n",
            "['startin', \"'\", 'come']\n",
            "['look', 'little', 'pale', 'son']\n",
            "['right', 'big', 'one', 'free', 'grub', 'boot', 'viva', 'skid', 'row', 'hey', 'anchor', 'dude', 'channel']\n",
            "['oh', 'yeah', 'thankful', 'get', 'story']\n",
            "['hey', 'listen', 'man']\n",
            "['wait', 'go', 'year', 'lone', 'conscience', 'salving', 'day', 'toss', 'people', 'bone', 'turkey', 'bone', 'suppose', 'well']\n",
            "['will', 'find', 'freddie', 'freeloader', 'emmett', 'kelly', 'charlie', 'chaplin', 'beloved', 'little', 'tramp']\n",
            "['pompous', 'blow', 'dry', 'college', 'boy']\n",
            "['know', 'girlfriend', 'weather', 'lady']\n",
            "['lisa', 'want', 'read', 'poem', 'write']\n",
            "['howl', 'unappreciate', 'lisa_simpson', 'see', 'good', 'meal']\n",
            "['son', 'family', 'watch', 'like']\n",
            "['yes', 'kent', 'ha_ha', 'apologize']\n",
            "['oh', 'sweet', 'little', 'bart']\n",
            "['hello', 'operator', 'gimme', 'number']\n",
            "['hey', 'thank', 'help', 'fella', 'reporter', 'smell', 'local', 'emmy']\n",
            "['yeah', 'rootin', \"'\", 'guy']\n",
            "['hey', 'get', 'place', 'sleep', 'tonight', 'bart']\n",
            "['yeah', 'family', 'kind', 'hang']\n",
            "['sound', 'pretty', 'sweet']\n",
            "['listen', 'guy', 'think', 'uh', 'feel', 'weird', 'take', 'money', 'kid', 'think', 'maybe']\n",
            "['forget', 'report', 'rescue', 'mission']\n",
            "['nah', 'check', 'long', 'go']\n",
            "['think', 'reason', 'run_away']\n",
            "['uh', 'kinda', 'yell', 'send', 'room', 'try', 'force', 'apologize', 'sister']\n",
            "['say', 'ruin', 'thanksgive']\n",
            "['good', 'thanksgiving', 'eh', 'boy']\n",
            "['comforting', 'know', 'voice']\n",
            "['let', 'home', 'declare', 'legally', 'dead', 'collect', 'insurance']\n",
            "['homer', 'terrible', 'thing', 'happen', 'blame']\n",
            "['child', 'need', 'discipline', 'ask', 'syndicated', 'advice', 'columnist']\n",
            "['hey', 'everybody', 'home']\n",
            "['oh', 'special', 'little', 'guy', 'worried']\n",
            "['oh', 'great', 'boy', 'afraid', 'lose']\n",
            "['welcome', 'bart', 'sorry', 'terrible', 'fight']\n",
            "['bart', 'like', 'sister']\n",
            "['yeah', 'boy', 'knee', 'beg', 'forgiveness']\n",
            "['yeah', 'beg', 'bart', 'beg']\n",
            "['lisa', 'beg', 'forgive']\n",
            "['fault', 'america', 'lose', 'way']\n",
            "['sorry', 'sorry', 'sorry', 'sorry', 'sorry']\n",
            "['sorry', 'right', 'sorry', 'come']\n",
            "['wiffle', 'ball', 'frisbee', 'water', 'rocket', 'hit', 'jackpot']\n",
            "['sellout', 'crowd', 'super_bowl', 'simpson', 'second', 'leave', 'simpson', 'fade', 'get', 'simpson', 'open']\n",
            "['touchdown', 'simpson', 'boy', 'want', 'win', 'superbowl']\n",
            "['dear', 'log', 'brother', 'miss', 'maybe', 'fault', 'fail', 'abuse', 'good', 'humor', 'miss', 'know']\n",
            "['hey', 'lis', 'lisa', 'bart']\n",
            "['bart', 'everybody', 'worried']\n",
            "['bart', 'burn', 'centerpiece']\n",
            "['know', 'know', 'know', 'enjoy', 'know']\n",
            "['bart', 'reason', 'apologize', 'look', 'deep', 'inside', 'find', 'spot', 'wish', 'feel', 'bad', 'hurt', 'sister', 'feeling']\n",
            "['hmmm', 'hmmm', 'look', 'spot', 'hmmm', 'hmmm', 'hmmm', 'check', 'stupid', 'go_to', 'find', 'wreck', 'work', 'hard', 'cr', 'uh', 'oh']\n",
            "['know', 'marge', 'great', 'parent']\n",
            "['oh', 'lord', 'bless', 'day', 'thank', 'thee', 'give', 'family', 'crack', 'togetherness', 'amen']\n",
            "['today', 'rasputin', 'friendly', 'russian']\n",
            "['hey', 'mad', 'russian']\n",
            "['yes', 'afraid', 'force', 'history', 'change', 'wrestling', 'forever']\n",
            "['challenger', 'university', 'heidelburg', 'professor', 'werner', 'von', 'brawn', 'brawn', \"'\", 'w', \"'\"]\n",
            "['titan', 'height', 'career', 'ah', 'ask', 'go', 'hell', 'match']\n",
            "['oh', 'bart', 'hope', 'take', 'seriously', 'year_old', 'know', 'choreograph', 'ballet']\n",
            "['rasputin', 'get', 'reach', 'hand', 'professor', 'get', 'patented', 'coma', 'lock', 'ask', 'go_to', 'hell', 'match']\n",
            "['oh', 'look', 'kiss', 'muscle', 'boo']\n",
            "['rasputin', 'spin', 'professor', 'like', 'auto', 'gyro', 'get', 'disorient']\n",
            "['hey', 'milhouse', 'crank']\n",
            "['hey', 'engrave', 'bar', 'stool']\n",
            "['ref', 'issue', 'warning', 'rasputin']\n",
            "['oh', 'oh', 'referee', 'permit']\n",
            "['saturday', 'night', 'life', 'change', 'forever']\n",
            "['saturday', 'springfield', 'speedway']\n",
            "['don', 'crusher', 'woodard']\n",
            "['jon', 'skunk', 'trumane']\n",
            "['team', 'tomomatsu', 'dirt', 'ride', 'dunk', 'master', 'year', 'big']\n",
            "['monster', 'truck', 'rally']\n",
            "['ton', 'story', 'car', 'crunching', 'fire', 'breathe', 'prehistoric', 'insanity']\n",
            "['night', 'springfield', 'speedway', 'saturday']\n",
            "['miss', 'better', 'dead', 'jail']\n",
            "['announcement', 'family', 'growth', 'thing', 'bart', 'think', 'monster', 'truck', 'rally', 'saturday']\n",
            "['uh', 'monster', 'truck', 'rally', 'growth', 'thing', 'think']\n",
            "['lisa', 'recital', 'saturday', 'night']\n",
            "['play', 'solo', 'miss', 'saturday', 'advise', 'start', 'look', 'child', 'therapist', 'sunday']\n",
            "['oh', 'cruel', 'fate', 'mock']\n",
            "['come', 'time', 'little', 'truck', 'game', 'start']\n",
            "['lisa', 'recital', 'start', \"o'clock\"]\n",
            "['people', 'let', 'good', 'assembly', 'manner', 'people', 'people', 'quiet', 'flick', 'light', 'thank', 'lady_gentleman', 'parent', 'music', 'lover', 'welcome', 'series', 'saturday', 'evening', 'concert']\n",
            "['tonight', 'sherbert', 'uh', 'schubert', 'unfinished', 'symphony']\n",
            "['oh', 'good', 'unfinished', 'long']\n",
            "['remember', 'child', 'stay', 'seven']\n",
            "['longer', 'sherbert', 'plan', 'make', 'piece', 'junk']\n",
            "['oh', 'lisa', 'wonderful', 'certainly', 'come', 'long', 'way', 'fingering']\n",
            "['thank', 'flander', 'big', 'know']\n",
            "['todd', 'solo', 'dad']\n",
            "['shhh', 'come', 'son', 'come']\n",
            "['come', 'flander', 'bad']\n",
            "['homer', 'drive', 'defensively']\n",
            "['good', 'defense', 'good', 'offense']\n",
            "['fast', 'dad', 'truckasaurous', 'await']\n",
            "['pull', 'pull', 'dog']\n",
            "['let', 'crack', 'windshield', 'melted', 'bumper', 'puncture', 'radiator', 'tooth', 'mark', 'trunk', 'plus', 'frame', 'damage', 'check', 'care']\n",
            "['uh', 'mrs_simpson', 'um', 'leo', 'g', 'clark', 'inventor', 'owner', 'operator', 'truckasaurous', 'let', 'truckasaurous', 'feel', 'badly', 'happen', 'team', 'truckasaurous', 'like', 'enjoy', 'half', 'bottle', 'domestic', 'champagne', 'good', 'sport']\n",
            "['hmmm', 'thank', 'gee', 'nice', 'monster', 'truck', 'rally', 'look', 'homer', 'champagne']\n",
            "['majestic', 'undercoating', 'proud', 'present', 'ms', 'monster']\n",
            "['wow', 'woman', 'mud', 'pull', 'driver']\n",
            "['barrier', 'break', 'right', 'sister']\n",
            "['gimme', 'nachos', 'homersaurous']\n",
            "['event', 'evening', 'special', 'surprise', 'guest', 'world', 'great', 'daredevil', 'man', 'stranger', 'danger', 'action', 'traction', 'captain', 'lance', 'murdock']\n",
            "['yes', 'see', 'daredevil', 'night', 'know', 'monkey', 'monkey']\n",
            "['hmmm', 'think', 'know', 'discourage', 'sort', 'behavior']\n",
            "['sorry', 'bart', 'dude', 'emergency']\n",
            "['lady_gentleman', 'especially', 'little', 'child', 'glad', 'witness', 'grisly', 'death', 'tonight', 'dangerous', 'stunt', 'deaf', 'defy', 'nature', 'gravity', 'leapin', \"'\", 'tank', 'water', 'fill', 'man', 'eat', 'great', 'white', 'shark', 'deadly', 'electric', 'eel', 'ravenous', 'piranhas', 'bone', 'crush', 'alligator', 'frightening', 'king', 'jungle', 'ferocious', 'lion']\n",
            "['forget', 'add', 'real', 'element', 'danger', 'drop', 'human', 'blood']\n",
            "['chance', 'survive', 'let', 'seat', 'belt', 'save', 'life', 'buckle']\n",
            "['fun', 'fill', 'evening']\n",
            "['lady_gentleman', 'year_old', 'brave', 'bold', 'class', 'risk', 'ass', 'world', 'great', 'daredevil', 'bart_simpson']\n",
            "['bart', 'bart', 'home', 'son']\n",
            "['dad', 'want', 'daredevil']\n",
            "['kid', 'stupid', 'thing']\n",
            "['spare', 'lecture', 'lady']\n",
            "['oh', 'little', 'boy']\n",
            "['come', 'marge', 'mad', \"'\", 'be']\n",
            "['well', 'right', 'get', 'stitch']\n",
            "['mrs_simpson', 'bart', 'tell', 'injure', 'train', 'career', 'death', 'defiance']\n",
            "['hey', 'otto', 'use', 'microphone']\n",
            "['bart', 'ward', 'child', 'hurt', 'imitate', 'stunt', 'see', 'television', 'movie', 'legitimate', 'stage']\n",
            "['little', 'boy', 'break', 'leg', 'try', 'fly', 'like', 'superman']\n",
            "['boy', 'brother', 'hit', 'head', 'wrench', 'mimic', 'recent', 'tv', 'wrestling', 'match']\n",
            "['will', 'subject', 'horror', 'stooge', 'ward']\n",
            "['gee', 'realize', 'tv', 'dangerous', 'influence']\n",
            "['tragic', 'small', 'price', 'pay', 'countless', 'hour', 'notch', 'entertainment']\n",
            "['amen', 'bart', 'dr_hibbert', 'point']\n",
            "['certainly', 'dad', 'learn', 'real', 'lesson', 'today', 'thank', 'dr_hibbert']\n",
            "['oh', 'man', 'king']\n",
            "['thank', 'about', 'hand', 'brave', 'little', 'animal']\n",
            "['oh', 'hi', 'kid', 'thank']\n",
            "['okay', 'field', 'tripper', 'bus']\n",
            "['runnin', \"'\", 'milhouse', 'kid', 'kick', 'jump', 'love', 'easy']\n",
            "['get', 'challenge', 'worthy']\n",
            "['hello', 'child', 'welcome', 'springfield', 'gorge']\n",
            "['man', 'thing', 'pretty', 'gnarly', 'bet', 'throw', 'dead', 'body', \"one'd\", 'find']\n",
            "['otto', 'go_to', 'leap', 'springfield', 'gorge', 'skateboard']\n",
            "['know', 'bart', 'adult', 'feel']\n",
            "['want', 'tell', 'jump']\n",
            "['attention', 'saturday', 'jump', 'springfield', 'gorge', 'skateboard', 'good', 'possibility', 'plunge', 'bloody', 'death', 'hope', 'thank']\n",
            "['springfield', 'gorge', 'bart', 'kill']\n",
            "['lisa', 'know', 'explain', 'thrill', 'jump', 'stuff', 'read']\n",
            "['thank', 'arrange', 'dr_hibbert']\n",
            "['oh', 'stem', 'tide', 'entertainment', 'relate', 'injury', 'child', 'meet', 'world', 'great', 'daredevil', 'lance', 'murdock']\n",
            "['lance', 'lisa', 'bart_simpson', 'bart', 'big', 'fan']\n",
            "['honor', 'lance', 'feel']\n",
            "['ow', 'doc', 'hear', 'snap']\n",
            "['hmm', 'afraid', 'bone', 'break']\n",
            "['worry', 'partner', 'break', 'thumb', 'dozen', 'time', 'hey', 'bet', 'like', 'autograph', 'nurse']\n",
            "['bart', 'fine', 'sir']\n",
            "['bart', 'thank', 'visit', 'springfield', 'general', 'hospital', 'visit', 'ray', 'sunshine', 'cloudy', 'day', 'pal', 'captain', 'lance', 'murdock']\n",
            "['wow', 'man', 'thank', 'lance']\n",
            "['welcome', 'thing', 'mouth']\n",
            "['mr', 'murdock', 'brother', 'think', 'jump', 'springfield', 'gorge', 'skateboard']\n",
            "['mean', 'bart', 'phoney', 'baloney', 'promise', 'expect', 'promise']\n",
            "['let', 'start', 'say', 'good', 'son', 'good', 'young', 'people', 'take', 'interest', 'danger', 'lot', 'people', 'go_to', 'tell', 'crazy', 'maybe', 'right', 'fact', 'matter', 'bone', 'heal', 'chick', 'dig', 'scar', 'united_states', 'america', 'good', 'doctor', 'daredevil', 'ratio', 'world']\n",
            "['welcome', 'little', 'pardner', 'way', 'tell', 'nurse', 'ready', 'sponge', 'bath', 'fringe', 'benefit', 'nurse']\n",
            "['springfield', 'gorge', 'think', 'settle', 'daredevil', 'junk']\n",
            "['sorry', 'bart', 'get', 'hurt', 'die', 'despite', 'extra', 'attention', 'receive', 'miss']\n",
            "['bart', 'forbid', 'jump', 'gorge']\n",
            "['room', 'bart', 'glad', 'somebody', 'finally', 'step', 'end', 'nonsense']\n",
            "['hey', 'man', 'tell', 'way', 'watch', 'hour', 'day', 'minute', 'turn', 'grab', 'skateboard', 'headin', \"'\", 'gorge']\n",
            "['get', 'marge', 'good', 'dead']\n",
            "['homer', 'father', 'get', 'try', 'reason']\n",
            "['oh', 'work', 'goner']\n",
            "['oh', 'come', 'homer', 'heart', 'heart', 'talk', 'son', 'get', 'try']\n",
            "['way', 'jump', 'gorge']\n",
            "['look', 'know', 'stop', 'thing', 'ask', 'promise', 'will', 'jump', 'gorge']\n",
            "['okay', 'dad', 'promise', 'jump', 'springfield', 'gorge']\n",
            "['know', 'marge', 'get', 'pretty', 'good', 'kid']\n",
            "['get', 'pretty', 'good', 'father']\n",
            "['think', 'say', 'noon']\n",
            "['aw', 'build', 'suspense']\n",
            "['hey', 'boy', 'wanna', 'toss', 'old']\n",
            "['little', 'liar', 'go_to', 'play', 'pickle']\n",
            "['boy', 'try', 'order', 'try', 'punish', 'god', 'help', 'try', 'reason', 'thing', 'leave', 'jump', 'gorge']\n",
            "['way', 'like', 'witness', 'family', 'member', 'stupidly', 'risk', 'life', 'good', 'reason']\n",
            "['wait', 'dad', 'will', 'jump', 'anymore', 'promise']\n",
            "['think', 'get', 'gut', 'try', 'raise', 'kid']\n",
            "['dash', 'rosemary', 'smidgin', 'thyme', 'pinch', 'marjoram']\n",
            "['know', 'marge', 'good', 'pork_chop', 'world']\n",
            "['oh', 'homer', 'special', 'extra', 'ingredient', 'care']\n",
            "['sprinkle', 'chervil', 'half', 'teaspoon', 'turmeric', 'whisper', 'msg']\n",
            "['marge', 'go_to', 'build', 'spice', 'rack']\n",
            "['trouble', 'get', 'garageful', 'tool', 'use']\n",
            "['hey', 'kid', 'spy', 'itchy_scratchy', 'port', 'bow']\n",
            "['know', 'stuff', 'come', 'handy', 'day', 'let', 'ah', 'complete', 'handyman', 'bookshelf', 'volume', 'spice', 'rack']\n",
            "['pick', 'ham', 'mer']\n",
            "['hey', 'dad', 'head']\n",
            "['humph', 'innocent', 'child', 'idea', 'attack', 'father', 'mallet']\n",
            "['maggie', 'bad', 'baby']\n",
            "['away', 'marge', 'get', 'crazy', 'look', 'eye']\n",
            "['hey', 'mom', 'watch']\n",
            "['will', 'watch', 'cartoon', 'anymore']\n",
            "['mom', 'cartoon', 'away', 'grow', 'sense', 'humor', 'robot']\n",
            "['hear', 'cartoon', 'tough', 'break', 'man']\n",
            "['hey', 'watch', 'itchy_scratchy', 'house']\n",
            "['hey', 'crazy', 'work']\n",
            "['hear', 'will', 'rest', 'week', 'tell', 'baby', 'beat', 'oh', 'bad', 'excuse', 'think', 'wise', 'guy']\n",
            "['wonder', 'bart', 'lisa', 'late', 'get', 'home', 'school']\n",
            "['hey', 'come', 'watch', 'cartoon', 'kid']\n",
            "['homer', 'try', 'work']\n",
            "['catalogue', 'violence', 'cartoon', 'think', 'adult', 'actually', 'sit', 'watch']\n",
            "['kind', 'warped', 'human', 'find', 'funny']\n",
            "['kind', 'entertainment', 'think', 'suitable', 'young', 'impressionable', 'viewer']\n",
            "['tell', 'go', 'go', 'write', 'letter']\n",
            "['dear', 'purveyor', 'senseless', 'violence', 'know', 'sound', 'silly']\n",
            "['believe', 'cartoon', 'child', 'influence', 'behavior', 'negative', 'way']\n",
            "['try', 'tone', 'psychotic', 'violence']\n",
            "['fine', 'programming', 'truly', 'marge', 'simpson']\n",
            "['letter', 'miss', 'white', 'dear', 'value', 'viewer', 'thank', 'take', 'interest', 'itchy_scratchy', 'program', 'enclose', 'personally', 'autograph', 'photo', 'america', 'favorite', 'cat', 'mouse', 'team', 'add', 'collection']\n",
            "['regard', 'specific', 'comment', 'research', 'indicate', 'person', 'difference', 'matter', 'big', 'screwball', 'let', 'close', 'say']\n",
            "['horse', 'ride']\n",
            "['everybody', 'look', 'marge']\n",
            "['oh', 'long', 'go']\n",
            "['change', 'world', 'know', 'long', 'take', 'exactly', 'people', 'interest']\n",
            "['hello', 'marge', 'oh', 's', 'n', 'u', 'h']\n",
            "['nonviolence', 'understanding', 'help']\n",
            "['start', 'crusade', 'cartoon', 'violence']\n",
            "['mind', 'warp', 'afternoon']\n",
            "['remind', 'get_to', 'milhouse', 'uh', 'play', 'sport']\n",
            "['go', 'janey', 'go', 'um', 'make', 'childhood', 'year']\n",
            "['oh', 'oh', 'baby']\n",
            "['happen', 'child', 'grow', 'insanely', 'violent', 'role', 'model', 'like']\n",
            "['hit', 'head', 'mallet', 'week']\n",
            "['know', 'tv', 'dinner', 'bad']\n",
            "['dinner', 'watch', 'cartoon']\n",
            "['pea', 'fruit', 'cobbler']\n",
            "['oop', 'guess', 'watch', 'cartoon']\n",
            "['sorry', 'dinner', 'tomorrow', 'night']\n",
            "['hey', 'tomorrow', 'night', 'make', 'patent', 'pork_chop']\n",
            "['hmmm', 'sure', 'oh', 'dear', 'get', 'protest', 'rally', 'tomorrow']\n",
            "['million', 'woman', 'world', 'marry', 'jane', 'fonda']\n",
            "['guess', 'sideshow', 'mel', 'time', 'itchy_scratchy']\n",
            "['hey', 'hey', 'settle', 'boy', 'girl', 'krusty', 'bring', 'old', 'friend', 'corporal', 'punishment']\n",
            "['stop', 'go', 'people']\n",
            "['substantially', 'violence', 'child', 'programming']\n",
            "['violence', 'child', 'program', 'ming']\n",
            "['ruin', 'oh', 'oh', 'oh', 'stop']\n",
            "['oh', 'right', 'try', 'earn', 'living', 'right', 'stop', 'stop']\n",
            "['woman', 'screwball', 'marge', 'simpson', 'get', 'stop']\n",
            "['hit', 'head', 'piano']\n",
            "['stuff', 'tnt', 'throw', 'match', 'throat', 'run']\n",
            "['fancy', 'degree', 'good', 'sick']\n",
            "['hmmm', 'ah', 'ha', 'funny']\n",
            "['know', 'story', 'pretty', 'good', 'know', 'mouse', 'live', 'interesting', 'life']\n",
            "['needless', 'brutality', 'know', 'have', 'impact']\n",
            "['smartline', 'yes', 'hear', 'late', 'night', 'panel', 'discussion', 'love']\n",
            "['smartline', 'local', 'emmy', 'award', 'win', 'host', 'kent_brockman']\n",
            "['guy', 'go', 'fish', 'catch', 'catfish', 'big']\n",
            "['excuse', 'excuse', 'address']\n",
            "['excuse', 'think', 'bad', 'influence', 'child']\n",
            "['oh', 'break', 'think', 'bunch', 'baloney', 'prepare', 'debate', 'little', 'research', 'discover', 'startling', 'thing', 'violence', 'past', 'long', 'cartoon', 'invent']\n",
            "['yeah', 'call', 'crusade', 'instance', 'tremendous', 'violence', 'people', 'kill', 'darn', 'thing', 'go', 'thirty_year']\n",
            "['right', 'kent', 'viewpoint']\n",
            "['ah', 'kent', 'high', 'jink', 'comic', 'character', 'absolutely', 'pale', 'comparison', 'crippling', 'emotional', 'problem', 'psychiatrist', 'run', 'day', 'refer', 'woman', 'love', 'fear', 'win', 'sexaholism', 'stuff', 'like']\n",
            "['fact', 'guilty', 'little', 'pleasure', 'snuggle', 'big', 'bucket', 'buttered', 'popcorn', 'dim', 'light', 'turn', 'itchy_scratchy', 'laugh', 'silly', 'hell', 'wrong']\n",
            "['oh', 'sorry', 'kent', 'camera', 'get', 'hey', 'hey']\n",
            "['yes', 'like', 'ask', 'parent', 'springfield', 'concerned', 'write', 'let', 'cartoon', 'maker', 'know', 'feel', 'thank']\n",
            "['believe', 'watch', 'buy', 'product', 'brake', 'cross', 'street', 'wow', 'cold']\n",
            "['dear', 'sleaze', 'merchant', 'come', 'hurt']\n",
            "['gentleman', 'screwball', 'speak']\n",
            "['marge', 'simpson', 'fix', 'cartoon', 'violent', 'anymore']\n",
            "['myers', 'writer', 'listen', 'smart', 'end', 'picture']\n",
            "['okay', 'itchy', 'steal', 'scratchy', 'ice_cream', 'cone']\n",
            "['pie', 'pie', 'easy', 'draw']\n",
            "['okay', 'pie', 'scratchy', 'understandably', 'upset']\n",
            "['figure', 'know', 'grab', 'itchy', 'toss', 'bucket', 'acid']\n",
            "['remember', 'interpret', 'violence', 'morally', 'wrong', 'thank', 'big', 'idea', 'end']\n",
            "['let', 'oh', 'itchy', 'share', 'pie', 'scratchy', 'pie']\n",
            "['tool', 'home', 'handyman', 'need', 'jigsaw', 'power', 'drill', 'wood', 'turn', 'lathe']\n",
            "['asphalt', 'spreader', 'seven', 'tool', 'pay', 'machine']\n",
            "['mean', 'watch', 'cartoon', 'mom']\n",
            "['yes', 'dear', 'want']\n",
            "['love', 'share', 'share', 'love', 'share', 'love', 'love', 'love', 'share', 'share', 'share', 'itchy_scratchy', 'showwww']\n",
            "['itchy_scratchy', 'lose', 'edge']\n",
            "['think', 'convey', 'nice', 'message', 'sharing']\n",
            "['oh', 'hey', 'thank', 'maggie']\n",
            "['mmmm', 'hit', 'spot']\n",
            "['good', 'lemonade', 'scratchy']\n",
            "['oh', 'oh', 'oh', 'thank', 'itchy']\n",
            "['funny', 'boy', 'girl']\n",
            "['go', 'watch', 'rest', 'cute', 'cartoon']\n",
            "['nah', 'come', 'lis']\n",
            "['bowl', 'porridge', 'j', 'u', 'u', 'u_s', 't', 'right']\n",
            "['janey', 'go', 'bird', 'watch', 'see', 'grackle']\n",
            "['come', 'lis', 'let', 'finish', 'soapbox', 'racer']\n",
            "['wow', 'great', 'kid', 'golden', 'age', 'marge', 'parent', 'springfield', 'owe']\n",
            "['expect', 'thing', 'change']\n",
            "['know', 'change', 'world', 'well']\n",
            "['art', 'event', 'century', 'great', 'masterpiece', 'italian', 'renaissance', 'michelangelo', 'david', 'coast', 'coast', 'tour', 'united_states']\n",
            "['ah', 'sir', 'city', 'include', 'itinerary']\n",
            "['eh', 'new_york']\n",
            "['time', 'chicago', 'boston', 'los', 'angeles']\n",
            "['dressed', 'marge', 'get', 'lead', 'protest', 'abomination']\n",
            "['hmmm', 'michelangelo', 'david', 'masterpiece']\n",
            "['filth', 'graphically', 'portray', 'part', 'human', 'body', 'practical', 'evil']\n",
            "['tell', 'soft', 'frontal', 'nudity', 'come', 'girl']\n",
            "['want', 'big', 'italian', 'butt', 'outta']\n",
            "['hold', 'hold', 'hold', 'form', 'freedom', 'expression', 'like', 'big', 'naked', 'friend', 'form', 'like', 'itchy_scratchy']\n",
            "['guess', 'shame', 'hate', 'cartoon']\n",
            "['oh', 'yeah', 'marge', 'simpson', 'wannabe', 'wish', 'suppress', 'david', 'doodle']\n",
            "['um', 'know', 'guess', 'person', 'difference', 'time', 'probably']\n",
            "['guess', 'settle', 'like', 'alert', 'affiliate', 'end', 'early', 'tonight', 'join', 'tomorrow', 'topic', 'religion', 'true', 'faith']\n",
            "['oh', 'wrong', 'marge']\n",
            "['oh', 'homie', 'kid', 'chance', 'great', 'work', 'art', 'instead', 'home', 'watch', 'cat', 'mouse', 'disembowel']\n",
            "['hey', 'worry', 'marge', 'pretty', 'soon', 'boy', 'girl', 'springfield_elementary', 'school', 'go_to', 'come', 'thing']\n",
            "['uh', 'think', 'boy', 'hurt']\n",
            "['oh', 'cry', 'loud', 'nickel', 'let', 'go']\n",
            "['think', 'ambulance', 'sir']\n",
            "['hey', 'cool', 'dead']\n",
            "['hold', 'handrail', 'spit', 'por', 'favor', 'aguantese', 'en', 'la', 'baranda', 'escupas', 'en', 'los', 'lados']\n",
            "['great', 'grandpa', 'simpson']\n",
            "['hold', 'handrail', 'spit']\n",
            "['tell', 'hold', 'handrail', 'ask', 'spit']\n",
            "['ah', 'allow', 'introduce', 'devil', 'earn', 'eternal', 'damnation', 'lifetime', 'evil', 'deed', 'bart', 'spit', 'escalator', 'clinch']\n",
            "['hey', 'innocent', 'man']\n",
            "['innocent', 'everybody', 'innocent', 'okay', 'let', 'pull', 'file']\n",
            "['okay', 'hmmm', 'mistake', 'accord', 'arrive', 'time', 'yankees', 'win', 'pennant', 'nearly', 'century', 'ha_ha', 'boy', 'face', 'red']\n",
            "['um', 'avoid', 'come']\n",
            "['oh', 'okay', 'later']\n",
            "['goodbye', 'bart', 'remember', 'lie', 'cheat', 'steal', 'listen', 'heavy', 'metal', 'music']\n",
            "['oh', 'bart', 'think', 'minute', 'go', 'away']\n",
            "['away', 'mom', 'mile', 'mile', 'mile', 'away', 'writhe', 'agony', 'pit', 'hell', 'see']\n",
            "['hey', 'yeah', 'see', 'chase', 'bart', 'ambulance']\n",
            "['hutz', 'mr_simpson', 'lionel', 'hutz', 'attorney', 'law', 'card']\n",
            "['turn', 'sponge', 'water']\n",
            "['like', 'talk', 'bring', 'legal', 'action', 'fiend', 'boy']\n",
            "['fiend', 'boy', 'boss', 'doctor', 'say', 'bump', 'head', 'broken', 'toe']\n",
            "['doctor', 'doctor', 'idiot', 'tell', 'kind', 'permanent', 'injury', 'wait', 'hand', 'foot', 'rest', 'natural', 'life']\n",
            "['downside', 'good', 'che', 'ching', 'ching', 'cash', 'tragedy']\n",
            "['excuse', 'mr', 'hutz', 'shyster']\n",
            "['nice', 'little_girl', 'like', 'know', 'big', 'word', 'like']\n",
            "['mr', 'hutz', 'hardly', 'time', 'place', 'discuss']\n",
            "['right', 'right', 'feel', 'come', 'office', 'talk']\n",
            "['lionel', 'hutz', 'attorney', 'law', 'broken', 'neck', 'great']\n",
            "['hello', 'dr_hibbert']\n",
            "['hello', 'lisa', 'get', 'nasty', 'bump', 'head']\n",
            "['little', 'tiny', 'broken', 'toe']\n",
            "['start', 'mother', 'unbearably', 'doctor']\n",
            "['hmm', 'better', 'let', 'rest', 'awhile']\n",
            "['hey', 'simpson', 'hear', 'mr_burns', 'crush', 'boy']\n",
            "['yeah', 'spineless', 'march', 'mr_burns', \"'\", 'office', 'right']\n",
            "['mr_burns', 'want', 'march', 'office', 'right']\n",
            "['ah', 'simpson', 'meet']\n",
            "['nice', 'meet', 'sir']\n",
            "['yes', 'attorney', 'advise', 'pay', 'run', 'child', 'cut', 'check']\n",
            "['dollar', 'course', 'sign', 'waiver', 'relinquish', 'right', 'sue', 'forth', 'merely', 'formality']\n",
            "['w', 'v', 'generous', 'offer', 'sir', 'medical', 'bill']\n",
            "['oh', 'extortion', 'little', 'game', 'simpson', 'fine', 'lawyer', 'springfield', 'simpson', 'tangle', 'crush', 'like', 'paper', 'cup']\n",
            "['mr_burns', 'throw']\n",
            "['hey', 'lionel', 'hutz']\n",
            "['right', 'mr_simpson', 'call', 'della']\n",
            "['oh', 'call', 'yes', 'uh', 'supreme', 'court', 'call', 'need', 'help', 'freedom', 'thing']\n",
            "['tell', 'sit', 'tight', 'way', 'mr_simpson']\n",
            "['sure', 'get', 'education', 'mr', 'hutz']\n",
            "['yes', 'harvard', 'yale', 'mit', 'oxford', 'sorbonne', 'louvre']\n",
            "['oh', 'oh', 'mr_simpson', 'state', 'bar', 'forbid', 'promise', 'big', 'cash', 'settlement', 'promise', 'big', 'cash', 'settlement', 'fee', 'percent']\n",
            "['get', 'lawyer', 'mr_simpson', 'get', 'exquisite', 'faux', 'pearl', 'necklace', 'value', 'gift']\n",
            "['dunno', 'different', 'idea', 'big', 'big', 'cash', 'settlement']\n",
            "['whoo', 'ooo', 'stand', 'correct', 'million', 'buck', 'okay']\n",
            "['good', 'proceed', 'mr', 'hutz']\n",
            "['real', 'doctor', 'opinion']\n",
            "['son', 'sick', 'boy', 'look', 'x', 'ray']\n",
            "['dark', 'spot', 'whiplash']\n",
            "['smudge', 'look', 'like', 'fingerprint', 'trauma']\n",
            "['course', 'go', 'die', 'fine']\n",
            "['play', 'baseball', 'morning']\n",
            "['right', 'excuse', 'dr_hibbert', 'family', 'physician', 'year', 'think', 'bart', 'fine']\n",
            "['oh', 'dr_hibbert', 'johns', 'hopkins', 'medical', 'school']\n",
            "['respect', 'mrs_simpson', 'doctor', 'boy', 'doctor', 'doctor', 'person', 'room', 'come', 'close', 'man']\n",
            "['doctor', 'sure', 'little', 'soft', 'tissue', 'trauma', 'facial', 'area']\n",
            "['oh', 'yeah', 'ton']\n",
            "['million_dollar', 'smither', 'want', 'homer', 'j', 'simpson', 'fire']\n",
            "['uh', 'think', 'wise', 'mr_burns', 'mean', 'think', 'headline']\n",
            "['press', 'critical', 'fire', 'crippled', 'boy', 'father', 'soon', 'accident']\n",
            "['thank', 'honor', 'bart', 'want', 'tell', 'jury', 'word', 'exactly', 'happen', 'day', 'accident']\n",
            "['right', 'want', 'like', 'ogre', 'bide', 'time', 'let', 'twist', 'wind', 'slowly', 'slowly', 'paper', 'find', 'new', 'flavor', 'month', 'find', 'cat', 'claw']\n",
            "['good', 'thinking', 'sir']\n",
            "['let', 'pretend', 'witness', 'stand', 'bart']\n",
            "['oh', 'fine', 'nice', 'bart', 'say', 'fine', 'wrong', 'fine', 'constant', 'pain']\n",
            "['think', 'charade', 'bart', 'look', 'injured']\n",
            "['maybe', 'lisa', 'point', 'mind', 'boy', 'living', 'room', 'court', 'bart', 'tell_truth']\n",
            "['yeah', 'truth', 'follow', 'bart', 'roll', 'eye', 'head', 'like']\n",
            "['ah', 'mean', 'like', 'dead', 'yeah', 'sure']\n",
            "['springfield', 'municipal', 'court', 'session', 'judge', 'moulton', 'presiding']\n",
            "['honor', 'client', 'instruct', 'remind', 'court', 'rich', 'important', 'like', 'man']\n",
            "['able', 'run', 'kid', 'want']\n",
            "['mr_burns', 'warn', 'continue', 'disrupt', 'court', 'way', 'cite', 'contempt']\n",
            "['call', 'bartholomew', 'j', 'simpson', 'stand']\n",
            "['hello', 'bart', 'know', 'difference', 'tell_truth', 'tell', 'lie', 'son']\n",
            "['uh_huh', 'lie', 'united_states', 'bart']\n",
            "['yes', 'sir', 'beautiful', 'sunday', 'afternoon', 'play', 'wholesome', 'childlike', 'way', 'little', 'realize', 'strike', 'luxury', 'car', 'death']\n",
            "['defenseless', 'child', \"o'clock\"]\n",
            "['luckily', 'kill', 'day', 'wish']\n",
            "['mr_burns', 'relate', 'word', 'exactly', 'happen', 'day', 'accident']\n",
            "['certainly', 'oh', 'beautiful', 'day', 'sun', 'shine', 'drive', 'orphanage', 'pass', 'toy']\n",
            "['suddenly', 'incorrigible', 'simpson', 'boy', 'dart']\n",
            "['oh', 'goodness', 'look', 'happen']\n",
            "['oh', 'important', 'sir', 'let', 'drive']\n",
            "['despicable', 'cold', 'blooded', 'monster', 'regardless', 'think', 'summon', 'help', 'comfort', 'dear', 'boy', 'ambulance', 'arrive']\n",
            "['look', 'like', 'believe', 'cock', 'bull', 'story']\n",
            "['look', 'good', 'mr_simpson', 'look', 'good']\n",
            "['hate', 'trial', 'watch']\n",
            "['oh', 'yeah', 'settlement', 'fine', 'hang', 'head', 'shame', 'price', 'brain', 'glorify', 'notary', 'public', 'big', 'ape', 'house', 'tonight', 'buy', 'banana']\n",
            "['ugly', 'customer', 'indonesian', 'rhino', 'earth']\n",
            "['know', 'like', 'animal']\n",
            "['oh', 'like', 'head', 'care', 'wine', 'old', 'buddy']\n",
            "['bottom', 'simpson', 'plenty', 'come']\n",
            "['mr_burns', 'try', 'drunk']\n",
            "['yes', 'homer', 'old', 'chum', 'sure', 'agree', 'trial', 'affront', 'collective', 'dignity', 'settle', 'man', 'man']\n",
            "['oh', 'mean', 'prepared', 'offer', 'generous', 'cash', 'settlement']\n",
            "['handsome', 'sum', 'end', 'little', 'embrolio']\n",
            "['answer', 'relax', 'talk', 'missus', 'soak', 'opulence', 'surrounding', 'dream', 'smither', 'let', 'powder', 'nose']\n",
            "['know', 'maybe', 'money', 'ugliness']\n",
            "['tell', 'think', 'think', 'think', 'idiot', 'reason', 'offer', 'know', 'go_to', 'lose', 'trial', 'pay', 'cool', 'million']\n",
            "['oh', 'feel', 'faint']\n",
            "['thousand_dollar', 'spit', 'thousand_dollar']\n",
            "['homer', 'happen', 'greediness', 'lying', 'shifty', 'lawyer', 'phony', 'doctor']\n",
            "['phony', 'doctor', 'hel', 'lo']\n",
            "['know', 'settle', 'bart', 'medical', 'bill', 'apology']\n",
            "['better', 'dyin', \"'\"]\n",
            "['sorry', 'offer', 'expire', 'guess', 'let', 'jury', 'decide', 'good', 'man', 'true', 'good', 'day', 'smither', 'release', 'hound']\n",
            "['honor', 'like', 'stand', 'mrs', 'homer', 'j', 'simpson']\n",
            "['swear', 'tell_truth', 'truth', 'truth', 'help', 'god']\n",
            "['sound_like', 'take', 'awful', 'seriously']\n",
            "['mrs_simpson', 'julius', 'hibbert', 'mean']\n",
            "['yes', 'family', 'physician', 'trust', 'friend', 'day', 'mother', 'see', 'cold', 'impetigo', 'competence', 'love', 'care']\n",
            "['wait_minute', 'confuse', 'court', 'hear', 'expert', 'testimony', 'dr', 'nick', 'riviera', 'opinion']\n",
            "['sorry', 'mother', 'say', 'nice']\n",
            "['mrs_simpson', 'opinion', 'dr', 'riviera', 'let', 'remind', 'oath']\n",
            "['honest', 'lot', 'concerned', 'wrap', 'bart', 'bandage', 'make', 'feel', 'well', 'mispronounce', 'word', 'know', 'like', 'abdomen', 'office', 'dirty', 'think', 'sure', 'doctor']\n",
            "['mrs_simpson', 'describe', 'word', 'bart', 'intense', 'mental', 'anguish', 'suffering']\n",
            "['guess', 'miss', 'day', 'school']\n",
            "['like', 'school']\n",
            "['guess', 'count', 'anguish']\n",
            "['little', 'hard', 'have', 'house']\n",
            "['pay', 'bart', 'dollar', 'week', 'trash']\n",
            "['suppose', 'able', 'week', 'give', 'dollar']\n",
            "['lawyer', 'assume', 'lawyer', 'ask', 'million', 'blame', 'try', 'thank', 'mrs_simpson']\n",
            "['go', 'write', 'figure', 'piece', 'paper', 'large', 'think', 'find', 'fair']\n",
            "['million_dollar', 'wife', 'cost', 'million_dollar']\n",
            "['homer', 'like', 'macaroni', 'cheese']\n",
            "['yeah', 'million_dollar', 'worth', 'treacherous', 'snake', 'woman', 'thank']\n",
            "['want', 'string', 'bean', 'timing', 'stab', 'uh', 'oh', 'better', 'answer', 'thank']\n",
            "['celery', 'cream', 'cheese']\n",
            "['know', 'cool', 'get', 'million', 'buck']\n",
            "['buy', 'ton', 'great', 'stuff', 'mom', 'maid', 'pool', 'fancy', 'sweater', 'stop', 'wrong']\n",
            "['marge', 'dear', 'right', 'go', 'moe', 'drink']\n",
            "['know', 'come', 'goodnight']\n",
            "['woman', 'intuition', 'tell', 'wonder', 'oh_god']\n",
            "['guess', 'class', 'go_to', 'die']\n",
            "['eh', 'well', 'rich', 'people', 'happy', 'day', 'bear', 'day', 'die', 'think', 'happy', 'trust', 'be']\n",
            "['moe', 'wish', 'shut']\n",
            "['hey', 'hey', 'guy', 'knock', 'wife']\n",
            "['homer', 'like', 'forgive', 'right', 'thing']\n",
            "['squabble', 'money', 'mean', 'know', 'different', 'time', 'wash', 'pant', 'pocket']\n",
            "['think', 'money', 'bad', 'marge', 'afraid', 'look', 'go_to', 'wife', 'mother', 'child', 'go_to', 'dame', 'blow', 'big', 'chance']\n",
            "['say', 'wife', 'year', 'child', 'time', 'honest', 'sure', 'love', 'anymore']\n",
            "['worry', 'let', 'bed', 'stuff', 'maybe', 'will', 'bad']\n",
            "['oh', 'lord', 'want', 'wait_minute', 'find', 'love', 'anymore', 'think', 'look', 'eye', 'find']\n",
            "['alright', 'alright', 'look', 'shut', 'start', 'foot', 'angry', 'good', 'good', 'homer', 'good', 'tough', 'need', 'refreshment', 'ahh', 'good', 'old', 'trustworthy', 'beer', 'love', 'die', 'alright', 'alright', 'get_to', 'look', 'wife', 'straight', 'eye', 'tell']\n",
            "['oh', 'kid', 'love']\n",
            "['sorry', 'scare', 'like', 'babe']\n",
            "['okay', 'everybody', 'minute', 'pitcher', 'customer', 'domestic', 'beer', 'hey', 'sharing']\n",
            "['meatloaf', 'ready', 'second', 'homer']\n",
            "['fast', 'microwave', 'ping']\n",
            "['unbelievably', 'hot', 'kid']\n",
            "['yum', 'get', 'dry', 'end', 'piece', 'lisa']\n",
            "['thursday', 'meatloaf', 'night', 'shall']\n",
            "['try', 'teach', 'open', 'minded', 'try', 'new', 'thing', 'live', 'life']\n",
            "['talk', 'try', 'teach']\n",
            "['maybe', 'lisa', 'right', 'tomorrow', 'night', 'nice', 'dinner']\n",
            "['tomorrow', 'night', 'friday', 'pork_chop', 'night', 'marge', 'miss', 'pork_chop', 'night', 'great', 'pig', 'scare', \"'\"]\n",
            "['friday', 'night', 'pork_chop', 'cradle', 'grave', 'etch', 'stone', 'god', 'library']\n",
            "['okay', 'okay', 'okay', 'okay', 'want']\n",
            "['hamburger', 'pizza', 'fry', 'chicken']\n",
            "['new', 'sushi', 'restaurant', 'elm', 'street']\n",
            "['sushi', 'hey', 'maybe', 'thing', 'hear', 'playground', 'raw', 'fish']\n",
            "['usual', 'playground', 'fact', 'right', 'miss', 'point', 'entirely', 'sushi', 'consider', 'delicacy']\n",
            "['dad', 'argument', 'humiliate']\n",
            "['say', 'time', 'make', 'think', 'go_to', 'yes', 'second', 'time']\n",
            "['yes', 'ninety', 'ninth', 'time']\n",
            "['oh', 'okay', 'okay']\n",
            "['alarm', 'chef', 'say', 'hello']\n",
            "['oh', 'okay', 'hello']\n",
            "['karioke', 'bar', 'soon', 'hop', 'drunken', 'japanese', 'businessman']\n",
            "['akira', 'waiter', 'order']\n",
            "['recommend', 'family', 'sure']\n",
            "['sushi', 'sampler', 'little_bit', 'non', 'threatening']\n",
            "['akira', 'good', 'man', 'like', 'shark', 'octopus', 'eel']\n",
            "['giant', 'squid', 'kind', 'drag', 'man', 'death']\n",
            "['hard', 'choose', 'look', 'terrible', 'bring']\n",
            "['toshiro', 'squid', 'look', 'like', 'hack', 'blind', 'woodsman', 'hang', 'head', 'shame']\n",
            "['good', 'thing', 'open', 'minded']\n",
            "['hmmm', 'hmmm', 'bad', 'interesting']\n",
            "['try', 'little', 'pink', 'hmmm', 'good']\n",
            "['oh', 'boy', 'fish', 'dee', 'lish']\n",
            "['hi', 'richie', 'sakai', 'anesthesiologist']\n",
            "['like', 'dedi', 'cate', 'song', 'wife', 'patti', 'bear', 'wagon', 'travel', 'mama', 'dance', 'money', 'throw', 'papa']\n",
            "['oh', 'oh', 'thing']\n",
            "['oh', 'oh', 'believe', 'try', 'fly', 'fish', 'roe']\n",
            "['recommend', 'raw', 'quail', 'egg']\n",
            "['black', 'private', 'dick', 'sex', 'machine', 'chick']\n",
            "['damn', 'right', 'cat', 'will', 'cop', 'danger']\n",
            "['get_to', 'try', 'huh', 'hey', 'fugu']\n",
            "['blowfish', 'sir', 'warn']\n",
            "['come', 'pal', 'fugu']\n",
            "['cat', 'shaft', 'bad', 'mother']\n",
            "[\"talkin_'\", 'shaft']\n",
            "['complicated', 'man', 'understand', 'woman']\n",
            "['fugu', 'cut', 'improperly']\n",
            "['yes_yes', 'poisonous', 'potentially', 'fatal', 'slice', 'properly', 'tasty']\n",
            "['oh', 'miss', 'krabappel', 'hair', 'smell', 'clean']\n",
            "['master', 'need', 'kitchen']\n",
            "['say', 'cover', 'damn']\n",
            "['master', 'need', 'skilled', 'hand']\n",
            "['skilled', 'hand', 'busy']\n",
            "['poison', 'poison', 'tasty', 'fish']\n",
            "['mmmm', 'fan', 'fugu', 'tastic']\n",
            "['beautiful', 'language', 'marge']\n",
            "['god', 'sake', 'eat', 'bite']\n",
            "['mr_simpson', 'san', 'shall', 'blunt', 'reason', 'believe', 'eat', 'poison']\n",
            "['poison', 'tell', 'quick']\n",
            "['oh', 'need', 'panic', 'map', 'hospital', 'menu']\n",
            "['try', 'new', 'homer', 'hurt', 'homer', 'hear', 'poison', 'pork_chop']\n",
            "['hmmm', 'wife', 'agree', 'break']\n",
            "['need', 'doc', 'read', 'marge', 'like', 'book']\n",
            "['oooh', 'good', 'news']\n",
            "['mr_simpson', 'fact', 'consume', 'venom', 'blowfish', 'chef', 'tell', 'probable', 'hour', 'live']\n",
            "['sorry', 'keep', 'wait', 'long']\n",
            "['oh', 'marge', 'go_to', 'die', 'go_to', 'die']\n",
            "['consolation', 'feel', 'pain', 'time', 'tomorrow', 'evening', 'heart', 'suddenly', 'explode']\n",
            "['little', 'death', 'anxiety', 'normal', 'expect', 'stage', 'denial']\n",
            "['doc', 'got_to', 'worth']\n",
            "['get_to', 'time']\n",
            "['tell', 'ya', 'come', 'go_to', 'learn', 'shave']\n",
            "['mr_simpson', 'progress', 'astound', 'leave', 'pamphlet', 'helpful']\n",
            "['hello', 'marge', 'hello', 'die']\n",
            "['sorry', 'homer', 'think', 'want', 'tell', 'kid']\n",
            "['upset', 'want', 'hour', 'family', 'life', 'happy', 'one']\n",
            "['decide', 'want', 'tomorrow']\n",
            "['marge', 'word', 'use', 'know']\n",
            "['suggestion', 'early', 'watch', 'sunrise']\n",
            "['ah', 'watch', 'sunrise']\n",
            "['till', 'm', 'dear', 'darling', 'day', 'earth']\n",
            "['thirty', 'oh', 'great']\n",
            "['marge', 'let', 'sleep', 'late']\n",
            "['look', 'peaceful', 'lying']\n",
            "['plenty', 'time', 'get', 'ton', 'important', 'stuff']\n",
            "['man', 'man', 'bart']\n",
            "['nooo', 'want', 'heart', 'heart', 'talk']\n",
            "['know', 'bart', 'man', 'house', 'mean', 'go_to', 'help']\n",
            "['oh', 'come', 'plenty', 'lisa', 'lift', 'finger', 'yell']\n",
            "['shut', 'bart', 'good', 'stuff', 'want', 'share', 'little', 'sentence', 'life', 'number', 'cover', 'number', 'oh', 'good', 'idea', 'boss', 'number', 'like', 'get']\n",
            "['hey', 'good', 'stuff']\n",
            "['listen', 'lisa', 'play', 'sax']\n",
            "['simpson', 'pleasant', 'surprise', 'pull', 'taffy']\n",
            "['gee', 'fun', 'stop', 'flander', 'house']\n",
            "['hey', 'flander', 'borrow', 'camcorder']\n",
            "['okey', 'dokel', 'hey', 'family', 'come', 'barbecue', 'tomorrow']\n",
            "['oh', 'sure', 'get', 'new', 'propane', 'beauty', 'sittin', \"'\", 'yard']\n",
            "['oh', 'cry', 'cook', 'good', 'eatin', \"'\"]\n",
            "['flanders', 'say', 'tomorrow', 'sure', 'hey', 'love', 'come', 'barbecue', 'bring', 'thick', 'juiciest', 't', 'bone', 'see']\n",
            "['mmm', 'mm', 'sound', 'terriff']\n",
            "['heh_heh', 'joke', 'dead']\n",
            "['sorry', 'officer', 'know', 'go', 'fast', 'ticket']\n",
            "['videotape', 'daughter', 'maggie', 'hi', 'maggie', 'speak', 'grave', 'oooooooh', 'hope', 'scare', 'grown', 'tape', 'probably', 'wonder', 'kind', 'man', 'father', 'simple', 'man', 'kind', 'man', 'gentle', 'man', 'love', 'child']\n",
            "['hello', 'yeah', 'bart', 'friend', 'milhouse', 'bart', 'butt']\n",
            "['huh', 'oh', 'want']\n",
            "['go', 'fishing', 'play', 'catch', 'hug']\n",
            "['dance', 'hoochy', 'koo', 'point']\n",
            "['want', 'know', 'love', 'dad']\n",
            "['oh', 'son', 'love', 'hey', 'hug']\n",
            "['old_man', 'get_to']\n",
            "['oh', 'son', 'get', 'lotta', 'catchin', \"'\", 'fishin', \"'\"]\n",
            "['gee', 'dad', 'tight', 'schedule']\n",
            "['oh', 'let', 'worm']\n",
            "['gee', 'dad', 'way', 'hog', 'moment']\n",
            "['quick', 'game', 'hacky', 'sack']\n",
            "['yeah', 'yeah', 'old', 'guy', 'little', 'love', 'starve']\n",
            "['move', 'hunk', 'junk', 'get_to', 'lose', 'time']\n",
            "['whoa', 'sound_like', 'order']\n",
            "['pay', 'taxis', 'pay', 'salary', 'ticket', 'ticket']\n",
            "['uh_huh', 'maybe', 'want', 'ticket']\n",
            "['hey', 'look', 'tax', 'dollar', 'pay', 'huh']\n",
            "['okay', 'flash', 'phone']\n",
            "['wait', 'marge', 'day', 'earth', 'drag', 'mess', 'know', 'barney']\n",
            "['damn', 'novelty', 'telephone', 'answer', 'machine', 'tape']\n",
            "['thank', 'lot', 'barney', 'waste', 'phone', 'stupid', 'ma']\n",
            "['home', 'home', 'hi', 'homer']\n",
            "['get_to', 'help', 'barney', 'jail']\n",
            "['hey', 'homer', 'window']\n",
            "['ju', 'ju', 'bring', 'buck', 'bail']\n",
            "['buck', 'kill', 'judge', 'go_to', 'buck']\n",
            "['fun', 'dress', 'dinner']\n",
            "['fun', 'use', 'good', 'china']\n",
            "['fun', 'use', 'candle']\n",
            "['love', 'father', 'enjoy', 'company']\n",
            "['heh', 'dollar', 'seventy', 'cent', 'know', 'usually', 'rusty', 'money']\n",
            "['dyin', \"'\", 'go_to', 'stop', 'moe', 'beer', 'buddy']\n",
            "['hey', 'barney', 'look', 'list', 'lot', 'thing', 'today', 'hey', 'boss']\n",
            "['smither', 'check', 'luscious', 'pair', 'red', 'head', 'baby', 'work', 'ankle']\n",
            "['re', 'ding_ding', 'sir']\n",
            "['hey', 'burn', 'eat', 'short']\n",
            "['homer_simpson', 'sir', 'schmo', 'sector', 'g']\n",
            "['simpson', 'eh', 'want', 'office', \"o'clock\", 'monday', 'morning', 'eat', 'short']\n",
            "['wow', 'luck', 'think', 'die', 'tell', 'boss', 'eat', 'short']\n",
            "['ah', 'homer', 'come', 'get', 'time', 'beer']\n",
            "['get_to', 'marge']\n",
            "['hello', 'moe', 'tavern', 'birthplace', 'rob', 'roy']\n",
            "['sec', 'hey', 'butts', 'seymour', 'butts', 'hey', 'everybody', 'wanna', 'seymour', 'butts']\n",
            "['oh', 'wait_minute', 'listen', 'little', 'scum', 'suck', 'pus', 'bucket', 'hand', 'go_to', 'pull', 'eyeball', 'corkscrew']\n",
            "['oh', 'busy', 'moe', 'beer']\n",
            "['guy', 'get', 'word', 'tell', 'work', 'think', 'smile', 'think', 'oh', 'word', 'will', 'love', 'moe']\n",
            "['come', 'barney', 'get_to', 'home']\n",
            "['fast', 'barney', 'faster']\n",
            "['oh', 'wait', 'longer', 'hold', 'marge', \"comin_'\", 'home', 'baby']\n",
            "['write', 'poem', 'afternoon', 'homer', 'call', 'husband']\n",
            "['ahem', 'blacken', 'cloud', 'form']\n",
            "['oh', 'gimme', 'break', 'marge']\n",
            "['soon', 'rain', 'fall', 'dear', 'depart', 'heed', 'love', 'love']\n",
            "['goodbye', 'maggie', 'stay', 'sweet']\n",
            "['goodbye', 'lisa', 'know', 'proud']\n",
            "['goodbye', 'bart', 'like', 'sheet']\n",
            "['oooo', 'read', 'larry', 'king']\n",
            "['hi', 'larry', 'king', 'begin', 'god', 'create', 'heaven', 'earth', 'earth', 'form', 'void']\n",
            "['eleazar', 'begat', 'phinehas', 'phinehas', 'begat', 'abishua', 'abishua']\n",
            "['begat', 'ahimaaz', 'ahimaaz', 'begat']\n",
            "['amariah', 'onward', 'amariah', 'begat', 'ahitub', 'ahitub', 'begat']\n",
            "['senator', 'mendoza', 'respected', 'citizen', 'state', 'mcbane', 'run', 'limo', 'cliff', 'break', 'neck', 'bodyguard', 'drive', 'bus', 'door']\n",
            "['shallum', 'begat', 'hilkiah', 'hilkiah', 'begat', 'azariah', 'shall', 'turn', 'heart', 'father', 'child', 'heart', 'child', 'father', 'come', 'smite', 'earth', 'curse', 'oh', 'friend', 'duke', 'zeever', 'stand', 'coffee', 'matzo', 'ball', 'soup', 'love', 'san', 'antonio', 'spur', 'way', 'bettin', \"'\", 'nba', 'year', 'think', 'go', 'win', 'guess']\n",
            "['oh', 'homer', 'homer']\n",
            "['drool', 'warm', 'alive', 'homer', 'homer', 'wake', 'alive']\n",
            "['right', 'stop', 'cut']\n",
            "['wake', 'alive', 'alive']\n",
            "['alive', 'alive', 'happy', 'day', 'forward', 'vow', 'live', 'life', 'full']\n",
            "['strike', 'row', 'let', 'come', 'excellent', 'make', 'pin', 'match', 'far', 'know']\n",
            "['yeah', 'far', 'uh', 'approach', 'wrong', 'beginning', 'far', 'concerned']\n",
            "['erratic', 'bowler', 'chad', 'tend', 'explode', 'seven', 'frame', 'remember', 'boline', 'illinois']\n",
            "['actually', 'actually', 'pontiac', 'michigan']\n",
            "['oh', 'thirty', 'pin', 'go']\n",
            "['step', 'need', 'spare']\n",
            "['sit', 'close', 'tv', 'hurt', 'eye']\n",
            "['movie', 'mcbane', 'shoot', '-PRON-', 'push', '-PRON-', 'plate', 'glass', 'window', 'splatter', 'f', 'hollywood', 'cookie', 'cutter', 'typically', 'brainless', 'scene']\n",
            "['want', 'hear', 'mcbane', 'outta']\n",
            "['know', 'believe', 'talk', 'movie']\n",
            "['think', 'mcbane', 'non', 'stop', 'roller', 'coaster', 'chill', 'thrill', 'spill', 'kill']\n",
            "['chase', 'end', 'friend']\n",
            "['nuts', 'movie', 'stink', 'like', 'creepy', 'bedroom', 'apartment']\n",
            "['mother', 'think', 'creepy']\n",
            "['mother', 'real', 'mature', 'sick']\n",
            "['love', 'watch', 'bald', 'guy', 'argue', 'fat', 'tub', 'lard']\n",
            "['right', 'right', 'time', 'dr', 'tv', 'perform', 'little', 'surgery']\n",
            "['look', 'like', 'lose', 'patient', 'doc']\n",
            "['shut', 'boy', 'cheap', 'chinese', 'tv', 'buy', 'well']\n",
            "['okay', 'everybody', 'remain', 'calm']\n",
            "['hey', 'everybody', 'look', 'real', 'close', 'kinda', '-PRON-']\n",
            "['hey', 'yeah', 'yeah', 'think']\n",
            "['think', 'sick', 'stare', 'dot']\n",
            "['oh', 'miss', 'tv', 'dear', 'god', 'channel']\n",
            "['homer', 'end', 'world', 'know', 'get', 'marry', 'hardly', 'watch', 'television']\n",
            "['true', 'bart', 'shoot', 'pool', 'dance']\n",
            "['lot', 'time', 'stay', 'home', 'talk', 'like']\n",
            "['livin', \"'\", 'be', 'love']\n",
            "['hard', 'picture', 'hand', 'hand', 'crossroad', 'life', 'question']\n",
            "['okay', 'uh', 'dad', 'propose']\n",
            "['lisa', 'tell', 'different', 'story', 'father', 'meet', 'fall', 'love']\n",
            "['senior', 'high_school', 'meet']\n",
            "['ugh', 'gross', 'ecch']\n",
            "['people', 'space', 'cowboy', 'yeah', 'gangster', 'love', 'people', 'maurice', 'woo', 'woo', 'because', 'speak', 'puppet', 'oh', 'love']\n",
            "['hey', 'homer', 'late', 'english']\n",
            "['english', 'need', 'go', 'england', 'come', 'let', 'smoke']\n",
            "['equal', 'right', 'need', 'amendment']\n",
            "['come', 'marge', 'think', 'deserve', 'earn', 'man', 'job']\n",
            "['heavy', 'lifting', 'math']\n",
            "['oh', 'marge', 'ought', 'read']\n",
            "['oh', 'shop', 'kid', 'smoke']\n",
            "['oh', 'late', 'wood', 'shop']\n",
            "['early', 'lunch', 'let', 'grab', 'burger']\n",
            "['boy', 'stop', 'eatin', \"'\", 'gain', 'pound']\n",
            "['eh', 'metabmobolism', 'guess', 'lucky', 'one']\n",
            "['homer_simpson', 'barney', 'gumbel', 'springfield', 'answer', 'cheech', 'chong']\n",
            "['allow', 'gentleman', 'buy', 'day', 'detention', 'know']\n",
            "[\"o'clock\", 'old', 'building', 'room']\n",
            "['article', 'find', 'hire', 'professional', 'job', 'housewife', 'incidentally', 'married', 'house', 'cost', 'thousand_dollar', 'year']\n",
            "['step', 'liberation', 'free', 'male', 'impose', 'shackle']\n",
            "['think', 'burn', 'fast']\n",
            "['hm', 'guess', 'tissue', 'paper', 'inside']\n",
            "['miss', 'bouvier', 'surprised']\n",
            "['buy', 'day', 'detention', 'know']\n",
            "['hey', 'estelle', 'prom']\n",
            "['prom', 'elliot', 'gould']\n",
            "['hey', 'worry', 'barney', 'big', 'school', 'get_to', 'girl', 'want', 'prom']\n",
            "['political', 'prisoner', 'time', 'stand']\n",
            "['day', 'act', 'like', 'slap']\n",
            "['buy', 'day', 'detention']\n",
            "['day', 'okay', 'simpson', 'room']\n",
            "['jailhouse', 'romance', 'man']\n",
            "['reach', 'step', 'know', 'exist', 'problem', 'care']\n",
            "['say', 'boo', 'night', 'usually', 'wrestle', 'bucket', 'greasy', 'mitt']\n",
            "['uh', 'oh', 'grab', 'beer', 'boy']\n",
            "['cut', 'crap', 'collect', 'can', 'daddy', 'grab', 'beer']\n",
            "['girlfriend', 'real', 'looker']\n",
            "['ohhh', 'son', 'overreach', 'dented', 'car', 'dead', 'end', 'job', 'attractive', 'girl', 'ohh', 'blame', 'talk', 'long', 'time', 'ago']\n",
            "['hi', 'homer_simpson', 'need', 'guidance', 'counselor']\n",
            "['good_lord', 'simpson', 'come', 'long', 'time', 'ago']\n",
            "['yeah', 'maybe', 'meet', 'girl', 'marge', 'bouvier', 'want', 'force', 'like']\n",
            "['exactly', 'type', 'guidance']\n",
            "['like', 'think', 'helpful', 'student', 'n', 'z', 'advice', 'try', 'share', 'common', 'interest', 'spend', 'spend', 'spend']\n",
            "['oh', 'believe', 'active', 'forensic', 'team', 'meet', 'new', 'building', 'room', 'nineteen']\n",
            "['homer', 'plan', 'graduation']\n",
            "['go_to', 'drink', 'lot', 'beer', 'stay', 'night']\n",
            "['oh', 'mean', 'career', 'wise', 'know', 'nuclear_power', 'plant', 'open', 'soon', 'outfit', 'will', 'require', 'college', 'education']\n",
            "['nuclear_power', 'plant', 'kaboom']\n",
            "['bring', 'son', 'blind', 'lifetime', 'occupation', 'help', 'hurt']\n",
            "['woe', 'unto', 'shelbyville', 'underestimate', 'strength', 'dramatic', 'interpretation']\n",
            "['homer_simpson', 'like', 'sign']\n",
            "['opening', 'debate', 'team']\n",
            "['debate', 'like', 'argue']\n",
            "['stinkpot', 'warm', 'mrs', 'bloominstein']\n",
            "['year', 'topic', 'resolve', 'national', 'speed', 'limit', 'lower', 'mile', 'hour']\n",
            "['ridiculous', 'sure', 'save', 'life', 'million', 'late']\n",
            "['current', 'speed', 'limit', 'anachronism', 'fatuity']\n",
            "['wait_minute', 'word', 'call']\n",
            "['ignoramus', 'mean', 'stupid']\n",
            "['difference', 'ignorance', 'stupidity']\n",
            "['homer', 'like', 'present', 'rebuttal']\n",
            "['oh', 'remember', 'homer_simpson', 'moon', 'rebuttal']\n",
            "['problem', 'know', 'reference', 'ask', 'coach', 'flanagan', 'ask', 'mr', 'seckofsky', 'barney', 'gumbel']\n",
            "['look', 'ask', 'like', 'ask', 'position', 'touch', 'goody', 'ask', 'fair']\n",
            "['homer_simpson', 'oh', 'yeah', 'junior', 'varsity', 'shot', 'putter', 'hmmm', 'hmmm', 'think', 'apply', 'train', 'real', 'hard', 'hit', 'weight', 'foot']\n",
            "['year', 'solid', 'c', 'student', 'lamp', 'year']\n",
            "['thing', 'man', 'maybe', 'lucky', 'gal', 'wanna', 'prom']\n",
            "['like', 'nice', 'guy', 'time']\n",
            "['city', 'forensic', 'championship', 'come']\n",
            "['oh', 'tutor', 'time']\n",
            "['need', 'help', 'french']\n",
            "['french', 'coincidence', 'subject', 'have', 'trouble']\n",
            "['cagey', 'old', 'dog']\n",
            "['great', 'story', 'positively', 'spellbind', 'work', 'damn', 'work']\n",
            "['bart', 'pay_attention', 'tell', 'son', 'day', 'break']\n",
            "['ooh', 'lose', 'oh', 'plenty', 'come', 'uh', 'oh', 'zit', 'problemo']\n",
            "['help', 'study', 'heh_heh', 'heh']\n",
            "['shut', 'let', 'business']\n",
            "['tres', 'bien', 'probably', 'go', 'big', 'forensic', 'meet', 'tomorrow']\n",
            "['oh', 'wait_wait', 'wait', 'little', 'study', 'break']\n",
            "['homer', 'amazing', 'bon', 'jour', 'conjugate', 'regular', 'verb', 'irregular', 'verb', 'sing', 'verse', 'allouette']\n",
            "['allouette', 'jaunte', 'allouette', 'allouette', 'jaunte']\n",
            "['believe', 'stick', 'tell', 'new', 'stuff', 'minute', 'later', 'thank', 'marge', 'form', 'vowel', 'continent']\n",
            "['consonant', 'beautiful', 'mouth', 'beautiful', 'breath', 'push', 'past', 'beautiful', 'tooth']\n",
            "['know', 'homer', 'like', 'meet', 'dear', 'honest', 'open', 'trace', 'pretension']\n",
            "['ohhh', 'oh', 'marge', \"this'll\", 'great', 'night', 'life', 'save', 'new', 'engine', 'car', 'go_to', 'spend', 'rent', 'big', 'limo', 'go_to', 'buy', 'big', 'corsage', 'tux', 'go_to', 'wide', 'lapel', 'ruffle', 'high', 'platform', 'shoe', 'see']\n",
            "['maybe', 'wear', 'hair']\n",
            "['wait_wait', 'wait', 'marge', 'honest', 'open', 'like', 'load', 'french', 'class', 'brilliant', 'scheme', 'know', 'better']\n",
            "['know', 'city', 'forensic', 'final', 'tomorrow', 'keep', 'm', 'pretending', 'stupid', 'homer', 'j', 'simpson', 'hate']\n",
            "['hey', 'barney', 'guess', 'get', 'date', 'prom']\n",
            "['know', 'tell', 'story', 'end', 'sit', 'tell']\n",
            "['edge', 'seat', 'get', 'marry', 'kid', 'buy', 'cheap', 'tv', 'okay']\n",
            "['bring', 'son', 'blind', 'lifetime', 'occupation', 'help']\n",
            "['marge', 'appropriate', 'forum', 'forth', 'prom']\n",
            "['think', 'dozen', 'highly', 'cogent', 'argument', 'time', 'magazine', 'date', 'january', 'america', 'love', 'affair', 'prom', 'wallflower', 'look', 'forward', 'date', 'year']\n",
            "['artie', 'artie', 'good', 'argument', 'know', 'respect', 'year', 'delighted', 'prom']\n",
            "['pinch', 'check', 'glow']\n",
            "['little', 'try', 'break', 'capillary', 'dear']\n",
            "['lady', 'pinch', 'whore', 'use', 'rouge']\n",
            "['mm', 'hmm', 'suppose', 'want', 'come', 'sit']\n",
            "['marge', 'date', 'homely', 'time']\n",
            "['know', 'usually', 'insist', 'approve', 'marge', 'date', 'tell', 'sure', 'solid', 'citizen']\n",
            "['thanks', 'mr', 'b']\n",
            "['come', 'camera', 'ready']\n",
            "['say', 'hate', 'talk']\n",
            "['afraid', 'cancel', 'date', 'stay', 'away', 'completely', 'mean', 'skip', 'school', 'week', 'graduate', 'summer', 'hope']\n",
            "['artie', 'ziff', 'marge', 'date', 'prom']\n",
            "['come', 'young_man']\n",
            "['wait', 'second', 'date']\n",
            "['unpleasantness', 'forever', 'let', 'picture', 'happy', 'couple']\n",
            "['hey', 'buddy', 'date']\n",
            "['ouch', 'guess', 'want', 'home']\n",
            "['hey', 'pay', 'car', 'pay', 'tuxedo', 'pay', 'dinner', 'go', 'prom']\n",
            "['dance', 'closely', 'good', 'time', 'wait', 'second', 'bong', 'asthma', 'right']\n",
            "['homer_simpson', 'think', 'drop']\n",
            "['young_man', 'buy', 'decade', 'detention']\n",
            "['child', 'tabulate', 'vote', 'king', 'queen', 'springfield', 'high_school', 'class', 'artie', 'ziff', 'marge', 'bouvier']\n",
            "['oh', 'great', 'hail', 'queen', 'marge', 'woo', 'woo', 'long', 'live', 'queen']\n",
            "['fellow', 'classmate', 'instead', 'vote', 'athletic', 'hero', 'pretty', 'boy', 'elect', 'intellectual', 'superior', 'king', 'good']\n",
            "['say', 'king', 'queen', 'share', 'royal', 'dance']\n",
            "['bird', 'suddenly', 'appear', 'time', 'near']\n",
            "['eventually', 'like', 'hot', 'tub']\n",
            "['sure', 'mean', 'usually', 'thought', 'lot', 'thought', 'say', 'yes', 'say', 'time', 'yes', 'thing', 'sure', 'life', 'wrong']\n",
            "['okay', 'pay', 'drive']\n",
            "[\"o'clock\", 'want', 'afraid', 'go_to', 'dollar', 'hour']\n",
            "['naw', 'okay', 'broke', 'walk', 'home']\n",
            "['yeah', 'spoil', 'perfect', 'evening']\n",
            "['know', 'simpson', 'boy', 'show', 'take', 'year', 'life']\n",
            "['stop', 'go', 'good']\n",
            "['hey', 'good', 'evening', 'hezron', 'carver', 'graven', 'image']\n",
            "['ah', 'good', 'evening', 'homer', 'thief', 'business']\n",
            "['little', 'slow', 'past', 'month', 'steal', 'desert', 'know']\n",
            "['ah', 'worry', 'friend', 'figure', 'wander', 'week', 'top']\n",
            "['ah', 'good', 'evening', 'zohar', 'adulterer', 'wife', 'send', 'warm', 'regard']\n",
            "['ah', 'yes', 'good', 'woman', 'good']\n",
            "['thank', 'lusty', 'friend']\n",
            "['quick', 'everybody', 'look', 'busy']\n",
            "['lord', 'hand', 'commandment', 'live', 'read', 'particular', 'order', 'thou', 'shalt', 'grave', 'image']\n",
            "['thou', 'shalt', 'commit', 'adultery']\n",
            "['ah', 'look', 'like', 'party']\n",
            "['hey', 'moses', '-PRON-', \"comin_'\"]\n",
            "['thou', 'shall', 'steal']\n",
            "['dishonest', 'thing', 'hear']\n",
            "['box', 'ear', 'sneaky', 'pete']\n",
            "['hey', 'easy', 'property']\n",
            "['hey', 'flander', 'bug', 'butt']\n",
            "['ohhh', 'want', 'subscribe', 'new', 'art', 'craft', 'channel', 'sir', 'send', 'flimflam', 'man', 'install', 'know', 'offer', 'hook', 'illegally', 'cable', 'channel', 'buck']\n",
            "['boy', 'world', 'come']\n",
            "['hey', 'stop', 'cable', 'man', 'stop']\n",
            "['want', 'free', 'cable']\n",
            "['okay', 'mean', 'everybody', 'right']\n",
            "['oh', 'hey', 'have', 'second', 'thought', 'read', 'pamphlet']\n",
            "['decide', 'steal', 'cable']\n",
            "['myth', 'cable', 'piracy', 'wrong', 'fact', 'cable', 'company', 'big', 'faceless', 'corporation', 'make', 'okay']\n",
            "['cable', 'wonderful', 'dare', 'hope']\n",
            "['hate', 'bathroom', 'toilet', 'paper']\n",
            "['funny', 'because', 'true']\n",
            "['oh', 'hey', 'hey', 'family', 'family', 'come', 'announcement', 'simpson', 'cable']\n",
            "['cable', 'wow', 'cable']\n",
            "['right', 'channel', 'mtv', 'kid', 'vh', 'sixteen', 'hour', 'quality', 'programming', 'day']\n",
            "['homer', 'talk', 'cable', 'think', 'afford']\n",
            "['month', 'yeah', 'think', 'swing']\n",
            "['worry', 'marge', 'look']\n",
            "['myth', 'fair', 'pay', 'quality', 'run', 'movie', 'fact', 'movie', 'show', 'cable', 'star', 'repeat', 'ad', 'nauseam', 'hmm', 'know']\n",
            "['hear', 'roar', 'network', 'woman']\n",
            "['half', 'hour', 'cut', 'aid', 'bill', 'half', 'make', 'bandaid']\n",
            "['ooh', 'good', 'idea']\n",
            "['begin', 'need', 'yard', 'sterilize', 'cotton']\n",
            "['el', 'mummeo', 'le', 'pone', 'en', 'el', 'sleeper', 'hold', 'donde', 'esta', 'los', 'medicos', 'de', 'mexico']\n",
            "['oooo', 'pro', 'wrestling', 'mexico', 'know', 'real', 'sport']\n",
            "['cool', 'jaws', 'eat', 'boat']\n",
            "['cool', 'die', 'hard', 'jump', 'window']\n",
            "['cool', 'wall', 'street', 'get', 'arrest']\n",
            "['think', 'people', 'watch']\n",
            "['live', 'new', 'orleans', 'world', 'series', 'cockfighte', 'oh', 'son', 'gun', 'big', 'fun', 'bayou', 'tonight']\n",
            "['quick', 'drive', 'dad', 'car']\n",
            "['ready', 'church', 'homer']\n",
            "['huh', 'wha', \"'\", 'oh', 'okay']\n",
            "['today', 'christian', 'think', 'need', 'god', 'think', 'get', 'get', 'hi', 'fi', 'boob', 'tube', 'instant', 'pizza', 'pie']\n",
            "['right', 'child', 'want', 'frightened', 'responsibility', 'teach', 'today', 'topic', 'hell']\n",
            "['right', 'sit', 'mercy', 'sit', 'forgiveness', 'finally', 'good', 'stuff']\n",
            "['oh', 'hell', 'terrible', 'place', 'maggot', 'sheet', 'worm', 'blanket', 'lake', 'fire', 'burn', 'sulfur', 'torment', 'day', 'night', 'forever', 'matter', 'fact', 'actually', 'see', 'hell', 'frightened', 'die']\n",
            "['oh', 'miss', 'albright']\n",
            "['say', 'afterlife', 'steer', 'clear', 'abode', 'damned']\n",
            "['simple', 'rule', 'easy', 'live']\n",
            "['child', 'learn', 'today']\n",
            "['learn', 'sure', 'hell', 'tell', 'learn', 'hell', 'hell']\n",
            "['hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell', 'hell']\n",
            "['bart', 'longer', 'sunday', 'school', 'swear']\n",
            "['hey', 'anybody', 'little', 'call', 'pay', 'tv']\n",
            "['dad', 'sure', 'steal']\n",
            "['read', 'pamphlet', 'honey']\n",
            "['oh', 'goody', 'program', 'length', 'advertisement']\n",
            "['wait_minute', 'troy', 'little', 'confused', 'clean', 'straighten']\n",
            "['volunteer', 'somebody', 'crooked', 'yellow', 'tooth']\n",
            "['come', 'lisa', 'watch', 'little', 'cable']\n",
            "['will', 'cost', 'thing', 'soul']\n",
            "['whadda', 'ya', 'mean']\n",
            "['remember', 'eighth', 'commandment']\n",
            "['oh', 'course', 'thou', 'shalt', 'uh', 'covet', 'grave', 'image', 'covet']\n",
            "['thou', 'shalt', 'steal']\n",
            "['yes', 'eat', 'grape', 'charge']\n",
            "['oh', 'grape', 'care']\n",
            "['yeah', 'okay', 'right', 'need', 'price', 'check', 'grape', 'yeah', 'hear', 'phil', 'measly', 'stink', 'grape']\n",
            "['catch', 'theater', 'rent', 'someplace', 'get', 'blockbuster', 'channel']\n",
            "['dad', 'world', 'cesspool', 'corruption']\n",
            "['oh', 'great', 'right', 'make']\n",
            "['sunday', 'school', 'learn', 'steal', 'sin']\n",
            "['everybody', 'mean', 'steal', 'cable', 'speak']\n",
            "['oh', 'hm', 'look', 'way', 'breakfast', 'morning', 'pay']\n",
            "['pay', 'clothe', 'wear']\n",
            "['run', 'hills', 'ma', 'barker', 'fed']\n",
            "['dad', 'think', 'pretty', 'spurious']\n",
            "['friday', 'night', 'live', 'las', 'vegas', 'ultimate', 'match', 'bout', 'knock', 'guy']\n",
            "['watson', 'tatum', 'ii', 'time', 'money']\n",
            "['little', 'insulated', 'wire', 'bring', 'happiness']\n",
            "['hey', 'big', 'fight', \"comin_'\"]\n",
            "['yeah', 'want', 'come', 'house', 'listen', 'round', 'round', 'update', 'radio']\n",
            "['oh', 'yeah', 'okay', 'oh', 'fight', 'watch', 'photo', \"o'clock\", 'news']\n",
            "['shabby', 'whadda', 'homer']\n",
            "['hmm', 'yeah', 'house', 'watch', 'thing', 'live', 'cable', 'tv']\n",
            "['uh', 'homer_simpson', 'sir', 'drone', 'sector', 'g']\n",
            "['excellent', 'keen', 'see', 'watson', 'vs', 'tatum', 'ii', 'employee', 'house', 'oh', 'picture', 'screen', 'door', 'rust', 'filthy', 'hinge', 'mangy', 'dog', 'staggering', 'look', 'vainly', 'place', 'die']\n",
            "['permission', 'speak', 'frankly', 'sir']\n",
            "['thank', 'smither', 'candor', 'refreshing']\n",
            "['mean', 'pay', 'fight']\n",
            "['lose', 'common', 'touch', 'sir']\n",
            "['homer', 'hear', 'get', 'fight']\n",
            "['yeah', 'right', \"o'clock\", 'place', 'come', 'come']\n",
            "['hey', 'moe', 'come', 'get', 'cable', 'bar']\n",
            "['cable', 'mechanical', 'bull']\n",
            "['ooh', 'somebody', 'have', 'party']\n",
            "['yeah', 'friday', 'night', 'want', 'come']\n",
            "['thank', 'store', 'open', 'hour', 'put', 'great', 'demand', 'time']\n",
            "['oh', 'bad', 'go_to', 'great', 'fight']\n",
            "['oh', 'fight', 'brother', 'sanjay', 'cover', 'deplore', 'violence', 'kind']\n",
            "['man', 'take', 'bread', 'feed', 'starve', 'family', 'steal']\n",
            "['put', 'jelly', 'example']\n",
            "['come', 'lisa', 'reason', 'father', 'steal', 'bread']\n",
            "['maybe', 'watch', 'minute', 'sure', 'get', 'cable', 'free']\n",
            "['afraid', 'steal', 'lisa', 'think', 'hmmm']\n",
            "['lisa', 'surface', 'appear', 'ideal', 'solution', 'problem', 'remember', 'fourth', 'commandment', 'honor', 'thy', 'father', 'thy', 'mother', 'hmmm', 'lisa', 'like', 'set', 'example', 'watch', 'offending', 'technology']\n",
            "['thank', 'reverend', 'lovejoy']\n",
            "['watch', 'hat', 'entertainment', 'adult', 'program', 'day', 'day', 'florida', 'utah', 'come', 'stardust', 'memory']\n",
            "['blue', 'chip', 'close', 'quarter', 'oil', 'service', 'stock', 'slump', 'slightly', 'news', 'opec', 'continue', 'stalemate', 'meeting', 'geneva', 'switzerland']\n",
            "['son', 'watch', 'channel', 'mommy', 'daddy', 'love', 'want', 'promise', 'will', 'watch', 'channel']\n",
            "['promise', 'watch', 'channel']\n",
            "['hi', 'dad', 'think', 'steal', 'cable', 'wrong', 'choose', 'watch', 'hope', 'follow', 'example', 'hear', 'matter', 'thank', 'time']\n",
            "['hey', 'lisa', 'race', 'belmont', 'horsie']\n",
            "['wrong', 'kid', 'moral', 'like', 'like', 'bart', 'get_to', 'happy', 'medium']\n",
            "['know', 'bart', 'look', 'racy', 'movie', 'today', 'lisa', 'lose', 'little', 'respect', 'maybe', 'think', 'unhook', 'cable']\n",
            "['unhook', 'love', 'cable']\n",
            "['look', 'look', 'marge', 'afford', 'afford', 'pay', 'go']\n",
            "['homer', 'afraid', 'cable', 'evil', 'presence', 'home']\n",
            "['severely', 'tempt']\n",
            "['marge', 'sorry', 'think', 'come']\n",
            "['come', 'foot', 'marge', 'come', 'cable', 'stay', 'foot', 'speak']\n",
            "['see', 'see', 'see', 'see', 'ugh', 'soccer', 'see']\n",
            "['door', 'lock', 'way', 'wonder', 'interested', 'car', 'stereo', 'dollar', 'value', 'let', 'buck']\n",
            "['house', 'wanna', 'associate', 'criminal']\n",
            "['sure', 'want', 'homer', 'look', 'friendly']\n",
            "['marge', 'careful', 'thief', 'talk', 'small', 'forgivable', 'stuff']\n",
            "['come', 'come', 'hat', 'theatre', 'air', 'beautiful', 'woman', 'world', 'cent', 'host', 'bart_simpson', 'year_old', 'enter']\n",
            "['hat', 'channel', 'honor', 'present', 'broadcast', 'nude']\n",
            "['huh', 'know', 'come']\n",
            "['bart', 'promise', 'watch', 'trash', 'room']\n",
            "['man', 'wish', 'adult', 'break', 'rule']\n",
            "['bring', 'import', 'generic', 'beer']\n",
            "['thank', 'barney', 'people', 'come', 'homer']\n",
            "['select', 'circle', 'friend']\n",
            "['oh', 'hello', 'mrs', 'homer', 'bring', 'assortment', 'jerky']\n",
            "['oh', 'didja', 'swipe', 'work']\n",
            "['oh', 'sir', 'love', 'lose', 'warrior', 'fact', 'scuffle', 'earlier', 'today', 'weigh']\n",
            "['understand', 'special', 'motivation', 'go', 'bout']\n",
            "['yeah', 'want', 'dedicate', 'fight', 'manager', 'vinnie', 'get', 'pass', 'away', 'week', 'ago']\n",
            "['yeth', 'like', 'dedicate', 'fight', 'memory', 'deceased', 'manager']\n",
            "['dedicate', 'fight', 'manager', 'man']\n",
            "['want', 'attention', 'fact', 'watch', 'fight', 'form', 'non', 'violent', 'protest']\n",
            "['hey', 'homer', 'bring', 'ya']\n",
            "['quick', 'moe', 'get_to', 'hide', 'mug']\n",
            "['right', 'hey', 'protest', 'outside', 'ya']\n",
            "['hey', 'homer', 'bring', 'mug']\n",
            "['oooh', 'thank', 'moe', 'want']\n",
            "['mr_burns', 'bart', 'quick', 'hide', 'stuff', 'borrow', 'work']\n",
            "['right', 'stuff', 'steal', 'work']\n",
            "['quit', 'stare', 'like']\n",
            "['oh', 'hello', 'simpson']\n",
            "['neighborhood', 'think', 'drop']\n",
            "['ugh', 'ah', 'hello', 'mr_burns', 'like', 'watch', 'fight']\n",
            "['fight', 'mind', 'oh', 'simpson', 'good', 'news', 'bring', 'munchie', 'smither', 'cheetos']\n",
            "['word', 'street', 'illegal', 'cable', 'hook']\n",
            "['wife', 'wife', 'idea', 'yeah', 'yeah']\n",
            "['hey', 'hey', 'settle', 'big', 'fella']\n",
            "['whoa', 'wonder', 'watch', 'fight']\n",
            "['oh', 'sure', 'sure', 'guest']\n",
            "['lisa', 'bring', 'lemonade', 'protest']\n",
            "['thank', 'mom', 'go']\n",
            "['love', 'somebody', 'faith', 'end', 'right', 'thing']\n",
            "['challenger', 'learn', 'fight', 'notorious', 'project', 'capital_city', 'hone', 'skill', 'serve', 'time', 'aggravated', 'assault', 'manslaughter', 'springfield', 'prison']\n",
            "['right', 'local', 'boy']\n",
            "['year', 'incarcerate', 'away', 'family', 'mother', 'child', 'condition', 'irrevocable']\n",
            "['marge', 'lisa', 'maggie']\n",
            "['shake', 'hand', 'clean']\n",
            "['excuse', 'hate', 'interrupt', 'judge', 'want', 'know', 'couple', 'important', 'decision', 'number', 'cut', 'cable', 'soon', 'fight', 'number', 'fond']\n",
            "['dad', 'save', 'soul']\n",
            "['yeah', 'bad', 'possible', 'time']\n",
            "['fight', 'history', 'stick', 'fork', 'stunning', 'knockout', 'thunderous', 'bolo', 'punch', 'closing', 'second', 'twelfth', 'round', 'drederick', 'tatum', 'new', 'champion', 'world']\n",
            "['place', 'blueberry', 'squishee', 'microwave', 'burrito']\n",
            "['great', 'fight', 'miss']\n",
            "['donnybrook', 'game', 'mr_burns']\n",
            "['oh', 'hogwash', 'watch', 'gentleman', 'jim', 'corbett', 'fight', 'eskimo', 'fellow', 'bare', 'knuckle', 'thirteen', 'round', 'course', 'fight', 'last', 'round', 'demand', 'nickel']\n",
            "['dad', 'beg', 'reconsider', 'tractor', 'pull', 'atlanta', 'braves', 'baseball', 'joe', 'franklin']\n",
            "['hey', 'homer', 'barney', 'wake']\n",
            "['want', 'tell', 'new', 'barbecue', 'joint']\n",
            "['call', 'greasy', 'joe', 'bottomless', 'bar', 'b', 'q', 'pit', 'taste', 'sauce', 'finger', 'ready', 'eat']\n",
            "['like', 'beautiful', 'dream']\n",
            "['marge', 'honey', 'get', 'word', 'greasy', 'joe', 'bottomless', 'bar', 'b', 'q', 'pit']\n",
            "['homer', 'remember', 'promise', 'try', 'limit', 'pork', 'serving', 'week']\n",
            "['marge', 'human', 'look', 'go_to', 'unload', 'kid', 'patty_selma', 'saturday', 'night', 'eat', 'kick', 'place', 'like', 'old', 'time']\n",
            "['saturday', 'night', 'sure', 'sister', 'available']\n",
            "['saturday', 'go', 'stanley', 'peterson', 'wedding']\n",
            "['way', 'go', 'think', 'married']\n",
            "['hey', 'alleycat', 'save', 'honeymoon']\n",
            "['mm', 'hmm', 'beat', 'throw', 'bouquet']\n",
            "['f', 'l', 'oh', 'sorry', 'c']\n",
            "['oncoming', 'vehicle', 'dead']\n",
            "['ah', 'like', 'man']\n",
            "['friend', 'relative', 'work', 'relate', 'acquaintance', 'gather', 'today', 'join', 'stanley', 'martha', 'holy', 'matrimony']\n",
            "['martha', 'dear', 'remember', 'day', 'meet']\n",
            "['choose', 'seat', 'martha', 'love', 'know', 'walnut', 'end']\n",
            "['brandy', 'fine', 'girl', 'good', 'wife', 'life', 'love', 'lady', 'sea']\n",
            "['poor', 'brandy', 'aunt', 'selma', 'think', 'marry']\n",
            "['oh', 'know', 'know', 'somebody']\n",
            "['sure', 'resent', 'pity', 'year_old', 'niece', 'simply', 'hope', 'statistically', 'insignificant', 'year_old', 'single', 'woman', 'find', 'fair', 'prince']\n",
            "['patty_selma', 'home']\n",
            "['tell', 'thing', 'greasy', 'joe', 'sorry', 'see', 'like']\n",
            "['marge', 'need', 'speak']\n",
            "['oh', 'sauce', 'barney', 'drink', 'bowl', 'barney', 'sister', 'law']\n",
            "['right', 'point', 'get', 'old', 'fat', 'uglier', 'marge', 'help', 'find', 'man', 'late']\n",
            "['homer', 'remember', 'family', 'vacation', 'bowler', 'hall', 'fame', 'st', 'louis', 'missouri', 'car', 'shape', 'like', 'giant', 'bowling', 'pin']\n",
            "['remember', 'owe', 'favor']\n",
            "['call', 'reason', 'desire']\n",
            "['want', 'find', 'husband', 'sister', 'selma']\n",
            "['find', 'husband', 'selma']\n",
            "['like', 'police', 'academy', 'movie', 'hummel', 'figurine', 'walk', 'park', 'clear', 'autumn', 'day']\n",
            "['oh', 'yeah', 'yeah', 'yeah', 'think', 'like', 'know', 'touch']\n",
            "['patty', 'choose', 'life', 'celibacy', 'selma', 'simply', 'celibacy', 'thrust']\n",
            "['homer', 'find', 'man']\n",
            "['oh', 'gee', 'tai', 'kwon']\n",
            "['honest', 'caring', 'handsome']\n",
            "['hey', 'well', 'husband']\n",
            "['sodium', 'tetrasulfate', 'highly', 'caustic', 'remove', 'skin']\n",
            "['chiefly', 'manufacture', 'rayon', 'film', 'preservative', 'fast', 'food', 'potent', 'herbicide']\n",
            "['find', 'man', 'find', 'man', 'find', 'man']\n",
            "['boy', 'good', 'man', 'hard', 'find']\n",
            "['gentleman', 'accord', 'source', 'plan', 'simultaneously', 'drop', 'pencil', 'afternoon', 'suspend']\n",
            "['vandalism', 'fan', 'hold', 'hat']\n",
            "['seafood', 'burrito', 'apu']\n",
            "['loathe', 'interrupt', 'meditation', 'time', 'come', 'money', 'change', 'hand']\n",
            "['cafeteria', 'think', 'best', 'tater', 'tot', 'money', 'buy']\n",
            "['wait_minute', 'smell_like', 'sodium', 'tetrasulfate', 'bond', 'chlorophyll']\n",
            "['bart', 'flabbergast', 'surely', 'know', 'write', 'foot', 'high', 'letter', 'field', 'catch']\n",
            "['maybe', 'bart', 'sir']\n",
            "['sheer', 'contempt', 'demonstrate', 'incident', 'make', 'wish', 'pull', 'trusty', 'board', 'education', 'retirement']\n",
            "['minute', 'let', 'check', 'homer', 'sexual', 'come', 'come', 'guy', 'homer', 'sexual']\n",
            "['rotten', 'little', 'punk', 'hold', 'sink', 'tooth', 'cheek', 'rip', 'face']\n",
            "['think', 'real', 'question', 'homer_simpson']\n",
            "['oh', 'sorry', 'principal_skinner', 'bad', 'connection', 'think', 'bart', 'trouble']\n",
            "['afraid', 'time', 'victim', 'innocent', 'blade', 'grass', 'groundskeeper', 'willie', 'award', 'win', 'play', 'field', 'right', 'bart', 'repay', 'debt', 'society', 'break', 'physical', 'labor', 'sod', 'field', 'manually', 'seed', 'seed']\n",
            "['bart', 'tell', 'principal_skinner', 'married']\n",
            "['married', 'job', 'tend', 'girl', 'right']\n",
            "['course', 'pant', 'come', 'night', 'like', 'tell', 'question']\n",
            "['oh', 'reason', 'wonder', 'know', 'like', 'come', 'house', 'dinner', 'payback', 'crummy', 'thing', 'bart', 'school']\n",
            "['home', 'cooked', 'meal', 'nice', 'change', 'pace', 'delighted']\n",
            "['good', 'evening', 'principal_skinner', 'welcome', 'home']\n",
            "['thank', 'bart', 'hope', 'hour', 'leave', 'difference', 'schoolyard']\n",
            "['wait', 'shake', 'money', 'maker']\n",
            "['simpson', 'discomforte', 'thought', 'way', 'dinner', 'master', 'plan', 'set', 'unmarried', 'relation', 'assure']\n",
            "['ah', 'muh', 'foolish', 'heart']\n",
            "['heh_heh', 'heh', 'boy', 'meet', 'beast', 'principal_skinner', 'allow', 'introduce', 'wife', 'lovely', 'available', 'sister', 'selma']\n",
            "['hey', 'baldilock', 'patty']\n",
            "['patty', 'tell', 'trip', 'egypt']\n",
            "['tell', 'nile', 'smell_like', 'cattle', 'rot', 'get', 'horsefly', 'size', 'fist']\n",
            "['selma', 'hate', 'egypt', 'camel', 'spit']\n",
            "['oh', 'yes', 'hear', 'difficult', 'patty', 'parents', 'advisory', 'board', 'ask', 'attend', 'premiere', 'space', 'mutant', 'tomorrow', 'night', 'interested', 'join']\n",
            "['plan', 'tomorrow', 'night']\n",
            "['afraid', 'microwave', 'cookery', 'class']\n",
            "['patty', 'date', 'year', 'little', 'important', 'play', 'heart', 'mother']\n",
            "['pack', 'lady', 'laramie', 'hundred']\n",
            "['god', 'know', 'easily', 'easily', 'laramie', 'hi', 'tars', 'hard', 'pack', 'day']\n",
            "['smoke', 'good', 'health', 'need', 'lottery', 'ticket']\n",
            "['stupid', 'principal_skinner', 'sense', 'humor']\n",
            "['save', 'strength', 'lad', 'field', 'resod']\n",
            "['bart', 'happen', 'know', 'sort', 'candy', 'aunt', 'patty', 'like']\n",
            "['cherry', 'cordial', 'sir']\n",
            "['good', 'punishment', 'feel', 'learn', 'lesson']\n",
            "['thought', 'bad', 'make', 'stomach', 'turn']\n",
            "['willie', 'adio', 'dude']\n",
            "[\"c'mon\", 'patty', 'want', 'look', 'like', 'yosemite', 'sam']\n",
            "['cherry', 'cordial', 'hope', 'like', '-PRON-']\n",
            "['yeah', 'like', '-PRON-', 'okay', 'come', 'let']\n",
            "['ah', 'excellent', 'suggestion', 'suggest', 'start', 'springfield', 'revolving', 'restaurant', 'know', 'food', 'taste', 'better', 'revolve']\n",
            "['yeah', 'right', 'far', 'evening', 'big', 'disappointment']\n",
            "['hey', 'service', 'ask', 'water', 'time']\n",
            "['far', 'evening', 'big', 'disappointment']\n",
            "['little', 'jimmy', 'pearson', 'class', \"'\", 'believe']\n",
            "['good', 'evening', 'principal_skinner']\n",
            "['pearson', 'woman', 'glass', 'water', 'immediately', 'tuck', 'shirt']\n",
            "['nearly', 'thirty', 'work', 'busboy', 'standardize', 'testing', 'lie']\n",
            "['surprise', 'lucky', 'minute', 'young', 'skin', 'like', 'china', 'doll', 'bosoms', \"'_til\", 'tuesday']\n",
            "['worry', 'plenty', 'fish', 'sea', 'right', 'homer']\n",
            "['oh', 'yes', 'plenty', 'fish', 'bait']\n",
            "['oh', 'uh', 'sorry']\n",
            "['come', 'luv', 'loosen']\n",
            "['forget', 'happen', 'poor', 'dingo', 'horrible', 'thing']\n",
            "['oh', 'probably', 'wallaby', 'come']\n",
            "['oh', 'bad', 'film', 'see']\n",
            "['bad', 'service', 'revolving', 'restaurant']\n",
            "['nice', 'hate', 'thing']\n",
            "['kiss', 'patty', 'cootie']\n",
            "['thursday', 'go', 'food', 'shopping', 'come', 'like']\n",
            "['tell', 'filthy', 'detail', 'tongue', 'tired']\n",
            "['selma', 'lousy', 'meal', 'movie', 'awful', 'goodnight']\n",
            "['right', 'kiss', 'want', 'brag', 'friend', 'score']\n",
            "['wish', 'p', 'announcement', 'world', 'attention', 'seymour', 'skinner', 'love']\n",
            "['bart', 'skinner', 'go_to', 'kill']\n",
            "['ah', 'bart', 'hate', 'pull', 'away', 'daily', 'exercise']\n",
            "['want', 'know', 'go', 'ask', 'aunt', 'patty', 'hand', 'marriage']\n",
            "['lighten', 'homer', 'make', 'happy', 'hour', 'bitterly', 'ironic']\n",
            "['ah', 'moe', 'get_to', 'find', 'date', 'big', 'fat', 'snotty', 'sister', 'law', 'selma']\n",
            "['intrigue', 'selma', 'look', 'like']\n",
            "['like', 'wife', 'ugly', 'sister']\n",
            "['wheel', 'homer', 'picky', 'man']\n",
            "['good', 'rule', 'thumb', 'year', 'salary', 'sir', 'try']\n",
            "['homer', 'sister', 'go', 'barney', 'gumbel']\n",
            "['hey', 'selma', 'prize', 'pig', 'know']\n",
            "['bart', 'come', 'cheer', 'aunt', 'selma']\n",
            "['learn', 'school', 'today']\n",
            "['principal_skinner', 'go', 'ask', 'aunt', 'patty', 'marry']\n",
            "['thank', 'kid', 'day']\n",
            "[\"'\", 'marge', 'heifer', 'plain', 'simple']\n",
            "['oh', 'little', 'prom', 'queen']\n",
            "['sweet', 'talk', 'right', 'time', 'ashcan', 'girlish', 'hope', 'dream', 'grab', 'hold', 'train', 'station']\n",
            "['selma', 're', 'ding_ding']\n",
            "['dolle', 'like', 'chorus', 'girl']\n",
            "['take', 'ripe', 'piece', 'cheese', 'catch', 'mouse']\n",
            "['time', 'away', 'love', 'like', 'cheap', 'wine']\n",
            "['hey', 'look', 'bring', 'schnapps']\n",
            "['preoccupy', 'tonight', 'little', 'pudding', 'cup']\n",
            "['sister', 'date', 'big', 'fat', 'rummy']\n",
            "['oh', 'pick', 'spirit']\n",
            "['jeezum', 'crow', 'look', 'size', 'rock']\n",
            "['second', 'precious', 'jewel', 'bell', 'tower', 'patty', 'question', 'marry']\n",
            "['seymour', 'know', 'mean', 'awk']\n",
            "['love', 'caloo', 'calay']\n",
            "['special', 'tie', 'sister']\n",
            "['mmm_hmm', 'man', 'marry', 'understand']\n",
            "['leave', 'sister', 'man', 'oh']\n",
            "['yes', 'know', 'appreciate']\n",
            "['exactly', 'kind', 'catch']\n",
            "['good', 'night', 'sweet', 'principal']\n",
            "['oh', 'springfield_elementary', 'tomorrow', 'school', 'day']\n",
            "['get', 'service', 'year', 'blur']\n",
            "['hope', 'find', 'man', 'like', 'patty', 'throw', 'away', 'chance', 'happiness']\n",
            "['listen', 'barney', 'eh']\n",
            "['break', 'heart', 'moe']\n",
            "['worry', 'barney', 'time', 'heal', 'wound']\n",
            "['know', 'right', 'look', 'pitcher']\n",
            "['let', 'new', 'business', 'take', 'care', 'mcbain']\n",
            "['worry', 'senator', 'mendoza', 'dear', 'friend', 'mcbain', 'meet', 'shall', 'unfortunate', 'accident']\n",
            "['excellent', 'mcbain', 'way', 'stop', 'new', 'business']\n",
            "['certainly', 'break', 'meeting']\n",
            "['rule', 'constrain', 'man', 'mean', 'mcbain', 'rule', 'constrain', 'man', 'mean', 'mcbain']\n",
            "['punch', 'bring', 'pain', 'man']\n",
            "['romantic', 'subplot', 'feel', 'tack']\n",
            "['short', 'demand', 'refund']\n",
            "['hey', 'heart', 'attack', 'old', 'dude']\n",
            "['tell', 'young', 'whipper', 'snap']\n",
            "['thank', 'nuclear_power', 'cause', 'single', 'prove', 'fatality', 'country', 'amen']\n",
            "['nicely', 'say', 'homer']\n",
            "['dad', 'bart', 'eat', 'green', 'bean', 'blessing']\n",
            "['know', 'open', 'eye', 'blessing']\n",
            "['eat', 'bad', 'open', 'eye']\n",
            "['quiet', 'kid', 'hear', 'word', 'bart', 'watch', 'cartoon', 'lisa', 'college']\n",
            "['think', 'say', 'knock']\n",
            "['panta', 'ma', 'mime']\n",
            "['hospital', \"y'ello\", 'oh_god']\n",
            "['homer', 'happy', 'father', 'mild', 'arrhythmia']\n",
            "['mild', 'mild', 'pharmacy', 'quack']\n",
            "['oh', 'feisty', 'attitude', 'bury', 'grampa', 'simpson']\n",
            "['pull', 'chair', 'closer', 'son']\n",
            "['p', 'u', 'close', 'ish', 'homer', 'heart', 'attack', 'realize', 'go', 'die', 'someday']\n",
            "['oh', 'dad', 'imagination']\n",
            "['think', 'know', 'homer', 'half', 'brother']\n",
            "['huh', 'uh', 'happen', 'court', 'mother']\n",
            "['check', 'skirt', 'local', 'carnival', 'see']\n",
            "['hey', 'handsome', 'want', 'dunk', 'clown']\n",
            "['thing', 'mother', 'like', 'sex', 'money']\n",
            "['year', 'later', 'carnival', 'come', 'town', 'little', 'surprise']\n",
            "['leave', 'baby', 'shelbyville', 'orphanage', 'see', 'year', 'later', 'marry', 'mother']\n",
            "['abe', 'want', 'homer', 'grow', 'respect', 'father', 'know', 'carnival', 'incident']\n",
            "['promise', 'will', 'tell']\n",
            "['whoops', 'forget', 'tell']\n",
            "['make', 'feel', 'special', 'dad', 'keep', 'mean', 'love']\n",
            "['hmmm', 'interesting', 'theory']\n",
            "['go', 'find', 'brother', 'care', 'take', 'heaven', 'earth', 'go', 'find']\n",
            "['yeah', 'right', 'good_luck']\n",
            "['long', 'lose', 'half', 'brother', 'dickensian']\n",
            "['idea', 'bastard', 'live']\n",
            "['parent', 'married', 'correct', 'word']\n",
            "['bastard', 'bastard', 'bastard', 'bastard', 'bastard', 'bastard']\n",
            "['bastard', 'bastard', 'bastard']\n",
            "['ooo', 'little', 'late', 'pal', 'tear', 'orphanage', 'thirty', 'odd', 'year_ago']\n",
            "['thirty_year', 'find', 'doom', 'walk', 'life', 'oh', 'brother', 'art', 'thou']\n",
            "['easy', 'buddy', 'move', 'street']\n",
            "['oh', 'hee_hee', 'sorry']\n",
            "['know', 'feel', 'mr_simpson']\n",
            "['spend', 'year', 'search', 'long', 'lose', 'twin', 'brother']\n",
            "['yeah', 'yeah', 'yeah', 'wish', 'help', 'look', 'brother', 'today', 'tell']\n",
            "['hmmm', 'accord', 'record', 'mr', 'mrs', 'powell', 'adopt', 'brother', 'name', 'herbert']\n",
            "['herbert', 'herbert', 'powell', 'great', 'find']\n",
            "['sorry', 'allow', 'release', 'information']\n",
            "['oh', 'life', 'talk']\n",
            "['sympathize', 'situation', 'mr_simpson', 'brother', 'detroit']\n",
            "['know', 'want', 'narrow']\n",
            "['know', 'mr_simpson', 'ask', 'city', 'brotherly', 'love', 'philadelphia', 'detroit']\n",
            "['ask', 'change', 'subject', 'make', 'worthless', 'heartless', 'excuse', 'human']\n",
            "['read', 'line', 'fool']\n",
            "['oh', 'oh', 'okay', 'buck', 'tell', 'brother', 'live']\n",
            "['mr_simpson', 'want']\n",
            "['detroit', 'live', 'detroit']\n",
            "['let', 'powell', 'powell', 'powell', 'pomerant', 'poole', 'popkin', 'potter', 'quigley', 'quimby', 'randolph', 'whoop', 'far', 'powell']\n",
            "['call', 'herbert', 'powell', 'detroit']\n",
            "['want', 'try', 'h', 'powell']\n",
            "['h', 'course', 'stand', 'herbert', 'long', 'shot']\n",
            "['hello', 'h', 'powell', 'detroit', 'michigan']\n",
            "['chance', 'h', 'stand', 'herbert']\n",
            "['woo', 'woo', 'h', 'stand', 'herbert', 'herb', 'adopt']\n",
            "['baby', 'brother', 'homer']\n",
            "['hello', 'hello', 'hello', 'stupid', 'phone']\n",
            "['hey', 'hey', 'knock', 'silent', 'emotion', 'involve']\n",
            "['homer', 'think', 'need']\n",
            "['okay', 'brother', 'grab', 'plane', 'springfield', 'get', 'couch', 'fold']\n",
            "['little', 'little', 'little', 'little']\n",
            "['bart', 'lisa', 'behave', 'turn', 'car', 'right', 'home']\n",
            "['marge', 'want', 'brother']\n",
            "['oh_god', 'sakes', 'homer', 'threat']\n",
            "['know', 'go', 'oh', 'sorry', 'sir', 'know']\n",
            "['okay', 'carry', 'way', 'handle', 'marge']\n",
            "['day', 'lose', 'ground', 'japanese', 'want', 'know']\n",
            "['uh', 'unfair', 'trade', 'practice']\n",
            "['mushy', 'head', 'worlder', 'washington']\n",
            "['uh', 'sort', 'gypsy', 'curse']\n",
            "['tired', 'excuse', 'hire', 'harvard', 'deadhead']\n",
            "['yeah', 'mommy', 'daddy', 'pay', 'way', 'work', 'way', 'wash', 'dish', 'scrub', 'toilet']\n",
            "['oh', 'yeah', 'remember']\n",
            "['come', 'new', 'economy', 'model']\n",
            "['go_to', 'love', 'chief', 'persephone']\n",
            "['persephone', 'hell', 'kind', 'persephone']\n",
            "['greek', 'goddess', 'spring', 'rebirth']\n",
            "['sir', 'carry', 'hade', 'king', 'underworld', 'eat', 'pomegranate']\n",
            "['people', 'want', 'car', 'name', 'hungry', 'old', 'greek', 'broad', 'want', 'name', 'like', 'mustang', 'cheetah', 'vicious', 'animal', 'name', 'problem', 'guy', 'forget', 'root', 'root']\n",
            "['guess', 'extend', 'angle', 'meet', 'saxon']\n",
            "['word', 'white', 'meet', 'bread']\n",
            "['sir', 'love', 'know', 'root', 'teach']\n",
            "['root', 'know', 'lonely', 'guy']\n",
            "['marge', 'right', 'address']\n",
            "['homer', 'homer', 'welcome', 'home', 'brother']\n",
            "['holy', 'moly', 'bastard', 'rich']\n",
            "['herb', 'allow', 'introduce', 'family', 'wife', 'marge']\n",
            "['hello', 'old', 'dog', 'gorgeous']\n",
            "['child', 'bart', 'lisa', 'maggie']\n",
            "['hello', 'mr', 'powell']\n",
            "['yeah', 'boy', 'close']\n",
            "['lisa', 'little', 'hell', 'raiser', 'father', 'tell']\n",
            "['little', 'hell', 'raiser', 'sir']\n",
            "['like', 'hold', 'baby', 'herb']\n",
            "['oh', 'afraid', 'know']\n",
            "['know', 'dive', 'catch']\n",
            "['god', 'new', 'baby', 'smell', 'homer', 'rich', 'man', 'know']\n",
            "['want', 'right', 'home', 'anytime', 'hungry', 'anytime', 'day', 'night', 'cook', 'want']\n",
            "['absolutely', 'tennis', 'court', 'swimming', 'pool', 'screening', 'room']\n",
            "['mean', 'want', 'pork_chop', 'middle', 'night', \"guy'll\", 'fry', '-PRON-']\n",
            "['sure', 'pay', 'need', 'towel', 'laundry', 'maid']\n",
            "['wai', 'wai', 'wait_wait', 'wait', 'let', 'get', 'straight', 'christmas', 'day', 'm', 'rumble', 'stomach']\n",
            "['old_man', 'sure', 'love', 'pork_chop']\n",
            "['sure', 'uncle', 'herb']\n",
            "['bart', 'uncle', 'herb', 'sound', 'formal', 'think', 'unky', 'herb']\n",
            "['problemo', 'unky', 'herb']\n",
            "['adorable', 'nephew', 'adorable']\n",
            "['hmm', 'meet', 'homer', 'high_school', 'get', 'marry', 'beautiful', 'child']\n",
            "['actually', 'tell', 'pretty']\n",
            "['watch', 'dive', 'watch', 'dive', 'watch', 'dive']\n",
            "['watch', 'watch', 'watch']\n",
            "['millionaire', 'keep', 'wrong', 'look', 'son', 'come', 'soon', 'outta', 'meantime', 'pleeze', 'stupid']\n",
            "['unky', 'herb', 'spit']\n",
            "['love', 'kid', 'hock', 'brain']\n",
            "['ohh', 'oh', 'get']\n",
            "['hello', 'cook', 'sorry', 'bother', 'late', 'get', 'hankerin', \"'\", 'right', 'forget', 'apple', 'sauce']\n",
            "['okay', 'homer', 'pick', 'want']\n",
            "['sure', 'want', 'car']\n",
            "['hey', 'know', 'thing', 'cost', 'maybe', 'buck', 'worth', 'steel']\n",
            "['oh', 'okay', 'like', 'big']\n",
            "['americans', 'want', 'big', 'car']\n",
            "['sorry', 'car', 'pep']\n",
            "['americans', 'want', 'good', 'mileage', 'pep']\n",
            "['homer', 'tell', 'nice', 'man', 'country', 'come']\n",
            "['hear', 'moron', 'get', 'kill', 'marketplace', 'instead', 'listen', 'people', 'want', 'tell', '-PRON-', 'want', 'homer', 'need', 'help']\n",
            "['yeah', 'want', 'help', 'design', 'car', 'car', 'homer_simpson', 'want', 'pay', 'thousand_dollar', 'year']\n",
            "['homer', 'meet', 'team', 'engineer', 'go_to', 'build', 'car']\n",
            "['boy', 'girl', 'project', 'priority', 'hold', 'want', 'finish']\n",
            "['direct', 'question', 'mister', 'homer_simpson', 'man', 'vision', 'man', 'go_to', 'bust', 'company', 'rut', 'man', 'go', 'change', 'american', 'transportation', 'forever']\n",
            "['kind', 'car', 'like', 'mr_simpson']\n",
            "['kid', 'want', 'today', 'tell', 'unky', 'herb']\n",
            "['want', 'pony', 'ride', 'unky', 'herb']\n",
            "['want', 'boat', 'ride', 'unky', 'herb']\n",
            "['pony', 'ride', 'boat', 'ride', 'pony', 'ride', 'boat', 'ride']\n",
            "['right', 'wooo', 'doohickey']\n",
            "['mr_simpson', 'brother', 'tell', 'help', 'car']\n",
            "['hmmm', 'hmmm', 'coffee']\n",
            "['bat', 'unky', 'herbbbb']\n",
            "['ugh', 'oh', 'boy']\n",
            "['hey', 'homer', 'car', 'come']\n",
            "['oh', 'fine', 'put', 'board', 'rack', 'peanut', 'steering']\n",
            "['ask', 'rack', 'pinion', 'steering']\n",
            "['uh', 'yeah', 'think']\n",
            "['ask', 'know', 'call', 'rack', 'peanut', 'steering']\n",
            "['homer', 'know', 'give', 'job']\n",
            "['nah', 'think', 'genius']\n",
            "['homer', 'give', 'job', 'average', 'schmoo']\n",
            "['need', 'little', 'self', 'confidence']\n",
            "['ah', 'unky', 'herb', 'know', 'car']\n",
            "['bye', 'unky', 'herb']\n",
            "['listen', 'sure', 'sure', 'understand']\n",
            "['answer', 'self', 'confidence']\n",
            "['right', 'egghead', 'want', 'place', 'car', 'drink']\n",
            "['sir', 'car', 'beverage', 'holder']\n",
            "['hel', 'lo', 'hel', 'lo', 'einstein', 'say', 'place', 'drink', 'know', 'super', 'slaker', 'sell', 'kwik_e', 'mart', 'cup', 'big']\n",
            "['extremely', 'large', 'beverage', 'holder']\n",
            "['know', 'little', 'ball', 'aerial', 'find', 'car', 'parking', 'lot', 'car']\n",
            "['thing', 'snazzy', 'style', 'like', 'tail', 'fin', 'bubble', 'dome', 'shag', 'carpeting']\n",
            "[\"y'ello\", 'uh_huh', 'know', 'glad', 'nervous', 'mean', 'right', 'track', 'uh_huh', 'uh_huh', 'uh_huh', 'right', 'right', 'okay', 'go_to', 'go_to', 'hang', 'exact', 'opposite', 'say', 'good', 'bye']\n",
            "['bart', 'lisa', 'come']\n",
            "['want', 'hear', 'guy', 'plant', 'think', 'old_man']\n",
            "['homer_simpson', 'brilliant', 'man', 'lot', 'think', 'practical', 'idea', 'insure', 'financial', 'security', 'company', 'year', 'come', 'oh', 'yes', 'personal', 'hygiene', 'reproach']\n",
            "['want', 'horn', 'find', 'horn', 'mad', 'play', 'la', 'cucaracha']\n",
            "['kid', 'seat', 'holler', 'make', 'nuts', 'get']\n",
            "['maybe', 'build', 'video', 'game', 'entertain']\n",
            "['fire', 'brother', 'pay']\n",
            "['separate', 'sound', 'proof', 'bubble', 'dome', 'kid', 'optional', 'restraint', 'nuzzle']\n",
            "['bullseye', 'thing', 'gun', 'motor', 'want', 'people', 'think', 'world', 'come', 'end', 'vroom', 'vroom', 'vroom']\n",
            "['mouse', 'name', 'itchy']\n",
            "['cat', 'name', 'scratchy']\n",
            "['oh', 'good', 'good', 'good', 'good']\n",
            "['think', 'waste', 'life', 'board', 'room', 'stockholder', 'meeting', 'watch', 'cartoon', 'old', 'fool', 'waste', 'life']\n",
            "['hello', 'miss', 'antarctic']\n",
            "['lady_gentleman', 'esteem', 'stockholder', 'member', 'press', 'holiness', 'tonight', 'go', 'witness', 'automotive', 'history']\n",
            "['life', 'search', 'car', 'feel', 'certain', 'way']\n",
            "['powerful', 'like', 'gorilla', 'soft', 'yield', 'like', 'nerf', 'ball', 'find']\n",
            "['lady_gentleman', 'present', 'car', 'design', 'average', 'man', 'homer']\n",
            "['uh', 'jerry', 'sticker', 'price']\n",
            "['eighty', 'thousand_dollar', 'monstrosity', 'cost', 'eighty', 'thousand_dollar', 'mean', 'zoo', 'fun', 'ruin']\n",
            "['gee', 'herb', 'lose', 'business', 'home', 'possession', 'help', 'think', 'maybe', 'well', 'come', 'life']\n",
            "['maybe', 'well', 'maybe', 'spongehead', 'course', 'well', 'far', 'concerned', 'brother']\n",
            "['maybe', 'say', 'conversation']\n",
            "['life', 'unbridled', 'success', 'find', 'simpson']\n",
            "['millionaire', 'chip', 'old', 'block', 'sonny', 'boy']\n",
            "['dad', 'explain', 'way', 'home']\n",
            "['think', 'car', 'cool']\n",
            "['thank', 'boy', 'wait']\n",
            "['bad', 'dog', 'let', 'bad', 'santa_little', 'helper', 'stop', 'sport', 'section']\n",
            "['stay', 'away', 'homer', 'food']\n",
            "['time', 'lisa', 'school', 'day']\n",
            "['hmmm', 'lisa', 'look']\n",
            "['mom', 'tape', 'lunch', 'box', 'hand']\n",
            "['ohhh', 'burn', 'cheek', 'swollen', 'think', 'mump', 'call', 'doctor', 'hibbert']\n",
            "['marge', 'dog', 'hungry']\n",
            "['good_friend', 'good_friend', 'good_friend']\n",
            "['hello', 'doctor', 'hibbert', 'marge', 'simpson']\n",
            "['uh', 'angry', 'home', 'number', 'ingenious']\n",
            "['doctor', 'think', 'lisa', 'mumps']\n",
            "['mrs_simpson', 'like', 'rely', 'diagnosis', 'think', 'professionally', 'derelict', 'let', 'check', 'schedule']\n",
            "['mm', 'hm', \"o'clock\", 'fine', 'thank', 'dr_hibbert']\n",
            "['way', 'fake', 'lisa', 'stay', 'home', 'stay', 'home']\n",
            "['bart', 'stay', 'home', 'go', 'school']\n",
            "['wait_minute', 'lisa', 'go', 'school', 'school', 'lisa', 'stay', 'home', 'stay', 'home', 'lisa', 'go', 'school']\n",
            "['lisa', 'confuse', 'brother', 'like', 'nice', 'day', 'school', 'bart']\n",
            "['homework', 'mrs', 'hoover']\n",
            "['homework', 'lisa', 'waste', 'chicken', 'pox', 'waste', 'mumps']\n",
            "['hey', 'otto', 'man']\n",
            "['yo', 'hairy', 'bro']\n",
            "['home', 'boy', 'home']\n",
            "['wander', 'mongrel', 'mom', 'pop', 'operation']\n",
            "['simpson', 'sylvia', 'winfield', 'canine', 'pool', 'call', 'dog', 'warden', 'right']\n",
            "['oh', 'ahead', 'precious', 'dog', 'warden', 'old', 'battle', 'ax', 'dog', 'tie', 'backyard']\n",
            "['family', 'block', 'earth', 'inconsiderate', 'let', 'monster', 'like', 'roam', 'free']\n",
            "['lose', 'hearing', 'stupid', 'go', 'explain', 'time', 'go', 'hang', 'dog', 'tie', 'dog', 'outside', 'look', 'right']\n",
            "['hey', 'lenny', 'need', 'leave', 'early', 'cover', 'ya']\n",
            "['hey', 'sure', 'thing', 'homer']\n",
            "['howdaly', 'simpson', \"gettin_'\", 'little', 'exercise', 'eh', 'good', 'pal', 'oh', 'look', 'old', 'rascal', 'wet', 'old', 'baby', 'boy', 'water', 'monster']\n",
            "['mr', 'universe', 'take', 'walk', 'haw_haw']\n",
            "['mr', 'universe', 'wish']\n",
            "['look', 'heavy', 'hand', 'ankle', 'weight', 'cute', 'assassin']\n",
            "['oh', 'betcha', 'know', 'get', 'velcro', 'strap', 'water', 'pump', 'tongue', 'build', 'pedometer', 'reflective', 'sidewall', 'little', 'vanity', 'license', 'plate']\n",
            "['know', 'givin', \"'\", '-PRON-', 'away', 'get', 'spoil']\n",
            "['whoops', 'heart', 'rate', 'drop', 'well', 'skedaddley']\n",
            "['hmmm', 'huh', 'discoloration', 'saliva', 'gland']\n",
            "['swell', 'peritage']\n",
            "['yeah', 'look', 'like', 'little', 'lisa', 'mump', 'guess', 'miss', 'week', 'school', 'young_lady']\n",
            "['oh', 'want', 'fall', 'class']\n",
            "['oh', 'responsibility', 'little_girl', 'favorite', 'subject']\n",
            "['arithmetic', 'know', 'polygon', 'hypotenuse', 'euclidean', 'algorithm', 'rest', 'wowwipop']\n",
            "[\"y'ello\", 'hi', 'lisa', 'wrong', 'mumps', 'oooh', 'kissing', 'disease', 'little_girl', 'grow']\n",
            "['yuck', 'quit', 'dad']\n",
            "['little_girl', 'want', 'let', 'write', 'copy', 'teen', 'dream', 'teen', 'scream', 'teen', 'steam', 'magazine', 'okay', 'sickie', 'goodbye', 'lisa']\n",
            "['wow', 'neat', 'smell', 'historic']\n",
            "['generation', 'woman', 'family', 'add', 'square', 'turn']\n",
            "['oh', 'know', 'sew']\n",
            "['oh', 'yes', 'know', 'memory', 'million', 'drop', 'stitch', 'flow', 'vein']\n",
            "['need', 'develop', 'callous']\n",
            "['sewing', 'finger', 'honey']\n",
            "['oh', 'man', 'dollar', 'uh', 'daughter']\n",
            "['got_to', 'spoil', 'spoil', 'spoil']\n",
            "['simpson', 'order', 'buy', 'shoe']\n",
            "['okay', 'flander', 'boss', 'heh_heh', 'heh']\n",
            "['truckin', \"'\", 'mean']\n",
            "['ooh', 'phonics', 'functions', 'vocabulary', 'remedial', 'reading', 'oh', 'homework', 'bart']\n",
            "['magazine', 'guy', 'name', 'corey']\n",
            "['yep', 'hee_hee', 'read', '-PRON-', 'weep']\n",
            "['better', 'big', 'one']\n",
            "['think', 'agree', 'consult', 'major', 'purchase']\n",
            "['buy', 'smoke', 'alarm', 'single', 'fire']\n",
            "['manhunt', 'woman', 'hunt']\n",
            "['actor', 'eyeball', 'need', 'look', 'white']\n",
            "['homer', 'lot', 'good', 'obedience', 'school']\n",
            "['oh', 'school', 'right', 'yeah', 'answer']\n",
            "['oooh', 'look', 'reputable']\n",
            "['lovely', 'handwriting', 'toffee', 'neat', 'job']\n",
            "['borrow', 'satan', 'little_helper']\n",
            "['know', 'little', 'love', 'compassion', 'puppy', 'grow', 'cuddly', 'little', 'bundle', 'joy', 'stuff', 'nonsense', 'teach', 'charlatan', 'learn', 'bloody', 'twit', 'let', 'tell', 'important', 'word', 'hear', 'life', 'choke', 'chain']\n",
            "['raise', 'dog', 'way', 'raise', 'child', 'simple', 'authoritative', 'command', 'lie']\n",
            "['follow', 'immediate', 'correction']\n",
            "['tell', 'maneuver', 'effectively']\n",
            "['dog', 'eye', 'cross', 'tongue', 'protrude', 'change', 'color', 'slightly']\n",
            "['dog', 'dead', 'madam']\n",
            "['know', 'ask', 'choke', 'chain', 'misnomer', 'trust', 'breathe']\n",
            "['jack', 'think', 'baby']\n",
            "['oh', 'sure', 'doll', 'face', 'like', 'prove']\n",
            "['treat', 'like', 'garbage']\n",
            "['way', 'love', 'baby']\n",
            "['oh', 'know', 'dip', 'watch', 'today', 'brandy', 'come', 'coma', 'know', 'phony', 'prince', 'body', 'hide', 'boathouse']\n",
            "['bad', 'dog', 'worry', 'snowball', 'safe']\n",
            "['mom', 'santa_little', 'helper', 'learn', 'obedience', 'school']\n",
            "['father', 'mcgrath', 'think', 'dead']\n",
            "['way', 'dog', 'relieve', 'like', 'faithful', 'friend', 'partner', 'life', 'like', 'hose', 'fireman', 'way', 'think', 'mr_simpson']\n",
            "['like', 'hose', 'wrinkle', 'highness']\n",
            "['change', 'mind', 'decide', 'want', 'shoe']\n",
            "['hey', 'wait_minute', 'happen']\n",
            "['faithful', 'dog', 'bring', 'shoe', 'fall', 'apart', 'mouth']\n",
            "['sorry', 'sir', 'warranty', 'cover', 'fire', 'theft', 'act', 'dog']\n",
            "['like', 'free', 'sample']\n",
            "['mmmm', 'macamadamia', 'nuts']\n",
            "['like', 'buy', 'dollar']\n",
            "['oh', 'little', 'plan', 'addict', 'jack', 'price', 'win']\n",
            "['property', 'hom', 'er', 'j', 'simp', 'son', 'hand']\n",
            "['look', 'mom', 'finish', 'patch', 'depict', 'great', 'musical', 'influence', 'life']\n",
            "['miss', 'winthrop', 'think']\n",
            "['left', 'mr', 'largo', 'music', 'teacher', 'school', 'teach', 'noblest', 'concerto', 'drain', 'beauty', 'soul', 'right', 'bleed', 'gum', 'murphy', 'teach', 'music', 'like', 'fire', 'belly', 'come', 'mouth', 'better', 'stick', 'instrument']\n",
            "['come', 'homer', 'want', 'sick', 'little_girl']\n",
            "['quilt', 'generation', 'go']\n",
            "['marge', 'honey', 'honey', 'honey', 'come', 'come', 'upset', 'end', 'world', 'love', 'quilt', 'attach']\n",
            "['everybody', 'kitchen', 'have', 'family', 'meeting']\n",
            "['problem', 'family', 'member', 'away']\n",
            "['way', 'dog', 'away', 'set', 'fire', 'hair', 'rip', 'clothe', 'sugar', 'gas', 'tank']\n",
            "['suffer', 'paw', 'dog', 'look', 'vacant', 'brown', 'eye', 'bear', 'let', 'sure', 'mom', 'agree']\n",
            "['afraid', 'agree', 'father']\n",
            "['homer', 'quilt', 'nice', 'dog', 'chew', 'obey', 'housebroken', 'spend', 'money', 'obedience', 'school', 'improvement']\n",
            "['right', 'right', 'santa_little', 'helper', 'study', 'real', 'hard', 'pass', 'final', 'perfect', 'dog']\n",
            "['tch', 'tch', 'oh', 'dear']\n",
            "['pay', 'way', 'big_deal', 'let', 'dog', 'pass']\n",
            "['dad', 'pet', 'question', 'integrity', 'disposition', 'question', 'heart', 'try', 'teach', 'way', 'solve', 'problem', 'love', 'throw', 'away']\n",
            "['oh', 'lisa', 'go', 'pull', 'plug', 'want', 'corner', 'honey']\n",
            "['oh', 'right', 'pass', 'obedience', 'school']\n",
            "['boy', 'hard', 'roll', 'roll', 'like']\n",
            "['congratulation', 'sonny', 'earn', 'toffee']\n",
            "['oh', 'thank', 'moldy', 'old', 'maid']\n",
            "['homer', 'place', 'ad', 'dog', 'fail', 'test']\n",
            "['commit', 'free', 'love', 'home', 'world', 'brilliant', 'dog', 'say', \"'\", 'love', \"'\", 'command']\n",
            "['sit', 'say', 'sit']\n",
            "['sniff', 'dog', 'butt', 'exactly', 'tell']\n",
            "['oh', 'away', 'move', 'country', 'dog', 'forbid', 'hear', 'oh', 'sure', \"c'mere\", 'boy', 'prowler', 'come', 'come', 'boy', 'boy', 'love', 'nice', 'man', 'lub', 'good', 'dog', 'good', 'doggie', 'amazing', 'soon', 'woooo', 'wooo']\n",
            "['lot', 'think', 'dog', 'master', 'stay', 'command', 'let', 'stay', 'away', 'beef', 'wellington']\n",
            "['stay', 'boy', 'stay', 'stay', 'stayyy']\n",
            "['oh', 'happy', 'farm', 'know', 'people', 'think', 'mule', 'pull', 'cart', 'impatient', 'people', 'think', 'patient', 'people', 'know', 'better']\n",
            "['uh', 'pick', 'tomorrow']\n",
            "['rubber', 'stamp', 'thank', 'line']\n",
            "['heaven', 'mergatroid', 'bart', 'cling', 'old', 'way', 'like', 'chew', 'shoe', 'tradition', 'wean', 'sleep', 'neuter', 'time', 'pass', 'world', 'need', 'college', 'graduate', 'know', 'sit']\n",
            "['sit', 'sit', 'come', 'boy', 'sit', 'sit']\n",
            "['want', 'strangle', 'dog']\n",
            "['pull', 'bloody', 'chain', 'boy']\n",
            "['sorry', 'boy', 'help', 'dumb']\n",
            "['sew', 'new', 'quilt', 'know', 'thing', 'link', 'chain', 'start']\n",
            "['patch', 'commemorate', 'destruction', 'old', 'quilt']\n",
            "['certainly', 'capture', 'moment', 'hmmm']\n",
            "['come', 'boy', 'sit', 'sit', 'sit', 'sit', 'oh', 'man']\n",
            "['bart', 'go_to', 'learn', 'spend', 'hour', 'torment', 'poor', 'creature', 'fun', 'frolic', 'boy']\n",
            "['go_to', 'miss', 'boy']\n",
            "['think', 'go_to', 'pal', 'forever', 'go_to', 'goodbye', 'understand', 'single', 'word', 'know', 'important', 'learn', 'sit']\n",
            "['shake', 'hand', 'stay']\n",
            "['right', 'good', 'boy', 'roll']\n",
            "['son', 'bitch', 'good']\n",
            "['dad', 'time', 'fun']\n",
            "['come', 'papa', 'come', 'papa']\n",
            "['oh', 'fun', 'today', 'trip', 'liquor', 'store', 'thank', 'beef', 'jerky']\n",
            "['know', 'grampa', 'kinda', 'smell_like', 'trunk', 'garage', 'wet']\n",
            "['huh', 'uh', 'smell_like', 'photo', 'lab']\n",
            "['stop', 'grampa', 'smell_like', 'regular', 'old_man', 'like', 'hallway', 'hospital']\n",
            "['homer', 'terrible', 'teach', 'child', 'treasure', 'elderly', 'know', 'old', 'someday']\n",
            "['god', 'right', 'marge', 'kid', 'home', 'like', 'dad']\n",
            "['think', 'better', 'set', 'example']\n",
            "['absolutely', 'sunday', 'month', 'pleasure', 'chore', 'place', 'fun', 'grampa', 'time']\n",
            "['enjoy', 'glass', 'blower', 'old', 'springfield', 'towne']\n",
            "['get', 'springfield', 'mystery', 'spot']\n",
            "['dad', 'dumb', 'mud', 'puddle']\n",
            "['discount', 'lion', 'safari']\n",
            "['like', 'go', 'wreck', 'dollar', 'worth', 'tooth', 'cent', 'worth', 'old', 'beef']\n",
            "['mr', 'simmon', 'nurse', 'bronski']\n",
            "['simpson', 'dammit', 'pill']\n",
            "['excuse', 'nurse', 'simmons', 'think', 'wrong', 'pill']\n",
            "['red', 'one', 'spasm', 'yellow', 'arrythmia', 'blue', 'est', 'eye', 'see', 'life']\n",
            "['look', 'starin', \"'\", 'like', 'couple', 'stupid', 'punk', 'teenager']\n",
            "['abraham', 'j', 'simpson', 'care', 'tip', 'wrist']\n",
            "['eh', 'widower', 'son', 'work', 'kidney']\n",
            "['widow', 'bad', 'hip', 'liver', 'disorder']\n",
            "['oh', 'get', 'plan']\n",
            "['oh', 'abe', 'go']\n",
            "['wonder', 'know', 'place', 'time', 'geez', 'think', 'easy', 'time']\n",
            "['ah', 'damn', 'pomade', 'oh']\n",
            "['ooh', 'hello', 'young_lady', 'grandmother', 'home']\n",
            "['oh', 'oh', 'oh', 'abe', 'tell', 'better', 'good', 'eye']\n",
            "['embrace', 'sweet', 'embraceable']\n",
            "['herman', 'special', 'lady', 'have', 'birthday', 'tomorrow']\n",
            "['ah', 'battleship', 'new', 'jersey']\n",
            "['idiot', 'girlfriend', 'bea', 'store', 'know']\n",
            "['ah', 'grampa', 'say', 'love', 'better', 'military', 'antique']\n",
            "['let', 'look', 'bayonet', 'case', 'huh']\n",
            "['friend', 'napoleon', 'hat']\n",
            "['look', 'like', 'napoleon', 'hat']\n",
            "['famous', 'hat', 'wear', 'week', 'april', 'defeat', 'sardinian']\n",
            "['kind', 'offer', 'man', 'gattle', 'gun', 'counter', 'try', 'grandma', 'world']\n",
            "['yo', 'active', 'wear', 'need', 'price', 'check', 'wool', 'shawl']\n",
            "['dad', 'sunday', 'month', 'know', 'mean']\n",
            "['oh', 'come', 'dad', 'promise', 'fun', 'time', 'go_to', 'lion']\n",
            "['girlfriend', 'bea', 'birthday']\n",
            "['oh', 'girlfriend', 'heh_heh', 'heh']\n",
            "['happy_birthday', 'bea', 'come', 'hey', 'room', 'friend', 'car']\n",
            "['invisible', 'idiot', 'birthday', 'tonight']\n",
            "['hey', 'kid', 'stop', 'kick', 'seat']\n",
            "['dad', 'want', 'know', 'go']\n",
            "['damn', 'childproof', 'door']\n",
            "['feed', 'animal', 'allow', 'animal', 'car', 'eye', 'contact', 'animal']\n",
            "['hey', 'anybody', 'notice', 'place', 'suck']\n",
            "['let', '-PRON-', 'sleep', 'time']\n",
            "['homer', 'sure', 'right', 'way', 'road', 'get', 'awfully', 'bumpy']\n",
            "['wing', 'de', 'well', 'girlfriend', 'birthday', 'party']\n",
            "['yeah', 'bart', 'push']\n",
            "['okay', 'see', 'lion']\n",
            "['mr_simpson', 'presume']\n",
            "['way', 'get_to', 'date', 'angel']\n",
            "['know', 'right', 'abe']\n",
            "['sorry', 'tell', 'bea', 'pass', 'away', 'night']\n",
            "['ticker', 'doc', 'say', 'left', 'ventricle', 'burst']\n",
            "['ohhh', 'jasper', 'die', 'burst', 'ventricle', 'know', 'die', 'broken', 'heart']\n",
            "['tell', 'care', 'pall', 'bearer']\n",
            "['tell', 'sorry', 'dad']\n",
            "['oh', 'dad', 'lose', 'hearing']\n",
            "['idiot', 'ignore', 'miss', 'precious', 'moment', 'bea', 'life', 'speak']\n",
            "['beautiful', 'service', 'mr_simpson']\n",
            "['lionel', 'hutz', 'attorney', 'law', 'executor', 'beatrice', 'simmons', \"'\", 'estate', 'mr_simpson', 'bea', 'wealthy', 'woman', 'surprise', 'surprise', 'leave']\n",
            "['catch', 'spend', 'night', 'haunted', 'house']\n",
            "['kid', 'kid', 'check', 'thousand_dollar', 'enjoy', 'fit', 'ah', 'touch']\n",
            "['ta', 'ta', 'mr_simpson', 'way', 'old', 'timer', 'will', 'pen', 'phone', 'number', 'look', 'like', 'cigar']\n",
            "['whoo', 'hoo', 'dad', 'dad', 'phone', 'call']\n",
            "['oh', 'dad', 'oh', 'know', 'forgive']\n",
            "['forgive', 'inherit', 'thousand_dollar', 'tell', 'get', 'thin', 'dime', 'heh_heh']\n",
            "['help', 'overhear', 'new', 'find', 'fortune', 'uh', 'let', 'assure', 'springfield', 'retirement', 'castle', 'money', 'difference']\n",
            "['mean', 'rub', 'down', 'rub', 'down']\n",
            "['listen', 'bloodsucker', 'occur', 'old', 'folk', 'deserve', 'treat', 'like', 'human', 'being', 'money']\n",
            "['oh', 'lousy', 'son']\n",
            "['hey', 'big', 'spender', 'change', 'heart']\n",
            "['bea', 'tell', 'enjoy', 'moola', 'go', 'dagnabit']\n",
            "['boss', 'stop', 'funsville']\n",
            "['oh', 'abraham', 'calm', 'scare', 'get', 'haunt', 'family', 'texas']\n",
            "['oh', 'glad', 'keepin', \"'\", 'busy']\n",
            "['listen', 'abe', 'want', 'know', 'money', 'bring', 'happiness']\n",
            "['oh', 'bea', 'cut', 'high', 'life']\n",
            "['abraham', 'happy', 'money', 'spread', 'people', 'happy']\n",
            "['oh', 'thanks', 'bea']\n",
            "['aw', 'miss', 'big', 'fat', 'dicken', 'hey', 'bea', 'get', 'ask', 'death', 'like']\n",
            "['homer', 'thing', 'dad', 'mope', 'house', 'day', 'think', 'time', 'talk', 'understand']\n",
            "['hi', 'ya', 'reach', 'dr', 'marvin', 'monroe', 'anxiety', 'line', 'sullen', 'teenager', 'press', 'estranged', 'spouse', 'press', 'trouble', 'maintain']\n",
            "['room', 'table', 'foolish', 'old_man']\n",
            "['sure', 'chair', 'den', 'problem', 'bart']\n",
            "['choose', 'corncob', 'en', 'garde']\n",
            "['precious', 'sack', 'gold']\n",
            "['buy', 'pleasure', 'simple', 'family', 'meal']\n",
            "['pass', 'bug', 'juice', 'dad']\n",
            "['wait', 'turn', 'pig', 'announcement', 'decide', 'bea', 'money', 'away', 'people', 'need', 'go_to', 'let', 'come', 'plead', 'case', 'decide', 'need']\n",
            "['grampa', 'noble', 'thought', 'express', 'table']\n",
            "['bart', 'forgive', 'dad', 'stupid', 'little', 'kid', 'say', 'thing', 'pop', 'head', 'know', 'wisdom', 'innocence']\n",
            "['bad', 'be', 'get']\n",
            "['reporter', 'marriage', 'stephanie', 'weather', 'lady', 'town', 'consume', 'rumor', 'innuendo', 'man']\n",
            "['today', 'abraham', 'grampa', 'simpson', 'announce', 'away', 'thousand_dollar', 'person', 'person', 'find', 'deserving']\n",
            "['grampa', 'simpson', 'modern', 'day', 'saint', 'rich', 'nut', 'time', 'tell']\n",
            "['kent_brockman', 'line', 'old_man', 'money']\n",
            "['gramp', 'want', 'customize', 'bus', \"y'know\", 'chop', 'jack', 'mag', 'wheel', 'psychedelic', 'paint', 'job', 'hell', 'man', 'jam', 'kid', 'school', 'mile', 'hour', 'artist', 'rendering', 'note', 'cobra', 'wrap', 'naked', 'chick']\n",
            "['yeah', 'yeah', 'ahead']\n",
            "['wait_wait', 'minute', 'wait', 'guy', 'own', 'nuclear_power', 'plant']\n",
            "['mr_simpson', 'dread', 'day', 'thousand_dollar', 'worth', 'grovel']\n",
            "['powerful', 'enemy', 'old_man']\n",
            "['deal', 'grampa', 'guy', 'think', 'explorer', 'leave', 'bar', 'night', 'map', 'ancient', 'treasure', 'direction', 'guy', 'house', 'find', 'need', 'money', 'need', 'provision', 'man', 'diving', 'bell']\n",
            "['pretty', 'stupid', 'far', 'runner']\n",
            "['special', 'isolation', 'chamber', 'subject', 'pull', 'lever', 'receive', 'food', 'warmth', 'floor', 'electrify', 'shower', 'icy', 'water', 'randomly', 'fall', 'subject', 'monroe', 'box']\n",
            "['huh', 'uh', 'sound', 'interesting']\n",
            "['oh', 'beauty', 'build', 'need', 'money', 'buy', 'baby', 'raise', 'box', 'age', 'thirty']\n",
            "['theory', 'subject', 'socially', 'maladjuste', 'harbor', 'deep', 'resentment']\n",
            "['let', 'want', 'teargas', 'blue', 'gun', 'paralyzer', 'dart']\n",
            "['copy', 'radioactive_man', 'number', 'time', 'fight', 'dr', 'crab', 'wanna', 'buy', 'baseball', 'card', 'guy', 'flippin', \"'\", 'bird']\n",
            "['oh', 'yeah', 'see']\n",
            "['death', 'ray', 'good', 'man', 'behold']\n",
            "['hey', 'feel', 'warm', 'kinda', 'nice']\n",
            "['prototype', 'proper', 'funding', 'confident', 'little', 'baby', 'destroy', 'area', 'size', 'new_york', 'city']\n",
            "['want', 'help', 'people', 'kill', '-PRON-']\n",
            "['oh', 'honest', 'ray', 'evil', 'application']\n",
            "['know', 'wife', 'happy', 'hate', 'death', 'ray', 'thing', 'day']\n",
            "['oh', 'lisa', 'make', 'think', 'deserve', 'money']\n",
            "['deserve', 'grampa', 'people', 'deserve', 'street', 'slum', 'little', 'child', 'need', 'library', 'book', 'family', 'end', 'meet', 'course', 'want', 'buy', 'pony']\n",
            "['princess', 'ride', 'day']\n",
            "['right', 'poor', 'soul', 'need', 'help', 'hand', 'need', 'walk', 'clear', 'head']\n",
            "['oh', 'poor', 'baby', 'lift', 'wallet']\n",
            "['know', 'decide', 'money', 'away', 'truly', 'needy', 'cause', 'thousand_dollar', 'need']\n",
            "['senior', 'gamble', 'junket', 'bet', 'double', 'money', 'triple']\n",
            "['plus', 'get', 'ninety', 'cent', 'shrimp', 'cocktail']\n",
            "['slow', 'try_kill']\n",
            "['hot', 'maniac', 'turn', 'air']\n",
            "['hey', 'mellow', 'old', 'dude', 'jam', 'baby', 'river']\n",
            "['miss', 'look', 'abe', 'simpson']\n",
            "['important', 'hold', 'tell', 'care', 'money', 'love']\n",
            "['leave', 'morning', 'senior', 'casino', 'junket']\n",
            "['hello', 'plato', 'partake', 'keno', 'craps', 'loose', 'slot', 'town', 'philosophy', 'enjoy']\n",
            "['double', 'cheese', 'burger', 'onion', 'ring', 'large', 'strawberry', 'shake', 'god', 'sake', 'hurry']\n",
            "['thousand_dollar', 'hmmmm', 'hmmm', 'let', 'century']\n",
            "['excuse', 'excuse', 'see', 'old_man', 'lot', 'money', 'look', 'like', 'wrinkle', 'hello', 'see']\n",
            "['holy', 'moly', 'win']\n",
            "['beat', 'boy', 'crampin', \"'\", 'style']\n",
            "['dad', 'get_to', 'quit', 'ahead', 'understand', 'money', 'leave']\n",
            "['sorry', 'boy', 'help', 'everybody']\n",
            "['homer', 'think', 'rudyard', 'kipling', 'say', 'best', 'heap', 'winning', 'risk', 'turn', 'pitch', 'toss', 'lose', 'start', 'beginning', 'breathe', 'word', 'loss', 'earth', 'man', 'son']\n",
            "['get', 'feeling', 'number']\n",
            "['wheel', 'go', 'thirty', 'sir']\n",
            "['okay', 'thirty', 'get', 'feeling', 'number']\n",
            "['clammy', 'paw', 'money']\n",
            "['gimme', 'money', 'ow', 'hurt']\n",
            "['son', 'land', 'thirty']\n",
            "['son', 'save', 'lose', 'money', 'time', 'life', 'glad', 'child']\n",
            "['figure', 'get', 'money']\n",
            "['come', 'dignity', 'friend']\n",
            "['live', 'mt', 'splashmore', 'tri', 'county', 'area', 'funnest', 'water', 'recreation', 'facility', 'krusty_clown']\n",
            "['know', 'today', 'day', 'special', 'week', 'location', 'fabulous', 'mt', 'splashmore', 'want', 'people', 'super', 'sideshow', 'mel']\n",
            "['food', 'grog', 'oh', 'throw', 'brunch', 'yesterday', 'fresh', 'fruit', 'delicious', 'melon', 'want', 'course', 'thing', 'go_to', 'miss', 'special', 'special', 'mount', 'splashmore', 'water', 'slide', 'god_bless', '-PRON-', 'fun', 'memory', 'excuse', 'minute']\n",
            "['great', 'week', 'lis']\n",
            "['hope', 'kid', 'come', 'weekend', 'pack', 'place', '-PRON-', 'grateful', 'tell', 'liar']\n",
            "['okay', 'kid', 'time']\n",
            "['want', 'mt', 'splashmore', 'mt', 'splashmore', 'right']\n",
            "['shut', 'quit', 'bug']\n",
            "[\"c'mon\", 'homer', 'lead']\n",
            "['homer', 'suit', 'leave', 'imagination']\n",
            "['head', 'kid', 'move', 'seat']\n",
            "['right', 'everybody', 'stick', 'want', 'separate']\n",
            "['challenge', 'rage', 'water', 'death', 'dare', 'discover', 'water', 'h', 'whoooooaaaa']\n",
            "['okay', 'lis', 'turn', 'waterworks', 'babe']\n",
            "['mommy', 'want', 'mommy']\n",
            "['step', 'aside', 'come', 'spread', 'spread', 'lose', 'kid', \"comin_'\", 'look', 'fatso', \"comin_'\", \"comin_'\", 'pardon', 'movin', \"'\", 'line', 'hey', 'lis', 'nice', 'work', 'babe']\n",
            "['maggie', 'stay', 'shallow', 'end']\n",
            "['slide', 'inspector', \"comin_'\", 'right', 'grab', 'handrail', 'young_man', 'outta', 'way', 'safety']\n",
            "['god_bless', 'man']\n",
            "['oh', 'urg', 'arrrgh', \"c'mon\", 'stupid', 'tube']\n",
            "['look', 'like', 'jam', 'delta', 'sector']\n",
            "['big', 'human', 'send', 'kid', 'dislodge']\n",
            "['eyewitness', 'estimate', 'man', 'weight', 'pound']\n",
            "['light', 'news', 'use', 'term', 'loosely']\n",
            "['slide', 'perfectly', 'safe', 'isolate', 'incident']\n",
            "['understand', 'krusty', 'exactly', 'say', 'right', 'recall', 'taint', 'krusty', 'brand', 'mayonnaise']\n",
            "['kent', 'know', 'question', 'bound', 'interview']\n",
            "['right', 'family', 'want', 'truth', 'pull', 'punch', 'little_bit', 'overweight']\n",
            "['forgive', 'dad', 'take', 'time', 'properly', 'sugarcoat', 'response']\n",
            "['thirty', 'seven', 'oh_god', 'hey', 'oh_god', 'pound', 'big', 'fat', 'pig']\n",
            "['homer', 'big', 'bone']\n",
            "['marge', 'gain', 'thirty', 'pound', 'bone']\n",
            "['go', 'diet', 'day', 'forward', 'pledge', 'pork_chop', 'succulent', 'donut', 'tasty', 'pizza', 'laden', 'delicious', 'topping', 'prevent', 'reach', 'scientifically', 'determine', 'ideal', 'weight', 'god', 'witness', 'hungry']\n",
            "['old', 'attic', 'kinda', 'spooky', 'boy', 'say', 'boy']\n",
            "['away', 'thing', 'help', 'find', 'athletic', 'equipment']\n",
            "['hey', 'homer', 'find', 'weight']\n",
            "['ooh', 'glutimus', 'maximizer']\n",
            "['hey', 'moptop', 'big', 'schnozz']\n",
            "['know', 'boy', 'ringo', 'starr']\n",
            "['mother', 'paint', 'guess', 'think', 'cute', 'hey']\n",
            "['oh', 'homer', 'jealous', 'schoolgirl', 'beatle', 'popular', 'crush']\n",
            "['oh', 'start', 'diet', 'pork_chop', 'night']\n",
            "['homer', 'get', 'steam', 'vegetable', 'rice', 'cake']\n",
            "['wait_minute', 'hey', 'set', 'drink', 'thing']\n",
            "['thirty', 'calorie', 'apiece']\n",
            "['hello', 'hello', 'hello', 'taste']\n",
            "['hey', 'hey', \"talkin_'\"]\n",
            "['mom', 'good', 'know', 'hand', 'fragile', 'young', 'talent', 'love', 'hear', 'particular', 'gift', 'squash']\n",
            "['portrait', 'bongo', 'beating', 'liverpudlian']\n",
            "['canvas', 'create', 'masterpiece', 'instead', 'soil', 'forever']\n",
            "['thank', 'mr', 'schindler']\n",
            "['oh', 'mom', 'believe', 'give', 'painting', 'small', 'minded', 'art', 'teacher']\n",
            "['upset', 'decide', 'send', 'portrait', 'man', 'earth', 'opinion', 'truly', 'trust']\n",
            "['maybe', 'class', 'springfield', 'community', 'college']\n",
            "['think', 'nice', 'idea', 'homer']\n",
            "['great', 'fine', 'nuts']\n",
            "['mmm', 'thirty', 'calorie']\n",
            "['enrol', 'screenwriting', 'class', 'yearn', 'tell', 'story', 'idealistic', 'young', 'hindu', 'push', 'far', 'convenience', 'store', 'bandit', 'hand', 'jerky', 'turkey']\n",
            "['oh', 'thank', 'actually', 'brother', 'sanjay', 'thought']\n",
            "['mother', 'like', 'enroll', 'painting', 'life', 'b']\n",
            "['whoa_whoa', 'whoa_whoa', 'fast', 'pint', 'size', 'afraid', 'enroll', 'professor', 'lombardo', 'personally', 'inspect', 'approve', 'portfolio']\n",
            "['oh', 'lisa', 'bad', 'idea']\n",
            "['good', 'fabulous', 'ooh', 'better', 'real', 'talent']\n",
            "['think', 'high_school', 'art', 'teacher', 'hate']\n",
            "['man', 'fool', 'admire', 'force', 'conviction']\n",
            "['oh', 'dear', 'class', 'excuse', 'nature', 'call']\n",
            "['heavy', 'hand', 'work', 'homer']\n",
            "['lombardo', 'method', 'learn', 'everyday', 'object', 'simple', 'grouping', 'geometrical', 'shape']\n",
            "['smither', 'find', 'artist']\n",
            "['concentric', 'circle', 'trapezoid', 'ellipsis', 'yes', 'rhombus', 'create', 'adorable', 'little', 'bunny', 'rabbit']\n",
            "['lincoln', 'lincoln', 'thinkin', \"'\", 'hell', 'drinkin', \"'\", 'water', 'wine', 'oh_god', 'turpentine', 'faster', 'faster']\n",
            "['bravo', 'walk', 'away', 'belong', 'age', 'stroke', 'oh', 'maybe', 'perfect']\n",
            "['mmmm', 'marge', 'find', 'inner', 'beauty', 'subject', 'bring']\n",
            "['thank', 'professor', 'lombardo']\n",
            "['welcome', 'dear', 'marge', 'walk']\n",
            "['marge', 'ask', 'submit', 'good', 'painting', 'class', 'springfield', 'art', 'exhibition', 'week', 'decide', 'choose', 'bald', 'adonis']\n",
            "['supportive', 'wish', 'teacher', 'like']\n",
            "['woo', 'ooo', 'work', 'art', 'supper', 'eat', 'heart']\n",
            "['garbage', 'matchbook', 'art', 'school', 'flunk', 'ham', 'fiste', 'nearsighted', 'house', 'painter', 'smither', 'throw', 'dung', 'heap']\n",
            "['sorry', 'work', 'quit']\n",
            "['smither', 'guess', 'artistic', 'temperament']\n",
            "['sir', 'remind', 'dedication', 'burn', 'wing', 'museum', 'day', 'away']\n",
            "['damnation', 'smither', 'idea', 'immortalize', 'portrait', 'half', 'bake', 'idea', 'have', 'child']\n",
            "['sir', 'afraid', 'systematically', 'alienate', 'springfield', 'entire', 'art', 'community', 'left', 'mrs', 'homer_simpson']\n",
            "['win', 'prize', 'springfield', 'art', 'fair', 'wife', 'employee', 'easily', 'intimidate']\n",
            "['excellent', 'wheel', 'turn', 'dame', 'fortune', 'hug', 'montgomery_burn', 'sweet', 'perfumed', 'bosom', 'somebody', 'like', 'smither']\n",
            "['somebody', 'like', 'sir']\n",
            "['woo', 'woo', 'yeah']\n",
            "['marge', 'marge', 'look', 'clothe', 'hang']\n",
            "['oh', 'wonderful', 'kid']\n",
            "['pass', 'moo', 'juice']\n",
            "['kid', 'remember', 'tell', 'show', 'little', 'support']\n",
            "['hey', 'give', 'donut', 'pilin', \"'\"]\n",
            "['yeah', 'homer_simpson', 'go', 'diet']\n",
            "['oh_god', 'buy', 'boat']\n",
            "['people', 'answer', 'door', 'day']\n",
            "['mr_burns', 'like', 'come']\n",
            "['mr_burns', 'like', 'commission', 'portrait', 'paint', 'rich', 'powerful']\n",
            "['drummer', 'rock', \"'_n\", 'roll', 'combo', 'call', 'beatles', 'sir']\n",
            "['beatle', 'eh', 'oh', 'yes', 'remember', 'key', 'caterwauling', 'old', 'sullivan', 'think', 'mrs_simpson', 'commission', 'glory', 'look', 'straight', 'eye', 'answer', 'simple', 'question']\n",
            "['maybe', 'gift', 'able', 'inner', 'beauty']\n",
            "['hmmm', 'mrs_simpson', 'immortalize']\n",
            "['ah', 'sir', 'world']\n",
            "['yes_yes', 'yes', 'stingy', 'blush', 'smither']\n",
            "['oh', 'original', 'sentiment']\n",
            "['outside', 'simpson', 'male', 'modeling']\n",
            "['paint', 'portrait', 'homer']\n",
            "['oh', 'wonderful', 'work', 'home', 'life', 'come', 'nice', 'way', 'marge', 'room']\n",
            "['honey', 'nuts', 'think', 'handsome', 'look', 'handsome']\n",
            "['homer', 'worry', 'need', 'find', 'mr_burns', \"'\", 'inner', 'beauty']\n",
            "['like', 'boy', 'mr_burns', 'dog', 'love']\n",
            "['mr_burns', 'baby']\n",
            "['right', 'right', 'take', 'funny', 'page']\n",
            "['ziggy', 'go', 'repair', 'shop', 'sign', 'doorbell', 'read', 'order']\n",
            "['ah', 'ziggy', 'win']\n",
            "['excuse', 'change', 'board', 'meeting']\n",
            "['sorry', 'mr_burns']\n",
            "['hey', 'mom', 'spot', 'body']\n",
            "['feel', 'comfortable', 'leave', 'sir']\n",
            "['course', 'smither', 'like', 'doctor']\n",
            "['smither', 'want', 'tea']\n",
            "['bother', 'order', 'like']\n",
            "['actually', 'value', 'second', 'moment', 'squeeze', 'orange', 'juice', 'morning', 'till', 'tuck', 'night', 'boss', 'good_friend']\n",
            "['right', 'sir', 'scald', 'speak']\n",
            "['dear', 'sally', 'response', 'letter', 'december', 'twelfth', 'favorite', 'color', 'blue', 'real', 'richard', 'thank', 'snapshot', 'real', 'cute', 'bird', 'luv', 'ringo', 'p', 's', 'forgive', 'lateness', 'reply']\n",
            "['mr', 'starr', 'tea', 'crumpet']\n",
            "['sir', 'forgive', 'old', 'brit', 'impertinence', 'devotion', 'fan', 'short', 'remarkable']\n",
            "['wetherby', 'take', 'time', 'write', 'care', 'take', 'year', 'go', 'answer']\n",
            "['springfield', 'u_s']\n",
            "['cease', 'infernal', 'tootling']\n",
            "['mr_burns', 'hard', 'discover', 'inner', 'beauty', 'shout', 'year_old', 'girl']\n",
            "['get', 'day', 'leave', 'advise', 'shut', 'paint']\n",
            "['right', 'scale', 'like', 'like', 'good', 'better', 'treat', 'right']\n",
            "['right', 'woo', 'woo', 'woo', 'woo']\n",
            "['marge', 'thirty', 'feel', 'fine', 'look', 'original', 'notch', 'come', 'belt']\n",
            "['wonderful', 'homer', 'proud']\n",
            "['let', 'straight', 'pleased', 'current', 'appearance', 'ah', 'good', 'man', 'fat', 'thing', 'see', 'safari']\n",
            "['mr_burns', 'posing', 'finish', 'portrait']\n",
            "['thank', 'goodness', 'day', 'suburban', 'nightmare', 'need', 'half', 'white', 'valium', 'thank', 'gracious', 'hospitality', 'unveiling']\n",
            "['burns', 'right', 'use']\n",
            "['listen', 'mean', 'little', 's', 'o', 'b']\n",
            "['think', 'good', 'everybody', 'meet']\n",
            "['yeah', 'long', 'paint', 'nice', 'picture', 'noon', 'tomorrow']\n",
            "['man', 'beautiful', 'good', 'guess', 'artist']\n",
            "['marge', 'merry', 'old', 'england']\n",
            "['desk', 'ringo', 'starr']\n",
            "['dear', 'marge', 'thank', 'fab', 'painting', 'truly', 'hang', 'wall', 'artist', 'answer', 'question', 'yes', 'hamburger', 'fry', 'england', 'french', 'fry', 'chips', 'luv', 'ringo', 'p', 's', 'forgive', 'lateness', 'reply']\n",
            "['come', 'marge', 'paint', 'think']\n",
            "['okay', 'homer', 'think']\n",
            "['friend', 'art', 'lover', 'security', 'personnel', 'today', 'red', 'letter', 'day', 'springfield', 'palace', 'fine', 'art', 'new', 'wing', 'museum', 'portrait', 'commemorate', 'man', 'ponie', 'dough']\n",
            "['lady_gentleman', 'invite', 'behold', 'montgomery_burn']\n",
            "['mrs_krabappel', 'traumatize', 'child']\n",
            "['asbestos', 'asbestos', 'asbestos', 'asbestos']\n",
            "['umm', 'hello', 'marge', 'simpson', 'paint', 'maybe', 'like', 'know', 'possess', 'guess', 'want', 'beneath', 'mr_burns', \"'\", 'fearsome', 'head', 'cruel', 'lip', 'spiteful', 'tongue', 'evil', 'brain', 'frail', 'wither', 'body', 'long', 'world', 'vulnerable', 'beautiful', 'god', 'creature']\n",
            "['bad', 'die', 'like']\n",
            "['know', 'art', 'critic', 'know', 'hate', 'hate', 'painting', 'bold', 'beautiful', 'uh', 'incidentally', 'thank', 'make', 'fun', 'genitalia']\n",
            "['hear', 'miss_hoover', 'drink', 'bottle', 'drain', 'cleaner', 'mistake']\n",
            "['uh', 'hear', 'fall']\n",
            "['child', 'will', 'stay', 'long', 'come', 'doctor', 'lyme', 'disease', 'principal_skinner', 'run', 'class', 'substitute', 'arrive']\n",
            "['uh', 'field', 'lyme', 'disease', 'spread', 'small', 'parasite', 'call', 'tick', 'disease', 'tick', 'attach', 'begin', 'suck', 'blood']\n",
            "['malignant', 'spirochete', 'infest', 'bloodstream', 'eventually', 'spread', 'spinal', 'fluid', 'brain']\n",
            "['brain', 'oh', 'dear', 'god']\n",
            "['come', 'elizabeth', 'come', 'come']\n",
            "['child', 'open', 'primer', 'page']\n",
            "['bart_simpson', 'know']\n",
            "['come', 'snowball', 'ii', 'keep']\n",
            "['go', 'gray', 'mother', 'eat']\n",
            "['usual', 'agree', 'martin', 'bart', 'shut', 'seat', 'immediately']\n",
            "['oh', 'look', 'cool', 'hit', 'reverse']\n",
            "['child', 'see', 'thing', 'little', 'friend', 'schwa']\n",
            "['yes', 'sir', 'yes']\n",
            "['sir', 'way', 'get', 'attention']\n",
            "['right', 'play', 'friendly', 'new', 'teacher', 'child']\n",
            "['howdy', 'texas', 'cowboy', 'year', \"young'uns\", 'ask', 'question', 'like']\n",
            "['play', 'kickball', 'instead', 'science', 'lunch']\n",
            "['kickball', 'son', 'be', 'kickball', 'question']\n",
            "['shoot', 'awfully', 'quiet', 'plain', 'everybody', 'want', 'eye', 'single', 'person', 'stare', 'right', 'right', 'thing', 'wrong', 'costume', 'anybody', 'name', 'thing', 'hat']\n",
            "['believe', 'know', 'answer']\n",
            "['ahead', 'miss', 'simpson']\n",
            "['um', 'belt', 'buckle', 'say', 'state', 'texas', 'texas', 'state']\n",
            "['speech', 'ready', 'dog', 'eat']\n",
            "['good', 'excellent', 'wear', 'digital', 'watch', 'accept', 'little', 'lady', 'record', 'jewish', 'cowboy', 'lady_gentleman', 'big', 'guy', 'great', 'shot', 'spend', 'money', 'freely', 'mr', 'bergstrom', 'feel', 'free', 'fun', 'want', 'suggestion', 'mister', 'nerdstrom', 'mister', 'boogerstrom']\n",
            "['boy', 'girl', 'today', 'begin', 'select', 'class', 'president']\n",
            "['allow', 'vote', 'strongly', 'suggest', 'elect', 'martin', 'martin']\n",
            "['president', 'demand', 'science', 'fiction', 'library', 'feature', 'b', 'c', 'overlord', 'genre', 'asimov', 'master', 'clarke']\n",
            "['aware', 'work', 'thank', 'watch', 'sky']\n",
            "['excellent', 'excellent', 'martin']\n",
            "['pemmican', 'sing', 'song', 'cowboy', 'accurate', 'fix', 'okay']\n",
            "['home', 'home', 'range', 'actually', 'range', 'far', 'home', 'desolate', 'place', 'danger', 'disease', 'ride', 'tall', 'saddle', 'deer', 'antelope', 'play', 'unlike', 'efficient', 'indians', 'cowboy', 'tongue', 'antelope', 'throw', 'rest', 'away']\n",
            "['seldom', 'hear', 'discouraging', 'word', 'sky', 'cloudy', 'day']\n",
            "['like', 'immature', 'people', 'instead', 'build']\n",
            "['lady_gentleman', 'singing', 'dork']\n",
            "['nominate', 'bart_simpson']\n",
            "['child', 'bart', 'need', 'reliable', 'deliver', 'important', 'message', 'principal', 'office']\n",
            "['mrs_krabappel', 'know', 'principal', 'office']\n",
            "['people', 'tell', 'encourage', 'bart', 'win', 'approval', 'make', 'fool', 'make', 'think']\n",
            "['hundred', 'people', 'visit', 'fair', 'know', 'grey', 'spider', 'play', 'important', 'die']\n",
            "['come', 'janey', 'everybody', 'talent', 'want']\n",
            "['talk', 'like', 'better', 'anybody']\n",
            "['yes', 'great', 'ok', 'ralph']\n",
            "['oh', 'disgusting', 'love', 'lisa', 'come', 'hold', 'saxophone']\n",
            "['come', 'lisa', 'bet', 'good']\n",
            "['right', 'owe', 'special']\n",
            "['technically', 'married', 'marriage', 'speak', 'mister', 'krabappel', 'move', 'little', 'love', 'nest']\n",
            "['profession', 'lot', 'strain', 'marriage']\n",
            "['go', 'look', 'substitute', 'teach', 'lesson', 'sorely', 'need']\n",
            "['mrs_krabappel', 'try', 'seduce']\n",
            "['sorry', 'mrs_krabappel', 'nice', 'child', 'love']\n",
            "['fall_asleep', 'mr', 'bergstrom', 'thing', 'think', 'thought', 'wake']\n",
            "['hmmm', 'feel', 'way', 'father']\n",
            "['understand', 'mr', 'bergstrom', 'smile', 'tooth']\n",
            "['laugh', 'tooth', 'think', 'call', 'eye', 'tooth']\n",
            "['know', 'orthodontic', 'work', 'absolutely', 'perfect']\n",
            "['hmmm', 'notice', 'little', 'thing', 'father']\n",
            "['mom', 'different', 'mean', 'man', 'make', 'feel', 'like', 'better']\n",
            "['mom', 'go_to', 'talk', 'go_to', 'talk']\n",
            "['lisa', 'talk', 'accept', 'fact', 'feel', 'way', 'father']\n",
            "['yesterday', 'read', 'charlotte', 'web', 'cry', 'end', 'try', 'hide', 'tear']\n",
            "['book', 'cry', 'boo', 'hoo', 'hoo']\n",
            "['remember', 'mean', 'get', 'lunch', 'igneous', 'rock', 'volcanic', 'sedimentary', 'layer', 'lisa', 'minute']\n",
            "['yes_yes', 'mr', 'bergstrom']\n",
            "['lisa', 'homework', 'neat', 'father', 'help']\n",
            "['homework', 'father', 'specialty']\n",
            "['shame', 'mean', 'dad']\n",
            "['sample', 'take', 'classroom', 'state', 'inspector', 'find', 'part', 'million', 'asbestos']\n",
            "['demand', 'asbestos', 'asbestos']\n",
            "['aw', 'dad', 'popularity', 'contest']\n",
            "['popularity', 'contest', 'excuse', 'important', 'popularity', 'bart', 'think', 'win']\n",
            "['woo', 'woo', 'right', 'know', 'personality', 'doctor', 'say', 'hyperactivity', 'know', 'well', 'president', 'simpson', 'nice', 'ring', 'boy']\n",
            "['say', 'easy', 'answer', 'look', 'hard']\n",
            "['oh', 'broke', 'appeal', 'low', 'common', 'denominator']\n",
            "['go', 'miss', 'brother', 'antic']\n",
            "['life', 'take', 'place', 'rest', 'hear']\n",
            "['place', 'intelligence', 'asset', 'liability']\n",
            "['yes', 'place', 'believe', 'true']\n",
            "['believe', 'word', 'body', 'language', 'semitic', 'good', 'look']\n",
            "['dear', 'miss_hoover', 'lyme', 'disease', 'miss', 'kevin', 'bite', 'come', 'soon', 'drawing', 'spirochete', 'love', 'ralph']\n",
            "['oh', 'great', 'ralph']\n",
            "['hey', 'kid', 'learn', 'week', 'springfield', 'museum', 'natural', 'history', 'close', 'forever', 'lack', 'interest', 'urge']\n",
            "['hmmm', 'lisa', 'need', 'museum', 'tomorrow', 'think']\n",
            "['homer', 'talk', 'lisa', 'concerned', 'relationship']\n",
            "['mom', 'think', 'drift', 'apart']\n",
            "['marge', 'understand', 'trap', 'smart', 'think', 'right', 'right', 'lousy', 'brain']\n",
            "['hey', 'mean', 'suggest', 'donation']\n",
            "['pay', 'wish', 'sir']\n",
            "['wish', 'pay', 'zero']\n",
            "['think', 'people', 'go_to', 'pay', 'dollar', 'cent', 'goodness', 'good_luck', 'lady', 'go_to', 'need']\n",
            "['hey', 'pay', 'read', 'sign']\n",
            "['tooth', 'jag', 'edge', 'rip', 'body', 'swallow']\n",
            "['actually', 'mr_simpson', 'know', 'great', 'deal', 'process', 'mummification', 'pull', 'brain', 'nose', 'iron', 'hook', 'stuff', 'inside', 'sawdust', 'onion']\n",
            "['ohh', 'pretty', 'creepy', 'chase', 'wolf', 'man']\n",
            "['mr_simpson', 'go_to', 'presumptuous', 'notice', 'lisa', 'feel', 'strong', 'male', 'role', 'model']\n",
            "['tell', 'right', 'look', 'see', 'everybody', 'dad', 'good', 'education', 'youthful', 'look', 'clean', 'credit', 'record', 'think', 'deserve', 'fat', 'old', 'piece']\n",
            "['mr_simpson', 'get', 'big', 'man', 'wonderful', 'girl', 'future', 'stake']\n",
            "['great', 'tell', 'favor', 'tell', 'earn']\n",
            "['ruin', 'chance', 'get', 'know', 'mr', 'bergstrom', 'outside', 'school']\n",
            "['tell', 'invite', 'mr', 'bergstrom', 'dinner']\n",
            "['oh', 'mom', 'wonderful', 'find', 'favorite', 'dish', 'help']\n",
            "['dye', 'shoe', 'pink']\n",
            "['mr', 'bergstrom', 'request', 'pleasure', 'company', 'mr', 'bergstrom', 'friday', 'mr', 'bergstrom', 'like', 'pork_chop', 'oh', 'course']\n",
            "['class', 'lyme', 'disease', 'turn']\n",
            "['psy', 'cho', 'ma', 'tic']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeNAl_MrvV_C"
      },
      "source": [
        "import multiprocessing\r\n",
        "\r\n",
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLynXrrZzhED"
      },
      "source": [
        "cores = multiprocessing.cpu_count()"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liQzgVwx094b"
      },
      "source": [
        "w = list(range(2,11))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OReQxV71NQi"
      },
      "source": [
        "d = list(range(10, 100, 10)) + list(range(100,600,100))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l3fLz-5Y1uoO",
        "outputId": "ab79969f-4c9b-456e-f8bc-7ca558fbfd3a"
      },
      "source": [
        "d"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UHxwYdGn2A6p",
        "outputId": "559ea0b5-33de-4ba0-ad1b-e0d935be9688"
      },
      "source": [
        "count = 0\r\n",
        "for window in w:\r\n",
        "  for size in d:\r\n",
        "    count += 1\r\n",
        "print(count)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "126\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQNOipxCK-9J"
      },
      "source": [
        "w2v_test = Word2Vec(min_count=20,\r\n",
        "                     iter = 100,\r\n",
        "                     window=4, #just to set as an init value\r\n",
        "                     size=4, #just to set as an init value\r\n",
        "                     sample=6e-5, \r\n",
        "                     alpha=0.03, \r\n",
        "                     min_alpha=0.0007, \r\n",
        "                     negative=20,\r\n",
        "                     workers=cores-1)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vlbpv3ApMEDV",
        "outputId": "47af90bb-0a4f-4754-ed51-9e64049b267c"
      },
      "source": [
        "t = time()\r\n",
        "w2v_test.build_vocab(sentences, progress_per=10000, update = True)\r\n",
        "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\r\n",
        "\r\n",
        "t = time()\r\n",
        "w2v_test.train(sentences, total_examples=w2v_test.corpus_count, epochs=2, report_delay=1)\r\n",
        "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\r\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:56:03: collecting all words and their counts\n",
            "INFO - 11:56:03: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 11:56:03: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 11:56:03: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 11:56:03: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 11:56:04: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 11:56:04: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 11:56:04: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 11:56:04: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 11:56:04: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 11:56:05: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 11:56:05: Updating model with new vocabulary\n",
            "INFO - 11:56:05: New added 3319 unique words (9% of original 33497) and increased the count of 3319 pre-existing words (9% of original 33497)\n",
            "INFO - 11:56:05: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 11:56:05: sample=6e-05 downsamples 2400 most-common words\n",
            "INFO - 11:56:05: downsampling leaves estimated 398323 word corpus (91.1% of prior 437324)\n",
            "INFO - 11:56:05: estimated required memory for 6638 words and 2 dimensions: 3425208 bytes\n",
            "INFO - 11:56:05: updating layer weights\n",
            "INFO - 11:56:05: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=4\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.03 mins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:56:06: EPOCH 1 - PROGRESS: at 39.38% examples, 78084 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 11:56:07: EPOCH 1 - PROGRESS: at 80.39% examples, 78788 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 11:56:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 11:56:07: EPOCH - 1 : training on 523700 raw words (198820 effective words) took 2.6s, 75190 effective words/s\n",
            "INFO - 11:56:08: EPOCH 2 - PROGRESS: at 39.38% examples, 78906 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 11:56:09: EPOCH 2 - PROGRESS: at 80.39% examples, 79379 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 11:56:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 11:56:10: EPOCH - 2 : training on 523700 raw words (199218 effective words) took 2.5s, 80228 effective words/s\n",
            "INFO - 11:56:10: training on a 1047400 raw words (398038 effective words) took 5.1s, 77340 effective words/s\n",
            "INFO - 11:56:10: saving Word2Vec object under mydemo.mdl, separately None\n",
            "INFO - 11:56:10: not storing attribute vectors_norm\n",
            "INFO - 11:56:10: not storing attribute cum_table\n",
            "INFO - 11:56:10: saved mydemo.mdl\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to train the model: 0.09 mins\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-gzNOlONFcn",
        "outputId": "fa9f7762-9dee-4ffc-f46e-650510755652"
      },
      "source": [
        "w2v_test.save(\"mydemo.mdl\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 11:56:44: saving Word2Vec object under mydemo.mdl, separately None\n",
            "INFO - 11:56:44: not storing attribute vectors_norm\n",
            "INFO - 11:56:44: not storing attribute cum_table\n",
            "INFO - 11:56:44: saved mydemo.mdl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jknj1N7ZLYFA"
      },
      "source": [
        "w2v_test.window = 4"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "21NX-_lmL5K0",
        "outputId": "de86978e-d606-4d95-da95-ccc4f003ca12"
      },
      "source": [
        "print(w2v_test.window)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGevFJtfp6fi"
      },
      "source": [
        "###Week 11 Experimentation on window size (w) and vector size (d)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ww9rNaaJ2jX3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd368f7b-2f1e-4fda-9d3d-b7c7031359ec"
      },
      "source": [
        "model_name = \" \"\r\n",
        "w2v = Word2Vec(min_count=20,\r\n",
        "                     iter = 100,\r\n",
        "                     window=2, #just to set as an init value\r\n",
        "                     size=2, #just to set as an init value\r\n",
        "                     sample=6e-5, \r\n",
        "                     alpha=0.03, \r\n",
        "                     min_alpha=0.0007, \r\n",
        "                     negative=20,\r\n",
        "                     workers=cores-1)\r\n",
        "w2v.build_vocab(sentences, progress_per=10000)\r\n",
        "for window in w:\r\n",
        "  for size in d:\r\n",
        "    model_name = \"w2v_model_window-{}_size-{}.mdl\".format(window,size)\r\n",
        "    #os.makedir(\"/content/.../w2v_model_window-{}_size-{}\")\r\n",
        "    #w2v.reset()\r\n",
        "    w2v.windows = window\r\n",
        "    w2v.size = size\r\n",
        "    #make sure that the model start training from scratch and does not continue on previous iteration!\r\n",
        "    w2v.train(sentences, total_examples=w2v.corpus_count, epochs=2, report_delay=1)\r\n",
        "    w2v.save(model_name)\r\n",
        "    \r\n",
        "    "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING - 12:13:41: consider setting layer size to a multiple of 4 for greater performance\n",
            "INFO - 12:13:41: collecting all words and their counts\n",
            "INFO - 12:13:41: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 12:13:41: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 12:13:42: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 12:13:42: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 12:13:42: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 12:13:42: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 12:13:43: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 12:13:43: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 12:13:43: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 12:13:43: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 12:13:43: Loading a fresh vocabulary\n",
            "INFO - 12:13:43: effective_min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n",
            "INFO - 12:13:43: effective_min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n",
            "INFO - 12:13:43: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 12:13:43: sample=6e-05 downsamples 1200 most-common words\n",
            "INFO - 12:13:43: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n",
            "INFO - 12:13:43: estimated required memory for 3319 words and 2 dimensions: 1712604 bytes\n",
            "INFO - 12:13:43: resetting layer weights\n",
            "INFO - 12:13:44: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:13:45: EPOCH 1 - PROGRESS: at 41.53% examples, 81050 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:46: EPOCH 1 - PROGRESS: at 84.20% examples, 81157 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:46: EPOCH - 1 : training on 523700 raw words (198820 effective words) took 2.4s, 81793 effective words/s\n",
            "INFO - 12:13:47: EPOCH 2 - PROGRESS: at 41.53% examples, 80658 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:48: EPOCH 2 - PROGRESS: at 82.28% examples, 80092 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:49: EPOCH - 2 : training on 523700 raw words (199218 effective words) took 2.5s, 80901 effective words/s\n",
            "INFO - 12:13:49: training on a 1047400 raw words (398038 effective words) took 4.9s, 81041 effective words/s\n",
            "INFO - 12:13:49: saving Word2Vec object under w2v_model_window-2_size-10.mdl, separately None\n",
            "INFO - 12:13:49: not storing attribute vectors_norm\n",
            "INFO - 12:13:49: not storing attribute cum_table\n",
            "INFO - 12:13:49: saved w2v_model_window-2_size-10.mdl\n",
            "WARNING - 12:13:49: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:13:49: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:13:50: EPOCH 1 - PROGRESS: at 33.37% examples, 67838 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:51: EPOCH 1 - PROGRESS: at 74.71% examples, 73023 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:51: EPOCH - 1 : training on 523700 raw words (199222 effective words) took 2.6s, 75241 effective words/s\n",
            "INFO - 12:13:52: EPOCH 2 - PROGRESS: at 39.38% examples, 79107 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:53: EPOCH 2 - PROGRESS: at 80.39% examples, 78938 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:54: EPOCH - 2 : training on 523700 raw words (199150 effective words) took 2.5s, 80043 effective words/s\n",
            "INFO - 12:13:54: training on a 1047400 raw words (398372 effective words) took 5.2s, 77284 effective words/s\n",
            "INFO - 12:13:54: saving Word2Vec object under w2v_model_window-2_size-20.mdl, separately None\n",
            "INFO - 12:13:54: not storing attribute vectors_norm\n",
            "INFO - 12:13:54: not storing attribute cum_table\n",
            "INFO - 12:13:54: saved w2v_model_window-2_size-20.mdl\n",
            "WARNING - 12:13:54: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:13:54: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:13:55: EPOCH 1 - PROGRESS: at 39.38% examples, 79518 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:56: EPOCH 1 - PROGRESS: at 82.28% examples, 80293 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:56: EPOCH - 1 : training on 523700 raw words (199540 effective words) took 2.5s, 81309 effective words/s\n",
            "INFO - 12:13:57: EPOCH 2 - PROGRESS: at 33.37% examples, 68150 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:58: EPOCH 2 - PROGRESS: at 74.71% examples, 73195 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:13:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:13:59: EPOCH - 2 : training on 523700 raw words (199462 effective words) took 2.6s, 75464 effective words/s\n",
            "INFO - 12:13:59: training on a 1047400 raw words (399002 effective words) took 5.1s, 77996 effective words/s\n",
            "INFO - 12:13:59: saving Word2Vec object under w2v_model_window-2_size-30.mdl, separately None\n",
            "INFO - 12:13:59: not storing attribute vectors_norm\n",
            "INFO - 12:13:59: not storing attribute cum_table\n",
            "INFO - 12:13:59: saved w2v_model_window-2_size-30.mdl\n",
            "WARNING - 12:13:59: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:13:59: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:00: EPOCH 1 - PROGRESS: at 39.38% examples, 76023 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:01: EPOCH 1 - PROGRESS: at 80.39% examples, 76510 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:02: EPOCH - 1 : training on 523700 raw words (199000 effective words) took 2.6s, 75467 effective words/s\n",
            "INFO - 12:14:03: EPOCH 2 - PROGRESS: at 39.38% examples, 77808 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:04: EPOCH 2 - PROGRESS: at 80.39% examples, 78899 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:04: EPOCH - 2 : training on 523700 raw words (199266 effective words) took 2.5s, 79987 effective words/s\n",
            "INFO - 12:14:04: training on a 1047400 raw words (398266 effective words) took 5.2s, 77321 effective words/s\n",
            "INFO - 12:14:04: saving Word2Vec object under w2v_model_window-2_size-40.mdl, separately None\n",
            "INFO - 12:14:04: not storing attribute vectors_norm\n",
            "INFO - 12:14:04: not storing attribute cum_table\n",
            "INFO - 12:14:04: saved w2v_model_window-2_size-40.mdl\n",
            "WARNING - 12:14:04: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:04: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:05: EPOCH 1 - PROGRESS: at 33.37% examples, 68007 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:06: EPOCH 1 - PROGRESS: at 74.71% examples, 73784 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:07: EPOCH - 1 : training on 523700 raw words (199201 effective words) took 2.6s, 75890 effective words/s\n",
            "INFO - 12:14:08: EPOCH 2 - PROGRESS: at 39.38% examples, 78836 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:09: EPOCH 2 - PROGRESS: at 80.39% examples, 79540 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:09: EPOCH - 2 : training on 523700 raw words (199075 effective words) took 2.5s, 80284 effective words/s\n",
            "INFO - 12:14:09: training on a 1047400 raw words (398276 effective words) took 5.1s, 77784 effective words/s\n",
            "INFO - 12:14:09: saving Word2Vec object under w2v_model_window-2_size-50.mdl, separately None\n",
            "INFO - 12:14:09: not storing attribute vectors_norm\n",
            "INFO - 12:14:09: not storing attribute cum_table\n",
            "INFO - 12:14:09: saved w2v_model_window-2_size-50.mdl\n",
            "WARNING - 12:14:09: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:09: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:10: EPOCH 1 - PROGRESS: at 39.38% examples, 79411 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:12: EPOCH 1 - PROGRESS: at 80.39% examples, 78435 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:12: EPOCH - 1 : training on 523700 raw words (199385 effective words) took 2.5s, 79761 effective words/s\n",
            "INFO - 12:14:13: EPOCH 2 - PROGRESS: at 33.37% examples, 67245 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:14: EPOCH 2 - PROGRESS: at 74.71% examples, 73607 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:15: EPOCH - 2 : training on 523700 raw words (198819 effective words) took 2.6s, 75757 effective words/s\n",
            "INFO - 12:14:15: training on a 1047400 raw words (398204 effective words) took 5.1s, 77494 effective words/s\n",
            "INFO - 12:14:15: saving Word2Vec object under w2v_model_window-2_size-60.mdl, separately None\n",
            "INFO - 12:14:15: not storing attribute vectors_norm\n",
            "INFO - 12:14:15: not storing attribute cum_table\n",
            "INFO - 12:14:15: saved w2v_model_window-2_size-60.mdl\n",
            "WARNING - 12:14:15: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:15: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:16: EPOCH 1 - PROGRESS: at 39.38% examples, 78882 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:17: EPOCH 1 - PROGRESS: at 80.39% examples, 79246 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:17: EPOCH - 1 : training on 523700 raw words (199107 effective words) took 2.5s, 79840 effective words/s\n",
            "INFO - 12:14:18: EPOCH 2 - PROGRESS: at 39.38% examples, 78631 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:19: EPOCH 2 - PROGRESS: at 82.28% examples, 80228 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:20: EPOCH - 2 : training on 523700 raw words (199018 effective words) took 2.5s, 80624 effective words/s\n",
            "INFO - 12:14:20: training on a 1047400 raw words (398125 effective words) took 5.0s, 79890 effective words/s\n",
            "INFO - 12:14:20: saving Word2Vec object under w2v_model_window-2_size-70.mdl, separately None\n",
            "INFO - 12:14:20: not storing attribute vectors_norm\n",
            "INFO - 12:14:20: not storing attribute cum_table\n",
            "INFO - 12:14:20: saved w2v_model_window-2_size-70.mdl\n",
            "WARNING - 12:14:20: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:20: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:21: EPOCH 1 - PROGRESS: at 33.37% examples, 66917 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:22: EPOCH 1 - PROGRESS: at 74.71% examples, 73140 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:22: EPOCH - 1 : training on 523700 raw words (199635 effective words) took 2.6s, 75657 effective words/s\n",
            "INFO - 12:14:23: EPOCH 2 - PROGRESS: at 39.38% examples, 77863 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:24: EPOCH 2 - PROGRESS: at 82.28% examples, 79389 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:25: EPOCH - 2 : training on 523700 raw words (199205 effective words) took 2.5s, 79340 effective words/s\n",
            "INFO - 12:14:25: training on a 1047400 raw words (398840 effective words) took 5.2s, 77217 effective words/s\n",
            "INFO - 12:14:25: saving Word2Vec object under w2v_model_window-2_size-80.mdl, separately None\n",
            "INFO - 12:14:25: not storing attribute vectors_norm\n",
            "INFO - 12:14:25: not storing attribute cum_table\n",
            "INFO - 12:14:25: saved w2v_model_window-2_size-80.mdl\n",
            "WARNING - 12:14:25: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:25: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:26: EPOCH 1 - PROGRESS: at 39.38% examples, 76993 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:27: EPOCH 1 - PROGRESS: at 82.28% examples, 79344 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:28: EPOCH - 1 : training on 523700 raw words (199196 effective words) took 2.6s, 75728 effective words/s\n",
            "INFO - 12:14:29: EPOCH 2 - PROGRESS: at 39.38% examples, 77900 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:30: EPOCH 2 - PROGRESS: at 80.39% examples, 78606 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:30: EPOCH - 2 : training on 523700 raw words (199097 effective words) took 2.5s, 79592 effective words/s\n",
            "INFO - 12:14:30: training on a 1047400 raw words (398293 effective words) took 5.2s, 77292 effective words/s\n",
            "INFO - 12:14:30: saving Word2Vec object under w2v_model_window-2_size-90.mdl, separately None\n",
            "INFO - 12:14:30: not storing attribute vectors_norm\n",
            "INFO - 12:14:30: not storing attribute cum_table\n",
            "INFO - 12:14:30: saved w2v_model_window-2_size-90.mdl\n",
            "WARNING - 12:14:30: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:30: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:31: EPOCH 1 - PROGRESS: at 39.38% examples, 78568 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:32: EPOCH 1 - PROGRESS: at 80.39% examples, 77621 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:33: EPOCH - 1 : training on 523700 raw words (199697 effective words) took 2.5s, 79158 effective words/s\n",
            "INFO - 12:14:34: EPOCH 2 - PROGRESS: at 39.38% examples, 78967 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:35: EPOCH 2 - PROGRESS: at 74.71% examples, 72491 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:35: EPOCH - 2 : training on 523700 raw words (199491 effective words) took 2.7s, 74730 effective words/s\n",
            "INFO - 12:14:35: training on a 1047400 raw words (399188 effective words) took 5.2s, 76585 effective words/s\n",
            "INFO - 12:14:35: saving Word2Vec object under w2v_model_window-2_size-100.mdl, separately None\n",
            "INFO - 12:14:35: not storing attribute vectors_norm\n",
            "INFO - 12:14:35: not storing attribute cum_table\n",
            "INFO - 12:14:35: saved w2v_model_window-2_size-100.mdl\n",
            "WARNING - 12:14:35: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:35: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:36: EPOCH 1 - PROGRESS: at 39.38% examples, 77053 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:37: EPOCH 1 - PROGRESS: at 82.28% examples, 78385 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:38: EPOCH - 1 : training on 523700 raw words (198582 effective words) took 2.5s, 79201 effective words/s\n",
            "INFO - 12:14:39: EPOCH 2 - PROGRESS: at 39.38% examples, 78490 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:40: EPOCH 2 - PROGRESS: at 82.28% examples, 79953 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:40: EPOCH - 2 : training on 523700 raw words (199255 effective words) took 2.5s, 80382 effective words/s\n",
            "INFO - 12:14:40: training on a 1047400 raw words (397837 effective words) took 5.0s, 79426 effective words/s\n",
            "INFO - 12:14:40: saving Word2Vec object under w2v_model_window-2_size-200.mdl, separately None\n",
            "INFO - 12:14:40: not storing attribute vectors_norm\n",
            "INFO - 12:14:40: not storing attribute cum_table\n",
            "INFO - 12:14:40: saved w2v_model_window-2_size-200.mdl\n",
            "WARNING - 12:14:40: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:40: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:41: EPOCH 1 - PROGRESS: at 41.53% examples, 79840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:42: EPOCH 1 - PROGRESS: at 76.60% examples, 73373 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:43: EPOCH - 1 : training on 523700 raw words (199012 effective words) took 2.6s, 75421 effective words/s\n",
            "INFO - 12:14:44: EPOCH 2 - PROGRESS: at 39.38% examples, 78330 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:45: EPOCH 2 - PROGRESS: at 82.28% examples, 79969 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:46: EPOCH - 2 : training on 523700 raw words (198827 effective words) took 2.5s, 80300 effective words/s\n",
            "INFO - 12:14:46: training on a 1047400 raw words (397839 effective words) took 5.1s, 77533 effective words/s\n",
            "INFO - 12:14:46: saving Word2Vec object under w2v_model_window-2_size-300.mdl, separately None\n",
            "INFO - 12:14:46: not storing attribute vectors_norm\n",
            "INFO - 12:14:46: not storing attribute cum_table\n",
            "INFO - 12:14:46: saved w2v_model_window-2_size-300.mdl\n",
            "WARNING - 12:14:46: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:46: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:47: EPOCH 1 - PROGRESS: at 39.38% examples, 77831 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:48: EPOCH 1 - PROGRESS: at 80.39% examples, 78931 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:48: EPOCH - 1 : training on 523700 raw words (199315 effective words) took 2.5s, 79676 effective words/s\n",
            "INFO - 12:14:49: EPOCH 2 - PROGRESS: at 39.38% examples, 77271 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:50: EPOCH 2 - PROGRESS: at 74.71% examples, 72799 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:51: EPOCH - 2 : training on 523700 raw words (199170 effective words) took 2.6s, 75194 effective words/s\n",
            "INFO - 12:14:51: training on a 1047400 raw words (398485 effective words) took 5.2s, 76990 effective words/s\n",
            "INFO - 12:14:51: saving Word2Vec object under w2v_model_window-2_size-400.mdl, separately None\n",
            "INFO - 12:14:51: not storing attribute vectors_norm\n",
            "INFO - 12:14:51: not storing attribute cum_table\n",
            "INFO - 12:14:51: saved w2v_model_window-2_size-400.mdl\n",
            "WARNING - 12:14:51: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:51: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:52: EPOCH 1 - PROGRESS: at 39.38% examples, 78795 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:53: EPOCH 1 - PROGRESS: at 80.39% examples, 79406 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:53: EPOCH - 1 : training on 523700 raw words (199503 effective words) took 2.5s, 79688 effective words/s\n",
            "INFO - 12:14:54: EPOCH 2 - PROGRESS: at 39.38% examples, 78129 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:55: EPOCH 2 - PROGRESS: at 80.39% examples, 78792 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:56: EPOCH - 2 : training on 523700 raw words (199304 effective words) took 2.5s, 79466 effective words/s\n",
            "INFO - 12:14:56: training on a 1047400 raw words (398807 effective words) took 5.0s, 79319 effective words/s\n",
            "INFO - 12:14:56: saving Word2Vec object under w2v_model_window-2_size-500.mdl, separately None\n",
            "INFO - 12:14:56: not storing attribute vectors_norm\n",
            "INFO - 12:14:56: not storing attribute cum_table\n",
            "INFO - 12:14:56: saved w2v_model_window-2_size-500.mdl\n",
            "WARNING - 12:14:56: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:14:56: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:14:57: EPOCH 1 - PROGRESS: at 39.38% examples, 78255 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:14:58: EPOCH 1 - PROGRESS: at 76.60% examples, 73478 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:14:58: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:14:58: EPOCH - 1 : training on 523700 raw words (199329 effective words) took 2.7s, 75062 effective words/s\n",
            "INFO - 12:15:00: EPOCH 2 - PROGRESS: at 39.38% examples, 77984 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:01: EPOCH 2 - PROGRESS: at 80.39% examples, 78047 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:01: EPOCH - 2 : training on 523700 raw words (198902 effective words) took 2.5s, 79487 effective words/s\n",
            "INFO - 12:15:01: training on a 1047400 raw words (398231 effective words) took 5.2s, 76952 effective words/s\n",
            "INFO - 12:15:01: saving Word2Vec object under w2v_model_window-3_size-10.mdl, separately None\n",
            "INFO - 12:15:01: not storing attribute vectors_norm\n",
            "INFO - 12:15:01: not storing attribute cum_table\n",
            "INFO - 12:15:01: saved w2v_model_window-3_size-10.mdl\n",
            "WARNING - 12:15:01: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:01: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:02: EPOCH 1 - PROGRESS: at 39.38% examples, 75949 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:03: EPOCH 1 - PROGRESS: at 72.83% examples, 69957 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:04: EPOCH - 1 : training on 523700 raw words (199000 effective words) took 2.8s, 72185 effective words/s\n",
            "INFO - 12:15:05: EPOCH 2 - PROGRESS: at 39.38% examples, 77280 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:06: EPOCH 2 - PROGRESS: at 74.71% examples, 72153 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:15:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:06: EPOCH - 2 : training on 523700 raw words (198802 effective words) took 2.7s, 74661 effective words/s\n",
            "INFO - 12:15:06: training on a 1047400 raw words (397802 effective words) took 5.4s, 72997 effective words/s\n",
            "INFO - 12:15:06: saving Word2Vec object under w2v_model_window-3_size-20.mdl, separately None\n",
            "INFO - 12:15:06: not storing attribute vectors_norm\n",
            "INFO - 12:15:06: not storing attribute cum_table\n",
            "INFO - 12:15:07: saved w2v_model_window-3_size-20.mdl\n",
            "WARNING - 12:15:07: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:07: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:08: EPOCH 1 - PROGRESS: at 39.38% examples, 76739 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:09: EPOCH 1 - PROGRESS: at 82.28% examples, 78554 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:09: EPOCH - 1 : training on 523700 raw words (198809 effective words) took 2.5s, 79177 effective words/s\n",
            "INFO - 12:15:10: EPOCH 2 - PROGRESS: at 39.38% examples, 77568 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:11: EPOCH 2 - PROGRESS: at 80.39% examples, 78753 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:12: EPOCH - 2 : training on 523700 raw words (198938 effective words) took 2.5s, 79540 effective words/s\n",
            "INFO - 12:15:12: training on a 1047400 raw words (397747 effective words) took 5.0s, 78885 effective words/s\n",
            "INFO - 12:15:12: saving Word2Vec object under w2v_model_window-3_size-30.mdl, separately None\n",
            "INFO - 12:15:12: not storing attribute vectors_norm\n",
            "INFO - 12:15:12: not storing attribute cum_table\n",
            "INFO - 12:15:12: saved w2v_model_window-3_size-30.mdl\n",
            "WARNING - 12:15:12: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:12: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:13: EPOCH 1 - PROGRESS: at 39.38% examples, 78087 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:14: EPOCH 1 - PROGRESS: at 76.60% examples, 73623 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:14: EPOCH - 1 : training on 523700 raw words (198677 effective words) took 2.7s, 74687 effective words/s\n",
            "INFO - 12:15:15: EPOCH 2 - PROGRESS: at 39.38% examples, 77791 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:16: EPOCH 2 - PROGRESS: at 80.39% examples, 78519 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:17: EPOCH - 2 : training on 523700 raw words (199116 effective words) took 2.5s, 79150 effective words/s\n",
            "INFO - 12:15:17: training on a 1047400 raw words (397793 effective words) took 5.2s, 76603 effective words/s\n",
            "INFO - 12:15:17: saving Word2Vec object under w2v_model_window-3_size-40.mdl, separately None\n",
            "INFO - 12:15:17: not storing attribute vectors_norm\n",
            "INFO - 12:15:17: not storing attribute cum_table\n",
            "INFO - 12:15:17: saved w2v_model_window-3_size-40.mdl\n",
            "WARNING - 12:15:17: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:17: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:18: EPOCH 1 - PROGRESS: at 41.53% examples, 79800 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:19: EPOCH 1 - PROGRESS: at 82.28% examples, 79843 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:19: EPOCH - 1 : training on 523700 raw words (199152 effective words) took 2.5s, 80288 effective words/s\n",
            "INFO - 12:15:20: EPOCH 2 - PROGRESS: at 33.37% examples, 67056 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:21: EPOCH 2 - PROGRESS: at 76.60% examples, 73830 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:22: EPOCH - 2 : training on 523700 raw words (199065 effective words) took 2.6s, 75482 effective words/s\n",
            "INFO - 12:15:22: training on a 1047400 raw words (398217 effective words) took 5.1s, 77489 effective words/s\n",
            "INFO - 12:15:22: saving Word2Vec object under w2v_model_window-3_size-50.mdl, separately None\n",
            "INFO - 12:15:22: not storing attribute vectors_norm\n",
            "INFO - 12:15:22: not storing attribute cum_table\n",
            "INFO - 12:15:22: saved w2v_model_window-3_size-50.mdl\n",
            "WARNING - 12:15:22: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:22: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:23: EPOCH 1 - PROGRESS: at 39.38% examples, 78086 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:24: EPOCH 1 - PROGRESS: at 80.39% examples, 77727 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:15:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:25: EPOCH - 1 : training on 523700 raw words (199243 effective words) took 2.5s, 78652 effective words/s\n",
            "INFO - 12:15:26: EPOCH 2 - PROGRESS: at 39.38% examples, 77918 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:27: EPOCH 2 - PROGRESS: at 82.28% examples, 79458 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:27: EPOCH - 2 : training on 523700 raw words (199251 effective words) took 2.5s, 79998 effective words/s\n",
            "INFO - 12:15:27: training on a 1047400 raw words (398494 effective words) took 5.0s, 79070 effective words/s\n",
            "INFO - 12:15:27: saving Word2Vec object under w2v_model_window-3_size-60.mdl, separately None\n",
            "INFO - 12:15:27: not storing attribute vectors_norm\n",
            "INFO - 12:15:27: not storing attribute cum_table\n",
            "INFO - 12:15:27: saved w2v_model_window-3_size-60.mdl\n",
            "WARNING - 12:15:27: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:27: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:28: EPOCH 1 - PROGRESS: at 33.37% examples, 67196 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:29: EPOCH 1 - PROGRESS: at 74.71% examples, 72551 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:30: EPOCH - 1 : training on 523700 raw words (198876 effective words) took 2.7s, 74361 effective words/s\n",
            "INFO - 12:15:31: EPOCH 2 - PROGRESS: at 39.38% examples, 75993 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:32: EPOCH 2 - PROGRESS: at 80.39% examples, 77320 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:32: EPOCH - 2 : training on 523700 raw words (199126 effective words) took 2.5s, 78804 effective words/s\n",
            "INFO - 12:15:32: training on a 1047400 raw words (398002 effective words) took 5.2s, 76226 effective words/s\n",
            "INFO - 12:15:32: saving Word2Vec object under w2v_model_window-3_size-70.mdl, separately None\n",
            "INFO - 12:15:32: not storing attribute vectors_norm\n",
            "INFO - 12:15:32: not storing attribute cum_table\n",
            "INFO - 12:15:32: saved w2v_model_window-3_size-70.mdl\n",
            "WARNING - 12:15:32: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:32: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:33: EPOCH 1 - PROGRESS: at 39.38% examples, 76325 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:34: EPOCH 1 - PROGRESS: at 80.39% examples, 77690 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:35: EPOCH - 1 : training on 523700 raw words (199422 effective words) took 2.6s, 77617 effective words/s\n",
            "INFO - 12:15:36: EPOCH 2 - PROGRESS: at 39.38% examples, 67483 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:37: EPOCH 2 - PROGRESS: at 80.39% examples, 72106 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:38: EPOCH - 2 : training on 523700 raw words (199070 effective words) took 2.7s, 73676 effective words/s\n",
            "INFO - 12:15:38: training on a 1047400 raw words (398492 effective words) took 5.3s, 75208 effective words/s\n",
            "INFO - 12:15:38: saving Word2Vec object under w2v_model_window-3_size-80.mdl, separately None\n",
            "INFO - 12:15:38: not storing attribute vectors_norm\n",
            "INFO - 12:15:38: not storing attribute cum_table\n",
            "INFO - 12:15:38: saved w2v_model_window-3_size-80.mdl\n",
            "WARNING - 12:15:38: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:38: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:39: EPOCH 1 - PROGRESS: at 39.38% examples, 78229 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:40: EPOCH 1 - PROGRESS: at 78.53% examples, 76992 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:40: EPOCH - 1 : training on 523700 raw words (199428 effective words) took 2.6s, 77540 effective words/s\n",
            "INFO - 12:15:41: EPOCH 2 - PROGRESS: at 37.40% examples, 74812 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:15:42: EPOCH 2 - PROGRESS: at 78.53% examples, 77000 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:15:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:43: EPOCH - 2 : training on 523700 raw words (199110 effective words) took 2.5s, 78097 effective words/s\n",
            "INFO - 12:15:43: training on a 1047400 raw words (398538 effective words) took 5.1s, 77457 effective words/s\n",
            "INFO - 12:15:43: saving Word2Vec object under w2v_model_window-3_size-90.mdl, separately None\n",
            "INFO - 12:15:43: not storing attribute vectors_norm\n",
            "INFO - 12:15:43: not storing attribute cum_table\n",
            "INFO - 12:15:43: saved w2v_model_window-3_size-90.mdl\n",
            "WARNING - 12:15:43: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:43: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:44: EPOCH 1 - PROGRESS: at 39.38% examples, 76947 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:45: EPOCH 1 - PROGRESS: at 74.71% examples, 72767 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:46: EPOCH - 1 : training on 523700 raw words (199093 effective words) took 2.7s, 74716 effective words/s\n",
            "INFO - 12:15:47: EPOCH 2 - PROGRESS: at 39.38% examples, 77116 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:48: EPOCH 2 - PROGRESS: at 80.39% examples, 77885 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:48: EPOCH - 2 : training on 523700 raw words (198886 effective words) took 2.5s, 78803 effective words/s\n",
            "INFO - 12:15:48: training on a 1047400 raw words (397979 effective words) took 5.2s, 76376 effective words/s\n",
            "INFO - 12:15:48: saving Word2Vec object under w2v_model_window-3_size-100.mdl, separately None\n",
            "INFO - 12:15:48: not storing attribute vectors_norm\n",
            "INFO - 12:15:48: not storing attribute cum_table\n",
            "INFO - 12:15:48: saved w2v_model_window-3_size-100.mdl\n",
            "WARNING - 12:15:48: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:48: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:49: EPOCH 1 - PROGRESS: at 37.40% examples, 75055 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:50: EPOCH 1 - PROGRESS: at 78.53% examples, 76835 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:51: EPOCH - 1 : training on 523700 raw words (199402 effective words) took 2.6s, 77677 effective words/s\n",
            "INFO - 12:15:52: EPOCH 2 - PROGRESS: at 37.40% examples, 68422 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:53: EPOCH 2 - PROGRESS: at 78.53% examples, 74013 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:53: EPOCH - 2 : training on 523700 raw words (199314 effective words) took 2.6s, 75256 effective words/s\n",
            "INFO - 12:15:53: training on a 1047400 raw words (398716 effective words) took 5.2s, 76044 effective words/s\n",
            "INFO - 12:15:53: saving Word2Vec object under w2v_model_window-3_size-200.mdl, separately None\n",
            "INFO - 12:15:53: not storing attribute vectors_norm\n",
            "INFO - 12:15:53: not storing attribute cum_table\n",
            "INFO - 12:15:53: saved w2v_model_window-3_size-200.mdl\n",
            "WARNING - 12:15:53: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:53: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:15:54: EPOCH 1 - PROGRESS: at 37.40% examples, 75170 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:55: EPOCH 1 - PROGRESS: at 78.53% examples, 76978 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:56: EPOCH - 1 : training on 523700 raw words (199574 effective words) took 2.6s, 76980 effective words/s\n",
            "INFO - 12:15:57: EPOCH 2 - PROGRESS: at 39.38% examples, 77695 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:58: EPOCH 2 - PROGRESS: at 80.39% examples, 78699 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:15:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:15:59: EPOCH - 2 : training on 523700 raw words (199289 effective words) took 2.5s, 78864 effective words/s\n",
            "INFO - 12:15:59: training on a 1047400 raw words (398863 effective words) took 5.1s, 77548 effective words/s\n",
            "INFO - 12:15:59: saving Word2Vec object under w2v_model_window-3_size-300.mdl, separately None\n",
            "INFO - 12:15:59: not storing attribute vectors_norm\n",
            "INFO - 12:15:59: not storing attribute cum_table\n",
            "INFO - 12:15:59: saved w2v_model_window-3_size-300.mdl\n",
            "WARNING - 12:15:59: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:15:59: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:00: EPOCH 1 - PROGRESS: at 31.39% examples, 63629 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:01: EPOCH 1 - PROGRESS: at 72.83% examples, 70940 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:01: EPOCH - 1 : training on 523700 raw words (199152 effective words) took 2.7s, 73989 effective words/s\n",
            "INFO - 12:16:02: EPOCH 2 - PROGRESS: at 39.38% examples, 75974 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:03: EPOCH 2 - PROGRESS: at 78.53% examples, 75548 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:04: EPOCH - 2 : training on 523700 raw words (198957 effective words) took 2.6s, 76674 effective words/s\n",
            "INFO - 12:16:04: training on a 1047400 raw words (398109 effective words) took 5.3s, 74978 effective words/s\n",
            "INFO - 12:16:04: saving Word2Vec object under w2v_model_window-3_size-400.mdl, separately None\n",
            "INFO - 12:16:04: not storing attribute vectors_norm\n",
            "INFO - 12:16:04: not storing attribute cum_table\n",
            "INFO - 12:16:04: saved w2v_model_window-3_size-400.mdl\n",
            "WARNING - 12:16:04: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:04: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:05: EPOCH 1 - PROGRESS: at 39.38% examples, 76472 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:06: EPOCH 1 - PROGRESS: at 80.39% examples, 76459 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:07: EPOCH - 1 : training on 523700 raw words (199111 effective words) took 2.6s, 76652 effective words/s\n",
            "INFO - 12:16:08: EPOCH 2 - PROGRESS: at 33.37% examples, 65499 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:09: EPOCH 2 - PROGRESS: at 74.71% examples, 72185 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:09: EPOCH - 2 : training on 523700 raw words (199432 effective words) took 2.7s, 73298 effective words/s\n",
            "INFO - 12:16:09: training on a 1047400 raw words (398543 effective words) took 5.3s, 74699 effective words/s\n",
            "INFO - 12:16:09: saving Word2Vec object under w2v_model_window-3_size-500.mdl, separately None\n",
            "INFO - 12:16:09: not storing attribute vectors_norm\n",
            "INFO - 12:16:09: not storing attribute cum_table\n",
            "INFO - 12:16:09: saved w2v_model_window-3_size-500.mdl\n",
            "WARNING - 12:16:09: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:09: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:10: EPOCH 1 - PROGRESS: at 39.38% examples, 76161 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:11: EPOCH 1 - PROGRESS: at 80.39% examples, 77158 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:12: EPOCH - 1 : training on 523700 raw words (199134 effective words) took 2.6s, 77893 effective words/s\n",
            "INFO - 12:16:13: EPOCH 2 - PROGRESS: at 39.38% examples, 76930 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:14: EPOCH 2 - PROGRESS: at 80.39% examples, 78440 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:15: EPOCH - 2 : training on 523700 raw words (199003 effective words) took 2.7s, 74678 effective words/s\n",
            "INFO - 12:16:15: training on a 1047400 raw words (398137 effective words) took 5.3s, 75823 effective words/s\n",
            "INFO - 12:16:15: saving Word2Vec object under w2v_model_window-4_size-10.mdl, separately None\n",
            "INFO - 12:16:15: not storing attribute vectors_norm\n",
            "INFO - 12:16:15: not storing attribute cum_table\n",
            "INFO - 12:16:15: saved w2v_model_window-4_size-10.mdl\n",
            "WARNING - 12:16:15: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:15: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:16: EPOCH 1 - PROGRESS: at 39.38% examples, 76640 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:17: EPOCH 1 - PROGRESS: at 80.39% examples, 78224 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:17: EPOCH - 1 : training on 523700 raw words (198588 effective words) took 2.5s, 79598 effective words/s\n",
            "INFO - 12:16:18: EPOCH 2 - PROGRESS: at 39.38% examples, 77914 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:19: EPOCH 2 - PROGRESS: at 82.28% examples, 78967 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:20: EPOCH - 2 : training on 523700 raw words (198989 effective words) took 2.5s, 78828 effective words/s\n",
            "INFO - 12:16:20: training on a 1047400 raw words (397577 effective words) took 5.0s, 78875 effective words/s\n",
            "INFO - 12:16:20: saving Word2Vec object under w2v_model_window-4_size-20.mdl, separately None\n",
            "INFO - 12:16:20: not storing attribute vectors_norm\n",
            "INFO - 12:16:20: not storing attribute cum_table\n",
            "INFO - 12:16:20: saved w2v_model_window-4_size-20.mdl\n",
            "WARNING - 12:16:20: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:20: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:21: EPOCH 1 - PROGRESS: at 39.38% examples, 76934 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:22: EPOCH 1 - PROGRESS: at 80.39% examples, 77514 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:22: EPOCH - 1 : training on 523700 raw words (199043 effective words) took 2.5s, 78236 effective words/s\n",
            "INFO - 12:16:23: EPOCH 2 - PROGRESS: at 31.39% examples, 63950 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:24: EPOCH 2 - PROGRESS: at 72.83% examples, 71866 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:25: EPOCH - 2 : training on 523700 raw words (199183 effective words) took 2.7s, 73371 effective words/s\n",
            "INFO - 12:16:25: training on a 1047400 raw words (398226 effective words) took 5.3s, 75428 effective words/s\n",
            "INFO - 12:16:25: saving Word2Vec object under w2v_model_window-4_size-30.mdl, separately None\n",
            "INFO - 12:16:25: not storing attribute vectors_norm\n",
            "INFO - 12:16:25: not storing attribute cum_table\n",
            "INFO - 12:16:25: saved w2v_model_window-4_size-30.mdl\n",
            "WARNING - 12:16:25: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:25: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:26: EPOCH 1 - PROGRESS: at 37.40% examples, 74583 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:27: EPOCH 1 - PROGRESS: at 78.53% examples, 75150 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:28: EPOCH - 1 : training on 523700 raw words (199578 effective words) took 2.6s, 77364 effective words/s\n",
            "INFO - 12:16:29: EPOCH 2 - PROGRESS: at 39.38% examples, 76175 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:30: EPOCH 2 - PROGRESS: at 80.39% examples, 77351 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:30: EPOCH - 2 : training on 523700 raw words (198701 effective words) took 2.6s, 77420 effective words/s\n",
            "INFO - 12:16:30: training on a 1047400 raw words (398279 effective words) took 5.2s, 77175 effective words/s\n",
            "INFO - 12:16:30: saving Word2Vec object under w2v_model_window-4_size-40.mdl, separately None\n",
            "INFO - 12:16:30: not storing attribute vectors_norm\n",
            "INFO - 12:16:30: not storing attribute cum_table\n",
            "INFO - 12:16:30: saved w2v_model_window-4_size-40.mdl\n",
            "WARNING - 12:16:30: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:30: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:31: EPOCH 1 - PROGRESS: at 31.39% examples, 62871 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:32: EPOCH 1 - PROGRESS: at 72.83% examples, 70144 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:33: EPOCH - 1 : training on 523700 raw words (199340 effective words) took 2.7s, 73102 effective words/s\n",
            "INFO - 12:16:34: EPOCH 2 - PROGRESS: at 37.40% examples, 75040 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:35: EPOCH 2 - PROGRESS: at 78.53% examples, 76836 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:36: EPOCH - 2 : training on 523700 raw words (198691 effective words) took 2.5s, 77955 effective words/s\n",
            "INFO - 12:16:36: training on a 1047400 raw words (398031 effective words) took 5.3s, 75214 effective words/s\n",
            "INFO - 12:16:36: saving Word2Vec object under w2v_model_window-4_size-50.mdl, separately None\n",
            "INFO - 12:16:36: not storing attribute vectors_norm\n",
            "INFO - 12:16:36: not storing attribute cum_table\n",
            "INFO - 12:16:36: saved w2v_model_window-4_size-50.mdl\n",
            "WARNING - 12:16:36: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:36: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:37: EPOCH 1 - PROGRESS: at 39.38% examples, 78134 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:38: EPOCH 1 - PROGRESS: at 78.53% examples, 76544 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:38: EPOCH - 1 : training on 523700 raw words (199121 effective words) took 2.6s, 77081 effective words/s\n",
            "INFO - 12:16:39: EPOCH 2 - PROGRESS: at 33.37% examples, 67051 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:40: EPOCH 2 - PROGRESS: at 74.71% examples, 72579 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:41: EPOCH - 2 : training on 523700 raw words (199187 effective words) took 2.7s, 73962 effective words/s\n",
            "INFO - 12:16:41: training on a 1047400 raw words (398308 effective words) took 5.3s, 75226 effective words/s\n",
            "INFO - 12:16:41: saving Word2Vec object under w2v_model_window-4_size-60.mdl, separately None\n",
            "INFO - 12:16:41: not storing attribute vectors_norm\n",
            "INFO - 12:16:41: not storing attribute cum_table\n",
            "INFO - 12:16:41: saved w2v_model_window-4_size-60.mdl\n",
            "WARNING - 12:16:41: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:41: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:42: EPOCH 1 - PROGRESS: at 39.38% examples, 74863 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:43: EPOCH 1 - PROGRESS: at 80.39% examples, 75598 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:43: EPOCH - 1 : training on 523700 raw words (199027 effective words) took 2.6s, 77347 effective words/s\n",
            "INFO - 12:16:44: EPOCH 2 - PROGRESS: at 37.40% examples, 75040 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:46: EPOCH 2 - PROGRESS: at 74.71% examples, 72076 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:46: EPOCH - 2 : training on 523700 raw words (198839 effective words) took 2.7s, 74228 effective words/s\n",
            "INFO - 12:16:46: training on a 1047400 raw words (397866 effective words) took 5.3s, 75483 effective words/s\n",
            "INFO - 12:16:46: saving Word2Vec object under w2v_model_window-4_size-70.mdl, separately None\n",
            "INFO - 12:16:46: not storing attribute vectors_norm\n",
            "INFO - 12:16:46: not storing attribute cum_table\n",
            "INFO - 12:16:46: saved w2v_model_window-4_size-70.mdl\n",
            "WARNING - 12:16:46: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:46: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:47: EPOCH 1 - PROGRESS: at 39.38% examples, 76699 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:48: EPOCH 1 - PROGRESS: at 80.39% examples, 77498 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:49: EPOCH - 1 : training on 523700 raw words (199133 effective words) took 2.5s, 79230 effective words/s\n",
            "INFO - 12:16:50: EPOCH 2 - PROGRESS: at 37.40% examples, 75388 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:51: EPOCH 2 - PROGRESS: at 78.53% examples, 76877 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:51: EPOCH - 2 : training on 523700 raw words (199381 effective words) took 2.5s, 78256 effective words/s\n",
            "INFO - 12:16:51: training on a 1047400 raw words (398514 effective words) took 5.1s, 78398 effective words/s\n",
            "INFO - 12:16:51: saving Word2Vec object under w2v_model_window-4_size-80.mdl, separately None\n",
            "INFO - 12:16:51: not storing attribute vectors_norm\n",
            "INFO - 12:16:51: not storing attribute cum_table\n",
            "INFO - 12:16:51: saved w2v_model_window-4_size-80.mdl\n",
            "WARNING - 12:16:51: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:51: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:52: EPOCH 1 - PROGRESS: at 37.40% examples, 75073 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:53: EPOCH 1 - PROGRESS: at 72.83% examples, 70218 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:16:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:54: EPOCH - 1 : training on 523700 raw words (198953 effective words) took 2.7s, 73017 effective words/s\n",
            "INFO - 12:16:55: EPOCH 2 - PROGRESS: at 39.38% examples, 76770 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:56: EPOCH 2 - PROGRESS: at 80.39% examples, 78119 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:57: EPOCH - 2 : training on 523700 raw words (199363 effective words) took 2.5s, 78540 effective words/s\n",
            "INFO - 12:16:57: training on a 1047400 raw words (398316 effective words) took 5.3s, 75374 effective words/s\n",
            "INFO - 12:16:57: saving Word2Vec object under w2v_model_window-4_size-90.mdl, separately None\n",
            "INFO - 12:16:57: not storing attribute vectors_norm\n",
            "INFO - 12:16:57: not storing attribute cum_table\n",
            "INFO - 12:16:57: saved w2v_model_window-4_size-90.mdl\n",
            "WARNING - 12:16:57: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:16:57: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:16:58: EPOCH 1 - PROGRESS: at 39.38% examples, 76127 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:59: EPOCH 1 - PROGRESS: at 80.39% examples, 77360 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:16:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:16:59: EPOCH - 1 : training on 523700 raw words (199470 effective words) took 2.6s, 77730 effective words/s\n",
            "INFO - 12:17:00: EPOCH 2 - PROGRESS: at 39.38% examples, 77804 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:01: EPOCH 2 - PROGRESS: at 74.71% examples, 72821 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:02: EPOCH - 2 : training on 523700 raw words (199181 effective words) took 2.7s, 74987 effective words/s\n",
            "INFO - 12:17:02: training on a 1047400 raw words (398651 effective words) took 5.2s, 76070 effective words/s\n",
            "INFO - 12:17:02: saving Word2Vec object under w2v_model_window-4_size-100.mdl, separately None\n",
            "INFO - 12:17:02: not storing attribute vectors_norm\n",
            "INFO - 12:17:02: not storing attribute cum_table\n",
            "INFO - 12:17:02: saved w2v_model_window-4_size-100.mdl\n",
            "WARNING - 12:17:02: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:02: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:03: EPOCH 1 - PROGRESS: at 39.38% examples, 78231 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:04: EPOCH 1 - PROGRESS: at 80.39% examples, 79151 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:04: EPOCH - 1 : training on 523700 raw words (199620 effective words) took 2.5s, 79858 effective words/s\n",
            "INFO - 12:17:05: EPOCH 2 - PROGRESS: at 39.38% examples, 78082 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:06: EPOCH 2 - PROGRESS: at 80.39% examples, 78902 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:17:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:07: EPOCH - 2 : training on 523700 raw words (199213 effective words) took 2.5s, 79461 effective words/s\n",
            "INFO - 12:17:07: training on a 1047400 raw words (398833 effective words) took 5.0s, 79329 effective words/s\n",
            "INFO - 12:17:07: saving Word2Vec object under w2v_model_window-4_size-200.mdl, separately None\n",
            "INFO - 12:17:07: not storing attribute vectors_norm\n",
            "INFO - 12:17:07: not storing attribute cum_table\n",
            "INFO - 12:17:07: saved w2v_model_window-4_size-200.mdl\n",
            "WARNING - 12:17:07: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:07: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:08: EPOCH 1 - PROGRESS: at 39.38% examples, 68848 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:09: EPOCH 1 - PROGRESS: at 80.39% examples, 73589 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:17:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:10: EPOCH - 1 : training on 523700 raw words (199360 effective words) took 2.6s, 75323 effective words/s\n",
            "INFO - 12:17:11: EPOCH 2 - PROGRESS: at 39.38% examples, 77865 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:12: EPOCH 2 - PROGRESS: at 82.28% examples, 79303 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:12: EPOCH - 2 : training on 523700 raw words (199406 effective words) took 2.5s, 80287 effective words/s\n",
            "INFO - 12:17:12: training on a 1047400 raw words (398766 effective words) took 5.2s, 77419 effective words/s\n",
            "INFO - 12:17:12: saving Word2Vec object under w2v_model_window-4_size-300.mdl, separately None\n",
            "INFO - 12:17:12: not storing attribute vectors_norm\n",
            "INFO - 12:17:12: not storing attribute cum_table\n",
            "INFO - 12:17:12: saved w2v_model_window-4_size-300.mdl\n",
            "WARNING - 12:17:12: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:12: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:13: EPOCH 1 - PROGRESS: at 39.38% examples, 78298 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:14: EPOCH 1 - PROGRESS: at 82.28% examples, 78677 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:15: EPOCH - 1 : training on 523700 raw words (199211 effective words) took 2.5s, 79509 effective words/s\n",
            "INFO - 12:17:16: EPOCH 2 - PROGRESS: at 33.37% examples, 65695 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:17: EPOCH 2 - PROGRESS: at 76.60% examples, 72583 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:17: EPOCH - 2 : training on 523700 raw words (198960 effective words) took 2.7s, 75028 effective words/s\n",
            "INFO - 12:17:17: training on a 1047400 raw words (398171 effective words) took 5.2s, 76837 effective words/s\n",
            "INFO - 12:17:17: saving Word2Vec object under w2v_model_window-4_size-400.mdl, separately None\n",
            "INFO - 12:17:17: not storing attribute vectors_norm\n",
            "INFO - 12:17:17: not storing attribute cum_table\n",
            "INFO - 12:17:17: saved w2v_model_window-4_size-400.mdl\n",
            "WARNING - 12:17:17: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:17: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:18: EPOCH 1 - PROGRESS: at 39.38% examples, 78259 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:19: EPOCH 1 - PROGRESS: at 80.39% examples, 78698 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:20: EPOCH - 1 : training on 523700 raw words (199523 effective words) took 2.5s, 78932 effective words/s\n",
            "INFO - 12:17:21: EPOCH 2 - PROGRESS: at 39.38% examples, 77357 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:22: EPOCH 2 - PROGRESS: at 82.28% examples, 78751 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:22: EPOCH - 2 : training on 523700 raw words (199005 effective words) took 2.5s, 79174 effective words/s\n",
            "INFO - 12:17:22: training on a 1047400 raw words (398528 effective words) took 5.1s, 78836 effective words/s\n",
            "INFO - 12:17:22: saving Word2Vec object under w2v_model_window-4_size-500.mdl, separately None\n",
            "INFO - 12:17:22: not storing attribute vectors_norm\n",
            "INFO - 12:17:22: not storing attribute cum_table\n",
            "INFO - 12:17:23: saved w2v_model_window-4_size-500.mdl\n",
            "WARNING - 12:17:23: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:23: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:24: EPOCH 1 - PROGRESS: at 33.37% examples, 66292 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:25: EPOCH 1 - PROGRESS: at 74.71% examples, 72548 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:25: EPOCH - 1 : training on 523700 raw words (198920 effective words) took 2.7s, 74861 effective words/s\n",
            "INFO - 12:17:26: EPOCH 2 - PROGRESS: at 39.38% examples, 77086 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:27: EPOCH 2 - PROGRESS: at 82.28% examples, 78509 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:17:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:28: EPOCH - 2 : training on 523700 raw words (199045 effective words) took 2.5s, 79798 effective words/s\n",
            "INFO - 12:17:28: training on a 1047400 raw words (397965 effective words) took 5.2s, 76988 effective words/s\n",
            "INFO - 12:17:28: saving Word2Vec object under w2v_model_window-5_size-10.mdl, separately None\n",
            "INFO - 12:17:28: not storing attribute vectors_norm\n",
            "INFO - 12:17:28: not storing attribute cum_table\n",
            "INFO - 12:17:28: saved w2v_model_window-5_size-10.mdl\n",
            "WARNING - 12:17:28: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:28: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:29: EPOCH 1 - PROGRESS: at 39.38% examples, 78336 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:30: EPOCH 1 - PROGRESS: at 80.39% examples, 78348 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:30: EPOCH - 1 : training on 523700 raw words (198897 effective words) took 2.5s, 78625 effective words/s\n",
            "INFO - 12:17:31: EPOCH 2 - PROGRESS: at 33.37% examples, 68068 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:32: EPOCH 2 - PROGRESS: at 74.71% examples, 73276 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:33: EPOCH - 2 : training on 523700 raw words (199124 effective words) took 2.6s, 75568 effective words/s\n",
            "INFO - 12:17:33: training on a 1047400 raw words (398021 effective words) took 5.2s, 76672 effective words/s\n",
            "INFO - 12:17:33: saving Word2Vec object under w2v_model_window-5_size-20.mdl, separately None\n",
            "INFO - 12:17:33: not storing attribute vectors_norm\n",
            "INFO - 12:17:33: not storing attribute cum_table\n",
            "INFO - 12:17:33: saved w2v_model_window-5_size-20.mdl\n",
            "WARNING - 12:17:33: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:33: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:34: EPOCH 1 - PROGRESS: at 39.38% examples, 77528 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:35: EPOCH 1 - PROGRESS: at 80.39% examples, 78335 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:35: EPOCH - 1 : training on 523700 raw words (199169 effective words) took 2.5s, 78718 effective words/s\n",
            "INFO - 12:17:37: EPOCH 2 - PROGRESS: at 39.38% examples, 77254 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:38: EPOCH 2 - PROGRESS: at 82.28% examples, 78500 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:38: EPOCH - 2 : training on 523700 raw words (199270 effective words) took 2.6s, 76009 effective words/s\n",
            "INFO - 12:17:38: training on a 1047400 raw words (398439 effective words) took 5.2s, 77011 effective words/s\n",
            "INFO - 12:17:38: saving Word2Vec object under w2v_model_window-5_size-30.mdl, separately None\n",
            "INFO - 12:17:38: not storing attribute vectors_norm\n",
            "INFO - 12:17:38: not storing attribute cum_table\n",
            "INFO - 12:17:38: saved w2v_model_window-5_size-30.mdl\n",
            "WARNING - 12:17:38: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:38: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:39: EPOCH 1 - PROGRESS: at 39.38% examples, 77481 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:40: EPOCH 1 - PROGRESS: at 80.39% examples, 78272 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:41: EPOCH - 1 : training on 523700 raw words (199148 effective words) took 2.5s, 79245 effective words/s\n",
            "INFO - 12:17:42: EPOCH 2 - PROGRESS: at 39.38% examples, 78284 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:43: EPOCH 2 - PROGRESS: at 82.28% examples, 78992 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:43: EPOCH - 2 : training on 523700 raw words (199553 effective words) took 2.5s, 79390 effective words/s\n",
            "INFO - 12:17:43: training on a 1047400 raw words (398701 effective words) took 5.0s, 79048 effective words/s\n",
            "INFO - 12:17:43: saving Word2Vec object under w2v_model_window-5_size-40.mdl, separately None\n",
            "INFO - 12:17:43: not storing attribute vectors_norm\n",
            "INFO - 12:17:43: not storing attribute cum_table\n",
            "INFO - 12:17:43: saved w2v_model_window-5_size-40.mdl\n",
            "WARNING - 12:17:43: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:43: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:44: EPOCH 1 - PROGRESS: at 39.38% examples, 78328 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:45: EPOCH 1 - PROGRESS: at 76.60% examples, 73828 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:46: EPOCH - 1 : training on 523700 raw words (199391 effective words) took 2.6s, 75449 effective words/s\n",
            "INFO - 12:17:47: EPOCH 2 - PROGRESS: at 39.38% examples, 78896 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:48: EPOCH 2 - PROGRESS: at 80.39% examples, 79509 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:48: EPOCH - 2 : training on 523700 raw words (199151 effective words) took 2.5s, 79583 effective words/s\n",
            "INFO - 12:17:48: training on a 1047400 raw words (398542 effective words) took 5.2s, 77175 effective words/s\n",
            "INFO - 12:17:48: saving Word2Vec object under w2v_model_window-5_size-50.mdl, separately None\n",
            "INFO - 12:17:48: not storing attribute vectors_norm\n",
            "INFO - 12:17:48: not storing attribute cum_table\n",
            "INFO - 12:17:48: saved w2v_model_window-5_size-50.mdl\n",
            "WARNING - 12:17:48: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:48: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:49: EPOCH 1 - PROGRESS: at 37.40% examples, 73298 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:51: EPOCH 1 - PROGRESS: at 78.53% examples, 75100 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:51: EPOCH - 1 : training on 523700 raw words (199175 effective words) took 2.6s, 76476 effective words/s\n",
            "INFO - 12:17:52: EPOCH 2 - PROGRESS: at 39.38% examples, 75014 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:17:53: EPOCH 2 - PROGRESS: at 76.60% examples, 71586 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:54: EPOCH - 2 : training on 523700 raw words (198765 effective words) took 2.7s, 73425 effective words/s\n",
            "INFO - 12:17:54: training on a 1047400 raw words (397940 effective words) took 5.3s, 74671 effective words/s\n",
            "INFO - 12:17:54: saving Word2Vec object under w2v_model_window-5_size-60.mdl, separately None\n",
            "INFO - 12:17:54: not storing attribute vectors_norm\n",
            "INFO - 12:17:54: not storing attribute cum_table\n",
            "INFO - 12:17:54: saved w2v_model_window-5_size-60.mdl\n",
            "WARNING - 12:17:54: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:54: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:17:55: EPOCH 1 - PROGRESS: at 39.38% examples, 77401 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:56: EPOCH 1 - PROGRESS: at 80.39% examples, 77671 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:56: EPOCH - 1 : training on 523700 raw words (198780 effective words) took 2.5s, 79314 effective words/s\n",
            "INFO - 12:17:57: EPOCH 2 - PROGRESS: at 39.38% examples, 78455 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:58: EPOCH 2 - PROGRESS: at 82.28% examples, 79891 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:17:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:17:59: EPOCH - 2 : training on 523700 raw words (199063 effective words) took 2.5s, 80002 effective words/s\n",
            "INFO - 12:17:59: training on a 1047400 raw words (397843 effective words) took 5.0s, 79321 effective words/s\n",
            "INFO - 12:17:59: saving Word2Vec object under w2v_model_window-5_size-70.mdl, separately None\n",
            "INFO - 12:17:59: not storing attribute vectors_norm\n",
            "INFO - 12:17:59: not storing attribute cum_table\n",
            "INFO - 12:17:59: saved w2v_model_window-5_size-70.mdl\n",
            "WARNING - 12:17:59: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:17:59: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:00: EPOCH 1 - PROGRESS: at 39.38% examples, 77113 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:01: EPOCH 1 - PROGRESS: at 74.71% examples, 72557 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:02: EPOCH - 1 : training on 523700 raw words (198740 effective words) took 2.7s, 74459 effective words/s\n",
            "INFO - 12:18:03: EPOCH 2 - PROGRESS: at 39.38% examples, 77980 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:04: EPOCH 2 - PROGRESS: at 80.39% examples, 77285 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:04: EPOCH - 2 : training on 523700 raw words (199581 effective words) took 2.6s, 75417 effective words/s\n",
            "INFO - 12:18:04: training on a 1047400 raw words (398321 effective words) took 5.3s, 74613 effective words/s\n",
            "INFO - 12:18:04: saving Word2Vec object under w2v_model_window-5_size-80.mdl, separately None\n",
            "INFO - 12:18:04: not storing attribute vectors_norm\n",
            "INFO - 12:18:04: not storing attribute cum_table\n",
            "INFO - 12:18:04: saved w2v_model_window-5_size-80.mdl\n",
            "WARNING - 12:18:04: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:04: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:05: EPOCH 1 - PROGRESS: at 37.40% examples, 74502 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:06: EPOCH 1 - PROGRESS: at 78.53% examples, 76039 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:07: EPOCH - 1 : training on 523700 raw words (199067 effective words) took 2.6s, 76814 effective words/s\n",
            "INFO - 12:18:08: EPOCH 2 - PROGRESS: at 39.38% examples, 76979 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:09: EPOCH 2 - PROGRESS: at 74.71% examples, 72019 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:10: EPOCH - 2 : training on 523700 raw words (199277 effective words) took 2.7s, 73475 effective words/s\n",
            "INFO - 12:18:10: training on a 1047400 raw words (398344 effective words) took 5.3s, 74826 effective words/s\n",
            "INFO - 12:18:10: saving Word2Vec object under w2v_model_window-5_size-90.mdl, separately None\n",
            "INFO - 12:18:10: not storing attribute vectors_norm\n",
            "INFO - 12:18:10: not storing attribute cum_table\n",
            "INFO - 12:18:10: saved w2v_model_window-5_size-90.mdl\n",
            "WARNING - 12:18:10: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:10: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:11: EPOCH 1 - PROGRESS: at 39.38% examples, 74425 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:12: EPOCH 1 - PROGRESS: at 80.39% examples, 76520 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:12: EPOCH - 1 : training on 523700 raw words (199026 effective words) took 2.6s, 77502 effective words/s\n",
            "INFO - 12:18:13: EPOCH 2 - PROGRESS: at 39.38% examples, 78057 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:14: EPOCH 2 - PROGRESS: at 80.39% examples, 77902 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:18:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:15: EPOCH - 2 : training on 523700 raw words (199458 effective words) took 2.6s, 77378 effective words/s\n",
            "INFO - 12:18:15: training on a 1047400 raw words (398484 effective words) took 5.2s, 77170 effective words/s\n",
            "INFO - 12:18:15: saving Word2Vec object under w2v_model_window-5_size-100.mdl, separately None\n",
            "INFO - 12:18:15: not storing attribute vectors_norm\n",
            "INFO - 12:18:15: not storing attribute cum_table\n",
            "INFO - 12:18:15: saved w2v_model_window-5_size-100.mdl\n",
            "WARNING - 12:18:15: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:15: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:16: EPOCH 1 - PROGRESS: at 37.40% examples, 74212 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:17: EPOCH 1 - PROGRESS: at 72.83% examples, 69912 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:18:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:18: EPOCH - 1 : training on 523700 raw words (198992 effective words) took 2.7s, 72631 effective words/s\n",
            "INFO - 12:18:19: EPOCH 2 - PROGRESS: at 37.40% examples, 74853 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:20: EPOCH 2 - PROGRESS: at 76.60% examples, 75641 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:20: EPOCH - 2 : training on 523700 raw words (198957 effective words) took 2.6s, 76235 effective words/s\n",
            "INFO - 12:18:20: training on a 1047400 raw words (397949 effective words) took 5.4s, 74031 effective words/s\n",
            "INFO - 12:18:20: saving Word2Vec object under w2v_model_window-5_size-200.mdl, separately None\n",
            "INFO - 12:18:20: not storing attribute vectors_norm\n",
            "INFO - 12:18:20: not storing attribute cum_table\n",
            "INFO - 12:18:20: saved w2v_model_window-5_size-200.mdl\n",
            "WARNING - 12:18:20: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:20: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:21: EPOCH 1 - PROGRESS: at 37.40% examples, 74126 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:22: EPOCH 1 - PROGRESS: at 76.60% examples, 74660 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:18:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:23: EPOCH - 1 : training on 523700 raw words (199227 effective words) took 2.6s, 76257 effective words/s\n",
            "INFO - 12:18:24: EPOCH 2 - PROGRESS: at 35.34% examples, 63164 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:25: EPOCH 2 - PROGRESS: at 74.71% examples, 69008 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:26: EPOCH - 2 : training on 523700 raw words (199072 effective words) took 2.8s, 71106 effective words/s\n",
            "INFO - 12:18:26: training on a 1047400 raw words (398299 effective words) took 5.5s, 73040 effective words/s\n",
            "INFO - 12:18:26: saving Word2Vec object under w2v_model_window-5_size-300.mdl, separately None\n",
            "INFO - 12:18:26: not storing attribute vectors_norm\n",
            "INFO - 12:18:26: not storing attribute cum_table\n",
            "INFO - 12:18:26: saved w2v_model_window-5_size-300.mdl\n",
            "WARNING - 12:18:26: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:26: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:27: EPOCH 1 - PROGRESS: at 37.40% examples, 72772 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:28: EPOCH 1 - PROGRESS: at 76.60% examples, 74486 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:28: EPOCH - 1 : training on 523700 raw words (198975 effective words) took 2.6s, 75292 effective words/s\n",
            "INFO - 12:18:29: EPOCH 2 - PROGRESS: at 37.40% examples, 72360 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:30: EPOCH 2 - PROGRESS: at 76.60% examples, 73586 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:31: EPOCH - 2 : training on 523700 raw words (198893 effective words) took 2.7s, 73675 effective words/s\n",
            "INFO - 12:18:31: training on a 1047400 raw words (397868 effective words) took 5.4s, 74140 effective words/s\n",
            "INFO - 12:18:31: saving Word2Vec object under w2v_model_window-5_size-400.mdl, separately None\n",
            "INFO - 12:18:31: not storing attribute vectors_norm\n",
            "INFO - 12:18:31: not storing attribute cum_table\n",
            "INFO - 12:18:31: saved w2v_model_window-5_size-400.mdl\n",
            "WARNING - 12:18:31: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:31: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:32: EPOCH 1 - PROGRESS: at 31.39% examples, 63955 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:33: EPOCH 1 - PROGRESS: at 72.83% examples, 71001 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:34: EPOCH - 1 : training on 523700 raw words (199699 effective words) took 2.7s, 73655 effective words/s\n",
            "INFO - 12:18:35: EPOCH 2 - PROGRESS: at 37.40% examples, 74518 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:36: EPOCH 2 - PROGRESS: at 76.60% examples, 74379 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:36: EPOCH - 2 : training on 523700 raw words (199150 effective words) took 2.6s, 75369 effective words/s\n",
            "INFO - 12:18:36: training on a 1047400 raw words (398849 effective words) took 5.4s, 74274 effective words/s\n",
            "INFO - 12:18:36: saving Word2Vec object under w2v_model_window-5_size-500.mdl, separately None\n",
            "INFO - 12:18:36: not storing attribute vectors_norm\n",
            "INFO - 12:18:36: not storing attribute cum_table\n",
            "INFO - 12:18:37: saved w2v_model_window-5_size-500.mdl\n",
            "WARNING - 12:18:37: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:37: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:38: EPOCH 1 - PROGRESS: at 37.40% examples, 73674 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:39: EPOCH 1 - PROGRESS: at 78.53% examples, 76454 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:39: EPOCH - 1 : training on 523700 raw words (199217 effective words) took 2.6s, 77624 effective words/s\n",
            "INFO - 12:18:40: EPOCH 2 - PROGRESS: at 33.37% examples, 65100 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:41: EPOCH 2 - PROGRESS: at 72.83% examples, 70530 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:42: EPOCH - 2 : training on 523700 raw words (199017 effective words) took 2.7s, 72543 effective words/s\n",
            "INFO - 12:18:42: training on a 1047400 raw words (398234 effective words) took 5.3s, 74763 effective words/s\n",
            "INFO - 12:18:42: saving Word2Vec object under w2v_model_window-6_size-10.mdl, separately None\n",
            "INFO - 12:18:42: not storing attribute vectors_norm\n",
            "INFO - 12:18:42: not storing attribute cum_table\n",
            "INFO - 12:18:42: saved w2v_model_window-6_size-10.mdl\n",
            "WARNING - 12:18:42: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:42: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:43: EPOCH 1 - PROGRESS: at 39.38% examples, 77125 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:44: EPOCH 1 - PROGRESS: at 82.28% examples, 78851 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:44: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:44: EPOCH - 1 : training on 523700 raw words (199212 effective words) took 2.5s, 79517 effective words/s\n",
            "INFO - 12:18:45: EPOCH 2 - PROGRESS: at 39.38% examples, 77575 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:46: EPOCH 2 - PROGRESS: at 80.39% examples, 78202 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:47: EPOCH - 2 : training on 523700 raw words (198886 effective words) took 2.5s, 79448 effective words/s\n",
            "INFO - 12:18:47: training on a 1047400 raw words (398098 effective words) took 5.0s, 79171 effective words/s\n",
            "INFO - 12:18:47: saving Word2Vec object under w2v_model_window-6_size-20.mdl, separately None\n",
            "INFO - 12:18:47: not storing attribute vectors_norm\n",
            "INFO - 12:18:47: not storing attribute cum_table\n",
            "INFO - 12:18:47: saved w2v_model_window-6_size-20.mdl\n",
            "WARNING - 12:18:47: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:47: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:48: EPOCH 1 - PROGRESS: at 33.37% examples, 66970 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:49: EPOCH 1 - PROGRESS: at 74.71% examples, 73340 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:50: EPOCH - 1 : training on 523700 raw words (199233 effective words) took 2.6s, 75345 effective words/s\n",
            "INFO - 12:18:51: EPOCH 2 - PROGRESS: at 39.38% examples, 77321 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:52: EPOCH 2 - PROGRESS: at 80.39% examples, 78649 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:52: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:52: EPOCH - 2 : training on 523700 raw words (199451 effective words) took 2.5s, 79245 effective words/s\n",
            "INFO - 12:18:52: training on a 1047400 raw words (398684 effective words) took 5.2s, 77018 effective words/s\n",
            "INFO - 12:18:52: saving Word2Vec object under w2v_model_window-6_size-30.mdl, separately None\n",
            "INFO - 12:18:52: not storing attribute vectors_norm\n",
            "INFO - 12:18:52: not storing attribute cum_table\n",
            "INFO - 12:18:52: saved w2v_model_window-6_size-30.mdl\n",
            "WARNING - 12:18:52: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:52: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:53: EPOCH 1 - PROGRESS: at 39.38% examples, 78216 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:54: EPOCH 1 - PROGRESS: at 82.28% examples, 80190 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:55: EPOCH - 1 : training on 523700 raw words (199284 effective words) took 2.5s, 80016 effective words/s\n",
            "INFO - 12:18:56: EPOCH 2 - PROGRESS: at 33.37% examples, 67405 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:57: EPOCH 2 - PROGRESS: at 74.71% examples, 73145 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:18:57: EPOCH - 2 : training on 523700 raw words (198990 effective words) took 2.6s, 75506 effective words/s\n",
            "INFO - 12:18:57: training on a 1047400 raw words (398274 effective words) took 5.2s, 77224 effective words/s\n",
            "INFO - 12:18:57: saving Word2Vec object under w2v_model_window-6_size-40.mdl, separately None\n",
            "INFO - 12:18:57: not storing attribute vectors_norm\n",
            "INFO - 12:18:57: not storing attribute cum_table\n",
            "INFO - 12:18:57: saved w2v_model_window-6_size-40.mdl\n",
            "WARNING - 12:18:57: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:18:57: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:18:58: EPOCH 1 - PROGRESS: at 39.38% examples, 77730 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:18:59: EPOCH 1 - PROGRESS: at 80.39% examples, 78361 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:00: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:00: EPOCH - 1 : training on 523700 raw words (199193 effective words) took 2.5s, 79106 effective words/s\n",
            "INFO - 12:19:01: EPOCH 2 - PROGRESS: at 39.38% examples, 79119 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:02: EPOCH 2 - PROGRESS: at 80.39% examples, 78465 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:02: EPOCH - 2 : training on 523700 raw words (199521 effective words) took 2.5s, 79413 effective words/s\n",
            "INFO - 12:19:02: training on a 1047400 raw words (398714 effective words) took 5.1s, 78939 effective words/s\n",
            "INFO - 12:19:02: saving Word2Vec object under w2v_model_window-6_size-50.mdl, separately None\n",
            "INFO - 12:19:02: not storing attribute vectors_norm\n",
            "INFO - 12:19:02: not storing attribute cum_table\n",
            "INFO - 12:19:02: saved w2v_model_window-6_size-50.mdl\n",
            "WARNING - 12:19:02: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:02: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:03: EPOCH 1 - PROGRESS: at 33.37% examples, 66548 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:04: EPOCH 1 - PROGRESS: at 74.71% examples, 73417 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:05: EPOCH - 1 : training on 523700 raw words (199250 effective words) took 2.6s, 75368 effective words/s\n",
            "INFO - 12:19:06: EPOCH 2 - PROGRESS: at 39.38% examples, 76388 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:07: EPOCH 2 - PROGRESS: at 82.28% examples, 78954 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:08: EPOCH - 2 : training on 523700 raw words (199396 effective words) took 2.5s, 79890 effective words/s\n",
            "INFO - 12:19:08: training on a 1047400 raw words (398646 effective words) took 5.2s, 77263 effective words/s\n",
            "INFO - 12:19:08: saving Word2Vec object under w2v_model_window-6_size-60.mdl, separately None\n",
            "INFO - 12:19:08: not storing attribute vectors_norm\n",
            "INFO - 12:19:08: not storing attribute cum_table\n",
            "INFO - 12:19:08: saved w2v_model_window-6_size-60.mdl\n",
            "WARNING - 12:19:08: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:08: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:09: EPOCH 1 - PROGRESS: at 39.38% examples, 77474 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:10: EPOCH 1 - PROGRESS: at 80.39% examples, 77867 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:10: EPOCH - 1 : training on 523700 raw words (199258 effective words) took 2.7s, 75066 effective words/s\n",
            "INFO - 12:19:11: EPOCH 2 - PROGRESS: at 39.38% examples, 79271 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:12: EPOCH 2 - PROGRESS: at 80.39% examples, 79299 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:13: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:13: EPOCH - 2 : training on 523700 raw words (198845 effective words) took 2.5s, 79728 effective words/s\n",
            "INFO - 12:19:13: training on a 1047400 raw words (398103 effective words) took 5.2s, 77016 effective words/s\n",
            "INFO - 12:19:13: saving Word2Vec object under w2v_model_window-6_size-70.mdl, separately None\n",
            "INFO - 12:19:13: not storing attribute vectors_norm\n",
            "INFO - 12:19:13: not storing attribute cum_table\n",
            "INFO - 12:19:13: saved w2v_model_window-6_size-70.mdl\n",
            "WARNING - 12:19:13: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:13: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:14: EPOCH 1 - PROGRESS: at 39.38% examples, 78924 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:15: EPOCH 1 - PROGRESS: at 80.39% examples, 78590 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:15: EPOCH - 1 : training on 523700 raw words (199152 effective words) took 2.5s, 79504 effective words/s\n",
            "INFO - 12:19:16: EPOCH 2 - PROGRESS: at 39.38% examples, 76905 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:17: EPOCH 2 - PROGRESS: at 82.28% examples, 79329 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:18: EPOCH - 2 : training on 523700 raw words (199134 effective words) took 2.6s, 75365 effective words/s\n",
            "INFO - 12:19:18: training on a 1047400 raw words (398286 effective words) took 5.2s, 77074 effective words/s\n",
            "INFO - 12:19:18: saving Word2Vec object under w2v_model_window-6_size-80.mdl, separately None\n",
            "INFO - 12:19:18: not storing attribute vectors_norm\n",
            "INFO - 12:19:18: not storing attribute cum_table\n",
            "INFO - 12:19:18: saved w2v_model_window-6_size-80.mdl\n",
            "WARNING - 12:19:18: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:18: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:19: EPOCH 1 - PROGRESS: at 39.38% examples, 77245 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:20: EPOCH 1 - PROGRESS: at 80.39% examples, 78641 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:21: EPOCH - 1 : training on 523700 raw words (199375 effective words) took 2.5s, 79822 effective words/s\n",
            "INFO - 12:19:22: EPOCH 2 - PROGRESS: at 39.38% examples, 78544 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:23: EPOCH 2 - PROGRESS: at 80.39% examples, 78016 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:23: EPOCH - 2 : training on 523700 raw words (199175 effective words) took 2.5s, 78498 effective words/s\n",
            "INFO - 12:19:23: training on a 1047400 raw words (398550 effective words) took 5.0s, 78924 effective words/s\n",
            "INFO - 12:19:23: saving Word2Vec object under w2v_model_window-6_size-90.mdl, separately None\n",
            "INFO - 12:19:23: not storing attribute vectors_norm\n",
            "INFO - 12:19:23: not storing attribute cum_table\n",
            "INFO - 12:19:23: saved w2v_model_window-6_size-90.mdl\n",
            "WARNING - 12:19:23: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:23: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:24: EPOCH 1 - PROGRESS: at 37.40% examples, 72651 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:25: EPOCH 1 - PROGRESS: at 76.60% examples, 74241 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:26: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:26: EPOCH - 1 : training on 523700 raw words (199066 effective words) took 2.8s, 72028 effective words/s\n",
            "INFO - 12:19:27: EPOCH 2 - PROGRESS: at 39.38% examples, 75872 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:28: EPOCH 2 - PROGRESS: at 80.39% examples, 77755 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:28: EPOCH - 2 : training on 523700 raw words (199225 effective words) took 2.5s, 78622 effective words/s\n",
            "INFO - 12:19:28: training on a 1047400 raw words (398291 effective words) took 5.3s, 74893 effective words/s\n",
            "INFO - 12:19:28: saving Word2Vec object under w2v_model_window-6_size-100.mdl, separately None\n",
            "INFO - 12:19:28: not storing attribute vectors_norm\n",
            "INFO - 12:19:28: not storing attribute cum_table\n",
            "INFO - 12:19:28: saved w2v_model_window-6_size-100.mdl\n",
            "WARNING - 12:19:28: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:28: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:30: EPOCH 1 - PROGRESS: at 39.38% examples, 77608 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:31: EPOCH 1 - PROGRESS: at 80.39% examples, 78196 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:31: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:31: EPOCH - 1 : training on 523700 raw words (199240 effective words) took 2.5s, 79129 effective words/s\n",
            "INFO - 12:19:32: EPOCH 2 - PROGRESS: at 39.38% examples, 75995 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:33: EPOCH 2 - PROGRESS: at 76.60% examples, 73367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:34: EPOCH - 2 : training on 523700 raw words (199631 effective words) took 2.7s, 75127 effective words/s\n",
            "INFO - 12:19:34: training on a 1047400 raw words (398871 effective words) took 5.2s, 76765 effective words/s\n",
            "INFO - 12:19:34: saving Word2Vec object under w2v_model_window-6_size-200.mdl, separately None\n",
            "INFO - 12:19:34: not storing attribute vectors_norm\n",
            "INFO - 12:19:34: not storing attribute cum_table\n",
            "INFO - 12:19:34: saved w2v_model_window-6_size-200.mdl\n",
            "WARNING - 12:19:34: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:34: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:35: EPOCH 1 - PROGRESS: at 39.38% examples, 78476 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:36: EPOCH 1 - PROGRESS: at 80.39% examples, 78249 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:36: EPOCH - 1 : training on 523700 raw words (198869 effective words) took 2.5s, 78864 effective words/s\n",
            "INFO - 12:19:37: EPOCH 2 - PROGRESS: at 39.38% examples, 78919 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:38: EPOCH 2 - PROGRESS: at 80.39% examples, 79145 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:39: EPOCH - 2 : training on 523700 raw words (199493 effective words) took 2.5s, 80007 effective words/s\n",
            "INFO - 12:19:39: training on a 1047400 raw words (398362 effective words) took 5.0s, 79145 effective words/s\n",
            "INFO - 12:19:39: saving Word2Vec object under w2v_model_window-6_size-300.mdl, separately None\n",
            "INFO - 12:19:39: not storing attribute vectors_norm\n",
            "INFO - 12:19:39: not storing attribute cum_table\n",
            "INFO - 12:19:39: saved w2v_model_window-6_size-300.mdl\n",
            "WARNING - 12:19:39: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:39: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:40: EPOCH 1 - PROGRESS: at 39.38% examples, 76838 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:41: EPOCH 1 - PROGRESS: at 76.60% examples, 73213 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:41: EPOCH - 1 : training on 523700 raw words (199038 effective words) took 2.6s, 75407 effective words/s\n",
            "INFO - 12:19:42: EPOCH 2 - PROGRESS: at 39.38% examples, 78894 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:43: EPOCH 2 - PROGRESS: at 80.39% examples, 79053 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:44: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:44: EPOCH - 2 : training on 523700 raw words (199116 effective words) took 2.5s, 80130 effective words/s\n",
            "INFO - 12:19:44: training on a 1047400 raw words (398154 effective words) took 5.1s, 77398 effective words/s\n",
            "INFO - 12:19:44: saving Word2Vec object under w2v_model_window-6_size-400.mdl, separately None\n",
            "INFO - 12:19:44: not storing attribute vectors_norm\n",
            "INFO - 12:19:44: not storing attribute cum_table\n",
            "INFO - 12:19:44: saved w2v_model_window-6_size-400.mdl\n",
            "WARNING - 12:19:44: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:44: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:45: EPOCH 1 - PROGRESS: at 39.38% examples, 77364 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:46: EPOCH 1 - PROGRESS: at 80.39% examples, 77486 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:47: EPOCH - 1 : training on 523700 raw words (198883 effective words) took 2.5s, 78575 effective words/s\n",
            "INFO - 12:19:48: EPOCH 2 - PROGRESS: at 39.38% examples, 75254 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:49: EPOCH 2 - PROGRESS: at 76.60% examples, 71956 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:19:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:49: EPOCH - 2 : training on 523700 raw words (198902 effective words) took 2.7s, 74618 effective words/s\n",
            "INFO - 12:19:49: training on a 1047400 raw words (397785 effective words) took 5.2s, 76136 effective words/s\n",
            "INFO - 12:19:49: saving Word2Vec object under w2v_model_window-6_size-500.mdl, separately None\n",
            "INFO - 12:19:49: not storing attribute vectors_norm\n",
            "INFO - 12:19:49: not storing attribute cum_table\n",
            "INFO - 12:19:49: saved w2v_model_window-6_size-500.mdl\n",
            "WARNING - 12:19:49: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:49: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:50: EPOCH 1 - PROGRESS: at 39.38% examples, 79079 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:51: EPOCH 1 - PROGRESS: at 80.39% examples, 79223 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:52: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:52: EPOCH - 1 : training on 523700 raw words (199024 effective words) took 2.5s, 80020 effective words/s\n",
            "INFO - 12:19:53: EPOCH 2 - PROGRESS: at 39.38% examples, 78379 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:54: EPOCH 2 - PROGRESS: at 82.28% examples, 79644 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:54: EPOCH - 2 : training on 523700 raw words (198733 effective words) took 2.5s, 80403 effective words/s\n",
            "INFO - 12:19:54: training on a 1047400 raw words (397757 effective words) took 5.0s, 79768 effective words/s\n",
            "INFO - 12:19:54: saving Word2Vec object under w2v_model_window-7_size-10.mdl, separately None\n",
            "INFO - 12:19:54: not storing attribute vectors_norm\n",
            "INFO - 12:19:54: not storing attribute cum_table\n",
            "INFO - 12:19:54: saved w2v_model_window-7_size-10.mdl\n",
            "WARNING - 12:19:54: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:54: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:19:55: EPOCH 1 - PROGRESS: at 39.38% examples, 77253 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:56: EPOCH 1 - PROGRESS: at 76.60% examples, 73135 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:57: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:57: EPOCH - 1 : training on 523700 raw words (198950 effective words) took 2.6s, 75140 effective words/s\n",
            "INFO - 12:19:58: EPOCH 2 - PROGRESS: at 39.38% examples, 77839 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:59: EPOCH 2 - PROGRESS: at 80.39% examples, 78959 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:19:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:19:59: EPOCH - 2 : training on 523700 raw words (198915 effective words) took 2.5s, 79038 effective words/s\n",
            "INFO - 12:19:59: training on a 1047400 raw words (397865 effective words) took 5.2s, 76670 effective words/s\n",
            "INFO - 12:19:59: saving Word2Vec object under w2v_model_window-7_size-20.mdl, separately None\n",
            "INFO - 12:19:59: not storing attribute vectors_norm\n",
            "INFO - 12:19:59: not storing attribute cum_table\n",
            "INFO - 12:19:59: saved w2v_model_window-7_size-20.mdl\n",
            "WARNING - 12:19:59: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:19:59: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:01: EPOCH 1 - PROGRESS: at 39.38% examples, 76809 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:02: EPOCH 1 - PROGRESS: at 80.39% examples, 77621 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:02: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:02: EPOCH - 1 : training on 523700 raw words (199079 effective words) took 2.6s, 77683 effective words/s\n",
            "INFO - 12:20:03: EPOCH 2 - PROGRESS: at 33.37% examples, 67457 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:04: EPOCH 2 - PROGRESS: at 74.71% examples, 73772 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:05: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:05: EPOCH - 2 : training on 523700 raw words (198684 effective words) took 2.6s, 75349 effective words/s\n",
            "INFO - 12:20:05: training on a 1047400 raw words (397763 effective words) took 5.2s, 76190 effective words/s\n",
            "INFO - 12:20:05: saving Word2Vec object under w2v_model_window-7_size-30.mdl, separately None\n",
            "INFO - 12:20:05: not storing attribute vectors_norm\n",
            "INFO - 12:20:05: not storing attribute cum_table\n",
            "INFO - 12:20:05: saved w2v_model_window-7_size-30.mdl\n",
            "WARNING - 12:20:05: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:05: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:06: EPOCH 1 - PROGRESS: at 39.38% examples, 77367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:07: EPOCH 1 - PROGRESS: at 80.39% examples, 78529 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:07: EPOCH - 1 : training on 523700 raw words (198948 effective words) took 2.5s, 79768 effective words/s\n",
            "INFO - 12:20:08: EPOCH 2 - PROGRESS: at 39.38% examples, 78721 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:09: EPOCH 2 - PROGRESS: at 82.28% examples, 79280 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:10: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:10: EPOCH - 2 : training on 523700 raw words (199012 effective words) took 2.5s, 79378 effective words/s\n",
            "INFO - 12:20:10: training on a 1047400 raw words (397960 effective words) took 5.0s, 79196 effective words/s\n",
            "INFO - 12:20:10: saving Word2Vec object under w2v_model_window-7_size-40.mdl, separately None\n",
            "INFO - 12:20:10: not storing attribute vectors_norm\n",
            "INFO - 12:20:10: not storing attribute cum_table\n",
            "INFO - 12:20:10: saved w2v_model_window-7_size-40.mdl\n",
            "WARNING - 12:20:10: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:10: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:11: EPOCH 1 - PROGRESS: at 39.38% examples, 77788 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:12: EPOCH 1 - PROGRESS: at 76.60% examples, 72878 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:12: EPOCH - 1 : training on 523700 raw words (199163 effective words) took 2.6s, 75728 effective words/s\n",
            "INFO - 12:20:14: EPOCH 2 - PROGRESS: at 41.53% examples, 79611 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:15: EPOCH 2 - PROGRESS: at 84.20% examples, 80302 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:15: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:15: EPOCH - 2 : training on 523700 raw words (199428 effective words) took 2.5s, 79881 effective words/s\n",
            "INFO - 12:20:15: training on a 1047400 raw words (398591 effective words) took 5.1s, 77407 effective words/s\n",
            "INFO - 12:20:15: saving Word2Vec object under w2v_model_window-7_size-50.mdl, separately None\n",
            "INFO - 12:20:15: not storing attribute vectors_norm\n",
            "INFO - 12:20:15: not storing attribute cum_table\n",
            "INFO - 12:20:15: saved w2v_model_window-7_size-50.mdl\n",
            "WARNING - 12:20:15: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:15: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:16: EPOCH 1 - PROGRESS: at 39.38% examples, 78659 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:17: EPOCH 1 - PROGRESS: at 82.28% examples, 79354 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:18: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:18: EPOCH - 1 : training on 523700 raw words (199044 effective words) took 2.5s, 80201 effective words/s\n",
            "INFO - 12:20:19: EPOCH 2 - PROGRESS: at 33.37% examples, 66278 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:20:20: EPOCH 2 - PROGRESS: at 74.71% examples, 73101 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:20: EPOCH - 2 : training on 523700 raw words (198917 effective words) took 2.6s, 75410 effective words/s\n",
            "INFO - 12:20:20: training on a 1047400 raw words (397961 effective words) took 5.1s, 77307 effective words/s\n",
            "INFO - 12:20:20: saving Word2Vec object under w2v_model_window-7_size-60.mdl, separately None\n",
            "INFO - 12:20:20: not storing attribute vectors_norm\n",
            "INFO - 12:20:20: not storing attribute cum_table\n",
            "INFO - 12:20:20: saved w2v_model_window-7_size-60.mdl\n",
            "WARNING - 12:20:20: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:20: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:21: EPOCH 1 - PROGRESS: at 39.38% examples, 78309 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:22: EPOCH 1 - PROGRESS: at 82.28% examples, 79665 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:23: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:23: EPOCH - 1 : training on 523700 raw words (198696 effective words) took 2.5s, 80176 effective words/s\n",
            "INFO - 12:20:24: EPOCH 2 - PROGRESS: at 39.38% examples, 77698 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:25: EPOCH 2 - PROGRESS: at 80.39% examples, 78649 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:25: EPOCH - 2 : training on 523700 raw words (198897 effective words) took 2.5s, 79046 effective words/s\n",
            "INFO - 12:20:25: training on a 1047400 raw words (397593 effective words) took 5.0s, 79247 effective words/s\n",
            "INFO - 12:20:25: saving Word2Vec object under w2v_model_window-7_size-70.mdl, separately None\n",
            "INFO - 12:20:25: not storing attribute vectors_norm\n",
            "INFO - 12:20:25: not storing attribute cum_table\n",
            "INFO - 12:20:25: saved w2v_model_window-7_size-70.mdl\n",
            "WARNING - 12:20:25: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:25: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:26: EPOCH 1 - PROGRESS: at 33.37% examples, 67916 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:27: EPOCH 1 - PROGRESS: at 74.71% examples, 73138 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:28: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:28: EPOCH - 1 : training on 523700 raw words (199178 effective words) took 2.6s, 75233 effective words/s\n",
            "INFO - 12:20:29: EPOCH 2 - PROGRESS: at 39.38% examples, 78488 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:30: EPOCH 2 - PROGRESS: at 80.39% examples, 78858 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:30: EPOCH - 2 : training on 523700 raw words (199387 effective words) took 2.5s, 79335 effective words/s\n",
            "INFO - 12:20:30: training on a 1047400 raw words (398565 effective words) took 5.2s, 76862 effective words/s\n",
            "INFO - 12:20:30: saving Word2Vec object under w2v_model_window-7_size-80.mdl, separately None\n",
            "INFO - 12:20:30: not storing attribute vectors_norm\n",
            "INFO - 12:20:30: not storing attribute cum_table\n",
            "INFO - 12:20:30: saved w2v_model_window-7_size-80.mdl\n",
            "WARNING - 12:20:30: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:30: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:32: EPOCH 1 - PROGRESS: at 39.38% examples, 78849 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:33: EPOCH 1 - PROGRESS: at 82.28% examples, 79929 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:33: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:33: EPOCH - 1 : training on 523700 raw words (199363 effective words) took 2.5s, 80752 effective words/s\n",
            "INFO - 12:20:34: EPOCH 2 - PROGRESS: at 33.37% examples, 67617 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:35: EPOCH 2 - PROGRESS: at 74.71% examples, 73092 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:36: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:36: EPOCH - 2 : training on 523700 raw words (198996 effective words) took 2.6s, 75203 effective words/s\n",
            "INFO - 12:20:36: training on a 1047400 raw words (398359 effective words) took 5.1s, 77517 effective words/s\n",
            "INFO - 12:20:36: saving Word2Vec object under w2v_model_window-7_size-90.mdl, separately None\n",
            "INFO - 12:20:36: not storing attribute vectors_norm\n",
            "INFO - 12:20:36: not storing attribute cum_table\n",
            "INFO - 12:20:36: saved w2v_model_window-7_size-90.mdl\n",
            "WARNING - 12:20:36: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:36: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:37: EPOCH 1 - PROGRESS: at 39.38% examples, 76117 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:20:38: EPOCH 1 - PROGRESS: at 80.39% examples, 77984 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:20:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:38: EPOCH - 1 : training on 523700 raw words (199230 effective words) took 2.5s, 79110 effective words/s\n",
            "INFO - 12:20:39: EPOCH 2 - PROGRESS: at 39.38% examples, 78381 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:40: EPOCH 2 - PROGRESS: at 80.39% examples, 78236 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:41: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:41: EPOCH - 2 : training on 523700 raw words (198901 effective words) took 2.5s, 78671 effective words/s\n",
            "INFO - 12:20:41: training on a 1047400 raw words (398131 effective words) took 5.1s, 78546 effective words/s\n",
            "INFO - 12:20:41: saving Word2Vec object under w2v_model_window-7_size-100.mdl, separately None\n",
            "INFO - 12:20:41: not storing attribute vectors_norm\n",
            "INFO - 12:20:41: not storing attribute cum_table\n",
            "INFO - 12:20:41: saved w2v_model_window-7_size-100.mdl\n",
            "WARNING - 12:20:41: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:41: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:42: EPOCH 1 - PROGRESS: at 33.37% examples, 65584 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:43: EPOCH 1 - PROGRESS: at 76.60% examples, 73461 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:43: EPOCH - 1 : training on 523700 raw words (199319 effective words) took 2.6s, 75323 effective words/s\n",
            "INFO - 12:20:44: EPOCH 2 - PROGRESS: at 39.38% examples, 79416 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:45: EPOCH 2 - PROGRESS: at 80.39% examples, 78553 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:46: EPOCH - 2 : training on 523700 raw words (199084 effective words) took 2.5s, 80276 effective words/s\n",
            "INFO - 12:20:46: training on a 1047400 raw words (398403 effective words) took 5.1s, 77448 effective words/s\n",
            "INFO - 12:20:46: saving Word2Vec object under w2v_model_window-7_size-200.mdl, separately None\n",
            "INFO - 12:20:46: not storing attribute vectors_norm\n",
            "INFO - 12:20:46: not storing attribute cum_table\n",
            "INFO - 12:20:46: saved w2v_model_window-7_size-200.mdl\n",
            "WARNING - 12:20:46: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:46: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:47: EPOCH 1 - PROGRESS: at 37.40% examples, 75174 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:48: EPOCH 1 - PROGRESS: at 80.39% examples, 78086 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:49: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:49: EPOCH - 1 : training on 523700 raw words (199594 effective words) took 2.7s, 74885 effective words/s\n",
            "INFO - 12:20:50: EPOCH 2 - PROGRESS: at 39.38% examples, 79506 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:51: EPOCH 2 - PROGRESS: at 80.39% examples, 79523 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:51: EPOCH - 2 : training on 523700 raw words (199327 effective words) took 2.5s, 79721 effective words/s\n",
            "INFO - 12:20:51: training on a 1047400 raw words (398921 effective words) took 5.2s, 76944 effective words/s\n",
            "INFO - 12:20:51: saving Word2Vec object under w2v_model_window-7_size-300.mdl, separately None\n",
            "INFO - 12:20:51: not storing attribute vectors_norm\n",
            "INFO - 12:20:51: not storing attribute cum_table\n",
            "INFO - 12:20:51: saved w2v_model_window-7_size-300.mdl\n",
            "WARNING - 12:20:51: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:51: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:52: EPOCH 1 - PROGRESS: at 39.38% examples, 78374 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:53: EPOCH 1 - PROGRESS: at 80.39% examples, 79089 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:54: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:54: EPOCH - 1 : training on 523700 raw words (198746 effective words) took 2.5s, 79566 effective words/s\n",
            "INFO - 12:20:55: EPOCH 2 - PROGRESS: at 39.38% examples, 79367 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:56: EPOCH 2 - PROGRESS: at 74.71% examples, 73518 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:56: EPOCH - 2 : training on 523700 raw words (199316 effective words) took 2.6s, 75301 effective words/s\n",
            "INFO - 12:20:56: training on a 1047400 raw words (398062 effective words) took 5.2s, 77091 effective words/s\n",
            "INFO - 12:20:56: saving Word2Vec object under w2v_model_window-7_size-400.mdl, separately None\n",
            "INFO - 12:20:56: not storing attribute vectors_norm\n",
            "INFO - 12:20:56: not storing attribute cum_table\n",
            "INFO - 12:20:56: saved w2v_model_window-7_size-400.mdl\n",
            "WARNING - 12:20:56: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:20:56: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:20:57: EPOCH 1 - PROGRESS: at 39.38% examples, 78449 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:58: EPOCH 1 - PROGRESS: at 82.28% examples, 79141 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:20:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:20:59: EPOCH - 1 : training on 523700 raw words (199070 effective words) took 2.5s, 79891 effective words/s\n",
            "INFO - 12:21:00: EPOCH 2 - PROGRESS: at 39.38% examples, 77414 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:01: EPOCH 2 - PROGRESS: at 80.39% examples, 78495 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:01: EPOCH - 2 : training on 523700 raw words (199596 effective words) took 2.5s, 79532 effective words/s\n",
            "INFO - 12:21:01: training on a 1047400 raw words (398666 effective words) took 5.0s, 79383 effective words/s\n",
            "INFO - 12:21:01: saving Word2Vec object under w2v_model_window-7_size-500.mdl, separately None\n",
            "INFO - 12:21:01: not storing attribute vectors_norm\n",
            "INFO - 12:21:01: not storing attribute cum_table\n",
            "INFO - 12:21:01: saved w2v_model_window-7_size-500.mdl\n",
            "WARNING - 12:21:01: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:01: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:02: EPOCH 1 - PROGRESS: at 33.37% examples, 66608 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:03: EPOCH 1 - PROGRESS: at 74.71% examples, 72790 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:04: EPOCH - 1 : training on 523700 raw words (199240 effective words) took 2.7s, 75021 effective words/s\n",
            "INFO - 12:21:05: EPOCH 2 - PROGRESS: at 39.38% examples, 77857 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:06: EPOCH 2 - PROGRESS: at 80.39% examples, 78236 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:07: EPOCH - 2 : training on 523700 raw words (199119 effective words) took 2.5s, 79200 effective words/s\n",
            "INFO - 12:21:07: training on a 1047400 raw words (398359 effective words) took 5.2s, 76677 effective words/s\n",
            "INFO - 12:21:07: saving Word2Vec object under w2v_model_window-8_size-10.mdl, separately None\n",
            "INFO - 12:21:07: not storing attribute vectors_norm\n",
            "INFO - 12:21:07: not storing attribute cum_table\n",
            "INFO - 12:21:07: saved w2v_model_window-8_size-10.mdl\n",
            "WARNING - 12:21:07: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:07: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:08: EPOCH 1 - PROGRESS: at 39.38% examples, 78868 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:09: EPOCH 1 - PROGRESS: at 82.28% examples, 80069 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:09: EPOCH - 1 : training on 523700 raw words (199309 effective words) took 2.5s, 80588 effective words/s\n",
            "INFO - 12:21:10: EPOCH 2 - PROGRESS: at 39.38% examples, 77696 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:11: EPOCH 2 - PROGRESS: at 74.71% examples, 73053 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:12: EPOCH - 2 : training on 523700 raw words (199233 effective words) took 2.7s, 74961 effective words/s\n",
            "INFO - 12:21:12: training on a 1047400 raw words (398542 effective words) took 5.2s, 77385 effective words/s\n",
            "INFO - 12:21:12: saving Word2Vec object under w2v_model_window-8_size-20.mdl, separately None\n",
            "INFO - 12:21:12: not storing attribute vectors_norm\n",
            "INFO - 12:21:12: not storing attribute cum_table\n",
            "INFO - 12:21:12: saved w2v_model_window-8_size-20.mdl\n",
            "WARNING - 12:21:12: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:12: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:13: EPOCH 1 - PROGRESS: at 39.38% examples, 77903 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:14: EPOCH 1 - PROGRESS: at 80.39% examples, 78595 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:14: EPOCH - 1 : training on 523700 raw words (198978 effective words) took 2.5s, 80140 effective words/s\n",
            "INFO - 12:21:15: EPOCH 2 - PROGRESS: at 39.38% examples, 77881 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:16: EPOCH 2 - PROGRESS: at 80.39% examples, 78955 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:17: EPOCH - 2 : training on 523700 raw words (199166 effective words) took 2.5s, 79641 effective words/s\n",
            "INFO - 12:21:17: training on a 1047400 raw words (398144 effective words) took 5.0s, 79467 effective words/s\n",
            "INFO - 12:21:17: saving Word2Vec object under w2v_model_window-8_size-30.mdl, separately None\n",
            "INFO - 12:21:17: not storing attribute vectors_norm\n",
            "INFO - 12:21:17: not storing attribute cum_table\n",
            "INFO - 12:21:17: saved w2v_model_window-8_size-30.mdl\n",
            "WARNING - 12:21:17: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:17: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:18: EPOCH 1 - PROGRESS: at 33.37% examples, 67135 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:19: EPOCH 1 - PROGRESS: at 76.60% examples, 73970 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:20: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:20: EPOCH - 1 : training on 523700 raw words (198548 effective words) took 2.6s, 75567 effective words/s\n",
            "INFO - 12:21:21: EPOCH 2 - PROGRESS: at 39.38% examples, 77178 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:22: EPOCH 2 - PROGRESS: at 82.28% examples, 79305 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:22: EPOCH - 2 : training on 523700 raw words (198922 effective words) took 2.5s, 79685 effective words/s\n",
            "INFO - 12:21:22: training on a 1047400 raw words (397470 effective words) took 5.1s, 77191 effective words/s\n",
            "INFO - 12:21:22: saving Word2Vec object under w2v_model_window-8_size-40.mdl, separately None\n",
            "INFO - 12:21:22: not storing attribute vectors_norm\n",
            "INFO - 12:21:22: not storing attribute cum_table\n",
            "INFO - 12:21:22: saved w2v_model_window-8_size-40.mdl\n",
            "WARNING - 12:21:22: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:22: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:23: EPOCH 1 - PROGRESS: at 39.38% examples, 78520 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:24: EPOCH 1 - PROGRESS: at 80.39% examples, 79189 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:25: EPOCH - 1 : training on 523700 raw words (199078 effective words) took 2.5s, 80208 effective words/s\n",
            "INFO - 12:21:26: EPOCH 2 - PROGRESS: at 31.39% examples, 63747 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:27: EPOCH 2 - PROGRESS: at 72.83% examples, 71628 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:27: EPOCH - 2 : training on 523700 raw words (198969 effective words) took 2.7s, 74533 effective words/s\n",
            "INFO - 12:21:27: training on a 1047400 raw words (398047 effective words) took 5.2s, 76951 effective words/s\n",
            "INFO - 12:21:27: saving Word2Vec object under w2v_model_window-8_size-50.mdl, separately None\n",
            "INFO - 12:21:27: not storing attribute vectors_norm\n",
            "INFO - 12:21:27: not storing attribute cum_table\n",
            "INFO - 12:21:27: saved w2v_model_window-8_size-50.mdl\n",
            "WARNING - 12:21:27: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:27: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:28: EPOCH 1 - PROGRESS: at 39.38% examples, 77977 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:29: EPOCH 1 - PROGRESS: at 82.28% examples, 79786 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:30: EPOCH - 1 : training on 523700 raw words (199479 effective words) took 2.5s, 80039 effective words/s\n",
            "INFO - 12:21:31: EPOCH 2 - PROGRESS: at 39.38% examples, 77369 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:32: EPOCH 2 - PROGRESS: at 80.39% examples, 78530 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:32: EPOCH - 2 : training on 523700 raw words (199176 effective words) took 2.5s, 79087 effective words/s\n",
            "INFO - 12:21:32: training on a 1047400 raw words (398655 effective words) took 5.0s, 79198 effective words/s\n",
            "INFO - 12:21:32: saving Word2Vec object under w2v_model_window-8_size-60.mdl, separately None\n",
            "INFO - 12:21:32: not storing attribute vectors_norm\n",
            "INFO - 12:21:32: not storing attribute cum_table\n",
            "INFO - 12:21:32: saved w2v_model_window-8_size-60.mdl\n",
            "WARNING - 12:21:32: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:32: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:33: EPOCH 1 - PROGRESS: at 35.34% examples, 68390 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:34: EPOCH 1 - PROGRESS: at 76.60% examples, 73815 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:35: EPOCH - 1 : training on 523700 raw words (198911 effective words) took 2.6s, 75634 effective words/s\n",
            "INFO - 12:21:36: EPOCH 2 - PROGRESS: at 39.38% examples, 77204 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:37: EPOCH 2 - PROGRESS: at 82.28% examples, 79506 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:38: EPOCH - 2 : training on 523700 raw words (199161 effective words) took 2.5s, 79336 effective words/s\n",
            "INFO - 12:21:38: training on a 1047400 raw words (398072 effective words) took 5.2s, 77176 effective words/s\n",
            "INFO - 12:21:38: saving Word2Vec object under w2v_model_window-8_size-70.mdl, separately None\n",
            "INFO - 12:21:38: not storing attribute vectors_norm\n",
            "INFO - 12:21:38: not storing attribute cum_table\n",
            "INFO - 12:21:38: saved w2v_model_window-8_size-70.mdl\n",
            "WARNING - 12:21:38: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:38: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:39: EPOCH 1 - PROGRESS: at 39.38% examples, 78774 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:40: EPOCH 1 - PROGRESS: at 82.28% examples, 79859 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:40: EPOCH - 1 : training on 523700 raw words (199063 effective words) took 2.6s, 76252 effective words/s\n",
            "INFO - 12:21:41: EPOCH 2 - PROGRESS: at 39.38% examples, 76725 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:42: EPOCH 2 - PROGRESS: at 82.28% examples, 79168 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:43: EPOCH - 2 : training on 523700 raw words (199135 effective words) took 2.5s, 79949 effective words/s\n",
            "INFO - 12:21:43: training on a 1047400 raw words (398198 effective words) took 5.1s, 77695 effective words/s\n",
            "INFO - 12:21:43: saving Word2Vec object under w2v_model_window-8_size-80.mdl, separately None\n",
            "INFO - 12:21:43: not storing attribute vectors_norm\n",
            "INFO - 12:21:43: not storing attribute cum_table\n",
            "INFO - 12:21:43: saved w2v_model_window-8_size-80.mdl\n",
            "WARNING - 12:21:43: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:43: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:44: EPOCH 1 - PROGRESS: at 39.38% examples, 79185 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:45: EPOCH 1 - PROGRESS: at 80.39% examples, 79517 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:45: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:45: EPOCH - 1 : training on 523700 raw words (199619 effective words) took 2.5s, 80124 effective words/s\n",
            "INFO - 12:21:46: EPOCH 2 - PROGRESS: at 39.38% examples, 78778 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:47: EPOCH 2 - PROGRESS: at 80.39% examples, 78928 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:48: EPOCH - 2 : training on 523700 raw words (199274 effective words) took 2.5s, 79387 effective words/s\n",
            "INFO - 12:21:48: training on a 1047400 raw words (398893 effective words) took 5.0s, 79495 effective words/s\n",
            "INFO - 12:21:48: saving Word2Vec object under w2v_model_window-8_size-90.mdl, separately None\n",
            "INFO - 12:21:48: not storing attribute vectors_norm\n",
            "INFO - 12:21:48: not storing attribute cum_table\n",
            "INFO - 12:21:48: saved w2v_model_window-8_size-90.mdl\n",
            "WARNING - 12:21:48: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:48: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:49: EPOCH 1 - PROGRESS: at 33.37% examples, 67489 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:50: EPOCH 1 - PROGRESS: at 74.71% examples, 73961 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:50: EPOCH - 1 : training on 523700 raw words (199387 effective words) took 2.6s, 76227 effective words/s\n",
            "INFO - 12:21:51: EPOCH 2 - PROGRESS: at 39.38% examples, 76883 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:52: EPOCH 2 - PROGRESS: at 80.39% examples, 78616 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:53: EPOCH - 2 : training on 523700 raw words (199234 effective words) took 2.5s, 79731 effective words/s\n",
            "INFO - 12:21:53: training on a 1047400 raw words (398621 effective words) took 5.1s, 77625 effective words/s\n",
            "INFO - 12:21:53: saving Word2Vec object under w2v_model_window-8_size-100.mdl, separately None\n",
            "INFO - 12:21:53: not storing attribute vectors_norm\n",
            "INFO - 12:21:53: not storing attribute cum_table\n",
            "INFO - 12:21:53: saved w2v_model_window-8_size-100.mdl\n",
            "WARNING - 12:21:53: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:53: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:54: EPOCH 1 - PROGRESS: at 41.53% examples, 79128 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:55: EPOCH 1 - PROGRESS: at 84.20% examples, 79916 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:21:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:55: EPOCH - 1 : training on 523700 raw words (199651 effective words) took 2.5s, 80442 effective words/s\n",
            "INFO - 12:21:57: EPOCH 2 - PROGRESS: at 33.37% examples, 65988 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:58: EPOCH 2 - PROGRESS: at 74.71% examples, 72835 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:21:58: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:21:58: EPOCH - 2 : training on 523700 raw words (198910 effective words) took 2.6s, 75495 effective words/s\n",
            "INFO - 12:21:58: training on a 1047400 raw words (398561 effective words) took 5.1s, 77463 effective words/s\n",
            "INFO - 12:21:58: saving Word2Vec object under w2v_model_window-8_size-200.mdl, separately None\n",
            "INFO - 12:21:58: not storing attribute vectors_norm\n",
            "INFO - 12:21:58: not storing attribute cum_table\n",
            "INFO - 12:21:58: saved w2v_model_window-8_size-200.mdl\n",
            "WARNING - 12:21:58: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:21:58: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:21:59: EPOCH 1 - PROGRESS: at 39.38% examples, 77251 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:00: EPOCH 1 - PROGRESS: at 80.39% examples, 78066 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:01: EPOCH - 1 : training on 523700 raw words (198931 effective words) took 2.5s, 79174 effective words/s\n",
            "INFO - 12:22:02: EPOCH 2 - PROGRESS: at 39.38% examples, 77764 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:03: EPOCH 2 - PROGRESS: at 80.39% examples, 78827 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:03: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:03: EPOCH - 2 : training on 523700 raw words (198797 effective words) took 2.6s, 75584 effective words/s\n",
            "INFO - 12:22:03: training on a 1047400 raw words (397728 effective words) took 5.2s, 76887 effective words/s\n",
            "INFO - 12:22:03: saving Word2Vec object under w2v_model_window-8_size-300.mdl, separately None\n",
            "INFO - 12:22:03: not storing attribute vectors_norm\n",
            "INFO - 12:22:03: not storing attribute cum_table\n",
            "INFO - 12:22:03: saved w2v_model_window-8_size-300.mdl\n",
            "WARNING - 12:22:03: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:03: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:04: EPOCH 1 - PROGRESS: at 39.38% examples, 78798 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:05: EPOCH 1 - PROGRESS: at 82.28% examples, 79485 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:06: EPOCH - 1 : training on 523700 raw words (198777 effective words) took 2.5s, 79253 effective words/s\n",
            "INFO - 12:22:07: EPOCH 2 - PROGRESS: at 39.38% examples, 78063 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:08: EPOCH 2 - PROGRESS: at 82.28% examples, 78952 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:08: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:08: EPOCH - 2 : training on 523700 raw words (199202 effective words) took 2.5s, 79629 effective words/s\n",
            "INFO - 12:22:08: training on a 1047400 raw words (397979 effective words) took 5.0s, 78967 effective words/s\n",
            "INFO - 12:22:08: saving Word2Vec object under w2v_model_window-8_size-400.mdl, separately None\n",
            "INFO - 12:22:08: not storing attribute vectors_norm\n",
            "INFO - 12:22:08: not storing attribute cum_table\n",
            "INFO - 12:22:08: saved w2v_model_window-8_size-400.mdl\n",
            "WARNING - 12:22:08: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:08: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:10: EPOCH 1 - PROGRESS: at 39.38% examples, 77691 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:11: EPOCH 1 - PROGRESS: at 76.60% examples, 73423 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:11: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:11: EPOCH - 1 : training on 523700 raw words (198848 effective words) took 2.7s, 75003 effective words/s\n",
            "INFO - 12:22:12: EPOCH 2 - PROGRESS: at 39.38% examples, 78475 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:13: EPOCH 2 - PROGRESS: at 82.28% examples, 80104 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:14: EPOCH - 2 : training on 523700 raw words (199428 effective words) took 2.5s, 80755 effective words/s\n",
            "INFO - 12:22:14: training on a 1047400 raw words (398276 effective words) took 5.1s, 77461 effective words/s\n",
            "INFO - 12:22:14: saving Word2Vec object under w2v_model_window-8_size-500.mdl, separately None\n",
            "INFO - 12:22:14: not storing attribute vectors_norm\n",
            "INFO - 12:22:14: not storing attribute cum_table\n",
            "INFO - 12:22:14: saved w2v_model_window-8_size-500.mdl\n",
            "WARNING - 12:22:14: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:14: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:15: EPOCH 1 - PROGRESS: at 39.38% examples, 78519 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:16: EPOCH 1 - PROGRESS: at 80.39% examples, 78619 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:16: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:16: EPOCH - 1 : training on 523700 raw words (199120 effective words) took 2.5s, 79569 effective words/s\n",
            "INFO - 12:22:17: EPOCH 2 - PROGRESS: at 39.38% examples, 78848 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:18: EPOCH 2 - PROGRESS: at 76.60% examples, 74205 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:19: EPOCH - 2 : training on 523700 raw words (198693 effective words) took 2.6s, 76145 effective words/s\n",
            "INFO - 12:22:19: training on a 1047400 raw words (397813 effective words) took 5.1s, 77593 effective words/s\n",
            "INFO - 12:22:19: saving Word2Vec object under w2v_model_window-9_size-10.mdl, separately None\n",
            "INFO - 12:22:19: not storing attribute vectors_norm\n",
            "INFO - 12:22:19: not storing attribute cum_table\n",
            "INFO - 12:22:19: saved w2v_model_window-9_size-10.mdl\n",
            "WARNING - 12:22:19: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:19: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:20: EPOCH 1 - PROGRESS: at 39.38% examples, 78566 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:21: EPOCH 1 - PROGRESS: at 82.28% examples, 79394 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:21: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:21: EPOCH - 1 : training on 523700 raw words (198683 effective words) took 2.5s, 79807 effective words/s\n",
            "INFO - 12:22:22: EPOCH 2 - PROGRESS: at 39.38% examples, 77683 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:23: EPOCH 2 - PROGRESS: at 82.28% examples, 79313 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:24: EPOCH - 2 : training on 523700 raw words (199085 effective words) took 2.5s, 80319 effective words/s\n",
            "INFO - 12:22:24: training on a 1047400 raw words (397768 effective words) took 5.0s, 79690 effective words/s\n",
            "INFO - 12:22:24: saving Word2Vec object under w2v_model_window-9_size-20.mdl, separately None\n",
            "INFO - 12:22:24: not storing attribute vectors_norm\n",
            "INFO - 12:22:24: not storing attribute cum_table\n",
            "INFO - 12:22:24: saved w2v_model_window-9_size-20.mdl\n",
            "WARNING - 12:22:24: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:24: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:25: EPOCH 1 - PROGRESS: at 39.38% examples, 78444 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:26: EPOCH 1 - PROGRESS: at 74.71% examples, 73254 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:27: EPOCH - 1 : training on 523700 raw words (199433 effective words) took 2.7s, 75140 effective words/s\n",
            "INFO - 12:22:28: EPOCH 2 - PROGRESS: at 39.38% examples, 79726 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:29: EPOCH 2 - PROGRESS: at 80.39% examples, 79494 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:29: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:29: EPOCH - 2 : training on 523700 raw words (199221 effective words) took 2.5s, 80183 effective words/s\n",
            "INFO - 12:22:29: training on a 1047400 raw words (398654 effective words) took 5.2s, 77119 effective words/s\n",
            "INFO - 12:22:29: saving Word2Vec object under w2v_model_window-9_size-30.mdl, separately None\n",
            "INFO - 12:22:29: not storing attribute vectors_norm\n",
            "INFO - 12:22:29: not storing attribute cum_table\n",
            "INFO - 12:22:29: saved w2v_model_window-9_size-30.mdl\n",
            "WARNING - 12:22:29: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:29: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:30: EPOCH 1 - PROGRESS: at 37.40% examples, 74802 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:31: EPOCH 1 - PROGRESS: at 80.39% examples, 77656 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:32: EPOCH - 1 : training on 523700 raw words (199143 effective words) took 2.5s, 78259 effective words/s\n",
            "INFO - 12:22:33: EPOCH 2 - PROGRESS: at 33.37% examples, 67084 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:34: EPOCH 2 - PROGRESS: at 76.60% examples, 74757 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:34: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:34: EPOCH - 2 : training on 523700 raw words (199666 effective words) took 2.6s, 76777 effective words/s\n",
            "INFO - 12:22:34: training on a 1047400 raw words (398809 effective words) took 5.2s, 77175 effective words/s\n",
            "INFO - 12:22:34: saving Word2Vec object under w2v_model_window-9_size-40.mdl, separately None\n",
            "INFO - 12:22:34: not storing attribute vectors_norm\n",
            "INFO - 12:22:34: not storing attribute cum_table\n",
            "INFO - 12:22:34: saved w2v_model_window-9_size-40.mdl\n",
            "WARNING - 12:22:34: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:34: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:35: EPOCH 1 - PROGRESS: at 39.38% examples, 77433 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:36: EPOCH 1 - PROGRESS: at 80.39% examples, 78840 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:37: EPOCH - 1 : training on 523700 raw words (199528 effective words) took 2.5s, 79602 effective words/s\n",
            "INFO - 12:22:38: EPOCH 2 - PROGRESS: at 39.38% examples, 77590 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:39: EPOCH 2 - PROGRESS: at 82.28% examples, 78781 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:39: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:39: EPOCH - 2 : training on 523700 raw words (199053 effective words) took 2.5s, 79693 effective words/s\n",
            "INFO - 12:22:39: training on a 1047400 raw words (398581 effective words) took 5.0s, 79182 effective words/s\n",
            "INFO - 12:22:39: saving Word2Vec object under w2v_model_window-9_size-50.mdl, separately None\n",
            "INFO - 12:22:39: not storing attribute vectors_norm\n",
            "INFO - 12:22:39: not storing attribute cum_table\n",
            "INFO - 12:22:39: saved w2v_model_window-9_size-50.mdl\n",
            "WARNING - 12:22:39: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:39: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:40: EPOCH 1 - PROGRESS: at 31.39% examples, 64145 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:41: EPOCH 1 - PROGRESS: at 74.71% examples, 72814 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:42: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:42: EPOCH - 1 : training on 523700 raw words (199133 effective words) took 2.7s, 74800 effective words/s\n",
            "INFO - 12:22:43: EPOCH 2 - PROGRESS: at 37.40% examples, 75201 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:44: EPOCH 2 - PROGRESS: at 78.53% examples, 77613 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:45: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:45: EPOCH - 2 : training on 523700 raw words (199075 effective words) took 2.5s, 78867 effective words/s\n",
            "INFO - 12:22:45: training on a 1047400 raw words (398208 effective words) took 5.2s, 76438 effective words/s\n",
            "INFO - 12:22:45: saving Word2Vec object under w2v_model_window-9_size-60.mdl, separately None\n",
            "INFO - 12:22:45: not storing attribute vectors_norm\n",
            "INFO - 12:22:45: not storing attribute cum_table\n",
            "INFO - 12:22:45: saved w2v_model_window-9_size-60.mdl\n",
            "WARNING - 12:22:45: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:45: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:46: EPOCH 1 - PROGRESS: at 37.40% examples, 75004 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:47: EPOCH 1 - PROGRESS: at 78.53% examples, 76333 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:47: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:47: EPOCH - 1 : training on 523700 raw words (199149 effective words) took 2.6s, 76408 effective words/s\n",
            "INFO - 12:22:48: EPOCH 2 - PROGRESS: at 33.37% examples, 65744 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:49: EPOCH 2 - PROGRESS: at 74.71% examples, 71519 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:50: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:50: EPOCH - 2 : training on 523700 raw words (199176 effective words) took 2.7s, 73384 effective words/s\n",
            "INFO - 12:22:50: training on a 1047400 raw words (398325 effective words) took 5.3s, 74556 effective words/s\n",
            "INFO - 12:22:50: saving Word2Vec object under w2v_model_window-9_size-70.mdl, separately None\n",
            "INFO - 12:22:50: not storing attribute vectors_norm\n",
            "INFO - 12:22:50: not storing attribute cum_table\n",
            "INFO - 12:22:50: saved w2v_model_window-9_size-70.mdl\n",
            "WARNING - 12:22:50: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:50: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:51: EPOCH 1 - PROGRESS: at 37.40% examples, 75520 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:52: EPOCH 1 - PROGRESS: at 78.53% examples, 76781 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:53: EPOCH - 1 : training on 523700 raw words (199439 effective words) took 2.6s, 77349 effective words/s\n",
            "INFO - 12:22:54: EPOCH 2 - PROGRESS: at 39.38% examples, 77110 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:55: EPOCH 2 - PROGRESS: at 80.39% examples, 77403 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:55: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:55: EPOCH - 2 : training on 523700 raw words (199031 effective words) took 2.7s, 73444 effective words/s\n",
            "INFO - 12:22:55: training on a 1047400 raw words (398470 effective words) took 5.3s, 75135 effective words/s\n",
            "INFO - 12:22:55: saving Word2Vec object under w2v_model_window-9_size-80.mdl, separately None\n",
            "INFO - 12:22:55: not storing attribute vectors_norm\n",
            "INFO - 12:22:55: not storing attribute cum_table\n",
            "INFO - 12:22:55: saved w2v_model_window-9_size-80.mdl\n",
            "WARNING - 12:22:55: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:22:55: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:22:56: EPOCH 1 - PROGRESS: at 35.34% examples, 68934 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:22:57: EPOCH 1 - PROGRESS: at 74.71% examples, 71098 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:22:58: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:22:58: EPOCH - 1 : training on 523700 raw words (199187 effective words) took 2.8s, 72274 effective words/s\n",
            "INFO - 12:22:59: EPOCH 2 - PROGRESS: at 35.34% examples, 70193 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:00: EPOCH 2 - PROGRESS: at 74.71% examples, 71478 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:01: EPOCH - 2 : training on 523700 raw words (199196 effective words) took 2.7s, 72462 effective words/s\n",
            "INFO - 12:23:01: training on a 1047400 raw words (398383 effective words) took 5.5s, 72018 effective words/s\n",
            "INFO - 12:23:01: saving Word2Vec object under w2v_model_window-9_size-90.mdl, separately None\n",
            "INFO - 12:23:01: not storing attribute vectors_norm\n",
            "INFO - 12:23:01: not storing attribute cum_table\n",
            "INFO - 12:23:01: saved w2v_model_window-9_size-90.mdl\n",
            "WARNING - 12:23:01: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:01: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:02: EPOCH 1 - PROGRESS: at 39.38% examples, 78140 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:03: EPOCH 1 - PROGRESS: at 74.71% examples, 72031 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:04: EPOCH - 1 : training on 523700 raw words (199008 effective words) took 2.7s, 74157 effective words/s\n",
            "INFO - 12:23:05: EPOCH 2 - PROGRESS: at 39.38% examples, 75979 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:06: EPOCH 2 - PROGRESS: at 80.39% examples, 76691 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:06: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:06: EPOCH - 2 : training on 523700 raw words (198958 effective words) took 2.6s, 77322 effective words/s\n",
            "INFO - 12:23:06: training on a 1047400 raw words (397966 effective words) took 5.3s, 75308 effective words/s\n",
            "INFO - 12:23:06: saving Word2Vec object under w2v_model_window-9_size-100.mdl, separately None\n",
            "INFO - 12:23:06: not storing attribute vectors_norm\n",
            "INFO - 12:23:06: not storing attribute cum_table\n",
            "INFO - 12:23:06: saved w2v_model_window-9_size-100.mdl\n",
            "WARNING - 12:23:06: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:06: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:07: EPOCH 1 - PROGRESS: at 37.40% examples, 74923 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:08: EPOCH 1 - PROGRESS: at 78.53% examples, 76034 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:09: EPOCH - 1 : training on 523700 raw words (198247 effective words) took 2.6s, 77223 effective words/s\n",
            "INFO - 12:23:10: EPOCH 2 - PROGRESS: at 39.38% examples, 76477 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:11: EPOCH 2 - PROGRESS: at 72.83% examples, 70642 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:12: EPOCH - 2 : training on 523700 raw words (199700 effective words) took 2.7s, 73457 effective words/s\n",
            "INFO - 12:23:12: training on a 1047400 raw words (397947 effective words) took 5.3s, 75011 effective words/s\n",
            "INFO - 12:23:12: saving Word2Vec object under w2v_model_window-9_size-200.mdl, separately None\n",
            "INFO - 12:23:12: not storing attribute vectors_norm\n",
            "INFO - 12:23:12: not storing attribute cum_table\n",
            "INFO - 12:23:12: saved w2v_model_window-9_size-200.mdl\n",
            "WARNING - 12:23:12: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:12: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:13: EPOCH 1 - PROGRESS: at 39.38% examples, 78449 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:14: EPOCH 1 - PROGRESS: at 80.39% examples, 79321 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:14: EPOCH - 1 : training on 523700 raw words (198991 effective words) took 2.5s, 79950 effective words/s\n",
            "INFO - 12:23:15: EPOCH 2 - PROGRESS: at 39.38% examples, 75852 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:23:16: EPOCH 2 - PROGRESS: at 80.39% examples, 77592 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:17: EPOCH - 2 : training on 523700 raw words (199236 effective words) took 2.6s, 78042 effective words/s\n",
            "INFO - 12:23:17: training on a 1047400 raw words (398227 effective words) took 5.1s, 78692 effective words/s\n",
            "INFO - 12:23:17: saving Word2Vec object under w2v_model_window-9_size-300.mdl, separately None\n",
            "INFO - 12:23:17: not storing attribute vectors_norm\n",
            "INFO - 12:23:17: not storing attribute cum_table\n",
            "INFO - 12:23:17: saved w2v_model_window-9_size-300.mdl\n",
            "WARNING - 12:23:17: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:17: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:18: EPOCH 1 - PROGRESS: at 37.40% examples, 75023 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:19: EPOCH 1 - PROGRESS: at 72.83% examples, 71612 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:19: EPOCH - 1 : training on 523700 raw words (199376 effective words) took 2.7s, 73381 effective words/s\n",
            "INFO - 12:23:20: EPOCH 2 - PROGRESS: at 37.40% examples, 75425 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:21: EPOCH 2 - PROGRESS: at 76.60% examples, 75645 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:22: EPOCH - 2 : training on 523700 raw words (199066 effective words) took 2.6s, 76400 effective words/s\n",
            "INFO - 12:23:22: training on a 1047400 raw words (398442 effective words) took 5.3s, 74494 effective words/s\n",
            "INFO - 12:23:22: saving Word2Vec object under w2v_model_window-9_size-400.mdl, separately None\n",
            "INFO - 12:23:22: not storing attribute vectors_norm\n",
            "INFO - 12:23:22: not storing attribute cum_table\n",
            "INFO - 12:23:22: saved w2v_model_window-9_size-400.mdl\n",
            "WARNING - 12:23:22: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:22: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:23: EPOCH 1 - PROGRESS: at 39.38% examples, 76534 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:24: EPOCH 1 - PROGRESS: at 82.28% examples, 78742 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:25: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:25: EPOCH - 1 : training on 523700 raw words (199388 effective words) took 2.5s, 79647 effective words/s\n",
            "INFO - 12:23:26: EPOCH 2 - PROGRESS: at 39.38% examples, 76647 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:27: EPOCH 2 - PROGRESS: at 74.71% examples, 71532 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:27: EPOCH - 2 : training on 523700 raw words (199009 effective words) took 2.7s, 73861 effective words/s\n",
            "INFO - 12:23:27: training on a 1047400 raw words (398397 effective words) took 5.2s, 76306 effective words/s\n",
            "INFO - 12:23:27: saving Word2Vec object under w2v_model_window-9_size-500.mdl, separately None\n",
            "INFO - 12:23:27: not storing attribute vectors_norm\n",
            "INFO - 12:23:27: not storing attribute cum_table\n",
            "INFO - 12:23:27: saved w2v_model_window-9_size-500.mdl\n",
            "WARNING - 12:23:27: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:27: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:28: EPOCH 1 - PROGRESS: at 39.38% examples, 77722 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:29: EPOCH 1 - PROGRESS: at 80.39% examples, 79049 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:30: EPOCH - 1 : training on 523700 raw words (199311 effective words) took 2.5s, 79976 effective words/s\n",
            "INFO - 12:23:31: EPOCH 2 - PROGRESS: at 37.40% examples, 73709 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:23:32: EPOCH 2 - PROGRESS: at 80.39% examples, 77046 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:32: EPOCH - 2 : training on 523700 raw words (199242 effective words) took 2.6s, 78063 effective words/s\n",
            "INFO - 12:23:32: training on a 1047400 raw words (398553 effective words) took 5.1s, 78600 effective words/s\n",
            "INFO - 12:23:32: saving Word2Vec object under w2v_model_window-10_size-10.mdl, separately None\n",
            "INFO - 12:23:32: not storing attribute vectors_norm\n",
            "INFO - 12:23:32: not storing attribute cum_table\n",
            "INFO - 12:23:32: saved w2v_model_window-10_size-10.mdl\n",
            "WARNING - 12:23:32: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:32: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:34: EPOCH 1 - PROGRESS: at 33.37% examples, 64860 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:35: EPOCH 1 - PROGRESS: at 76.60% examples, 73099 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:35: EPOCH - 1 : training on 523700 raw words (199067 effective words) took 2.6s, 75337 effective words/s\n",
            "INFO - 12:23:36: EPOCH 2 - PROGRESS: at 39.38% examples, 78248 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:37: EPOCH 2 - PROGRESS: at 80.39% examples, 77146 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:38: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:38: EPOCH - 2 : training on 523700 raw words (199041 effective words) took 2.5s, 78063 effective words/s\n",
            "INFO - 12:23:38: training on a 1047400 raw words (398108 effective words) took 5.2s, 76321 effective words/s\n",
            "INFO - 12:23:38: saving Word2Vec object under w2v_model_window-10_size-20.mdl, separately None\n",
            "INFO - 12:23:38: not storing attribute vectors_norm\n",
            "INFO - 12:23:38: not storing attribute cum_table\n",
            "INFO - 12:23:38: saved w2v_model_window-10_size-20.mdl\n",
            "WARNING - 12:23:38: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:38: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:39: EPOCH 1 - PROGRESS: at 39.38% examples, 76655 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:40: EPOCH 1 - PROGRESS: at 80.39% examples, 76898 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:40: EPOCH - 1 : training on 523700 raw words (198931 effective words) took 2.5s, 78041 effective words/s\n",
            "INFO - 12:23:41: EPOCH 2 - PROGRESS: at 35.34% examples, 63970 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:42: EPOCH 2 - PROGRESS: at 76.60% examples, 70946 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:43: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:43: EPOCH - 2 : training on 523700 raw words (198995 effective words) took 2.7s, 73584 effective words/s\n",
            "INFO - 12:23:43: training on a 1047400 raw words (397926 effective words) took 5.3s, 75494 effective words/s\n",
            "INFO - 12:23:43: saving Word2Vec object under w2v_model_window-10_size-30.mdl, separately None\n",
            "INFO - 12:23:43: not storing attribute vectors_norm\n",
            "INFO - 12:23:43: not storing attribute cum_table\n",
            "INFO - 12:23:43: saved w2v_model_window-10_size-30.mdl\n",
            "WARNING - 12:23:43: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:43: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:44: EPOCH 1 - PROGRESS: at 39.38% examples, 77685 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:45: EPOCH 1 - PROGRESS: at 80.39% examples, 77459 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:23:46: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:46: EPOCH - 1 : training on 523700 raw words (199012 effective words) took 2.5s, 78558 effective words/s\n",
            "INFO - 12:23:47: EPOCH 2 - PROGRESS: at 39.38% examples, 76550 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:48: EPOCH 2 - PROGRESS: at 80.39% examples, 77202 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:48: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:48: EPOCH - 2 : training on 523700 raw words (199126 effective words) took 2.5s, 78364 effective words/s\n",
            "INFO - 12:23:48: training on a 1047400 raw words (398138 effective words) took 5.1s, 78249 effective words/s\n",
            "INFO - 12:23:48: saving Word2Vec object under w2v_model_window-10_size-40.mdl, separately None\n",
            "INFO - 12:23:48: not storing attribute vectors_norm\n",
            "INFO - 12:23:48: not storing attribute cum_table\n",
            "INFO - 12:23:48: saved w2v_model_window-10_size-40.mdl\n",
            "WARNING - 12:23:48: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:48: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:49: EPOCH 1 - PROGRESS: at 33.37% examples, 66952 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:50: EPOCH 1 - PROGRESS: at 74.71% examples, 72959 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:51: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:51: EPOCH - 1 : training on 523700 raw words (198857 effective words) took 2.7s, 74135 effective words/s\n",
            "INFO - 12:23:52: EPOCH 2 - PROGRESS: at 39.38% examples, 77276 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:53: EPOCH 2 - PROGRESS: at 80.39% examples, 77616 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:53: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:53: EPOCH - 2 : training on 523700 raw words (199215 effective words) took 2.5s, 78591 effective words/s\n",
            "INFO - 12:23:53: training on a 1047400 raw words (398072 effective words) took 5.2s, 75893 effective words/s\n",
            "INFO - 12:23:53: saving Word2Vec object under w2v_model_window-10_size-50.mdl, separately None\n",
            "INFO - 12:23:53: not storing attribute vectors_norm\n",
            "INFO - 12:23:53: not storing attribute cum_table\n",
            "INFO - 12:23:53: saved w2v_model_window-10_size-50.mdl\n",
            "WARNING - 12:23:53: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:53: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:23:54: EPOCH 1 - PROGRESS: at 39.38% examples, 75901 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:23:56: EPOCH 1 - PROGRESS: at 80.39% examples, 76385 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:56: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:56: EPOCH - 1 : training on 523700 raw words (199109 effective words) took 2.7s, 74677 effective words/s\n",
            "INFO - 12:23:57: EPOCH 2 - PROGRESS: at 31.39% examples, 64203 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:58: EPOCH 2 - PROGRESS: at 74.71% examples, 72443 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:23:59: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:23:59: EPOCH - 2 : training on 523700 raw words (198820 effective words) took 2.7s, 74452 effective words/s\n",
            "INFO - 12:23:59: training on a 1047400 raw words (397929 effective words) took 5.4s, 74159 effective words/s\n",
            "INFO - 12:23:59: saving Word2Vec object under w2v_model_window-10_size-60.mdl, separately None\n",
            "INFO - 12:23:59: not storing attribute vectors_norm\n",
            "INFO - 12:23:59: not storing attribute cum_table\n",
            "INFO - 12:23:59: saved w2v_model_window-10_size-60.mdl\n",
            "WARNING - 12:23:59: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:23:59: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:00: EPOCH 1 - PROGRESS: at 39.38% examples, 79218 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:01: EPOCH 1 - PROGRESS: at 80.39% examples, 79668 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:01: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:01: EPOCH - 1 : training on 523700 raw words (198927 effective words) took 2.5s, 79727 effective words/s\n",
            "INFO - 12:24:02: EPOCH 2 - PROGRESS: at 39.38% examples, 78421 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:03: EPOCH 2 - PROGRESS: at 80.39% examples, 79364 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:04: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:04: EPOCH - 2 : training on 523700 raw words (199262 effective words) took 2.5s, 80526 effective words/s\n",
            "INFO - 12:24:04: training on a 1047400 raw words (398189 effective words) took 5.0s, 79898 effective words/s\n",
            "INFO - 12:24:04: saving Word2Vec object under w2v_model_window-10_size-70.mdl, separately None\n",
            "INFO - 12:24:04: not storing attribute vectors_norm\n",
            "INFO - 12:24:04: not storing attribute cum_table\n",
            "INFO - 12:24:04: saved w2v_model_window-10_size-70.mdl\n",
            "WARNING - 12:24:04: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:04: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:05: EPOCH 1 - PROGRESS: at 33.37% examples, 67402 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:06: EPOCH 1 - PROGRESS: at 74.71% examples, 73094 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:07: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:07: EPOCH - 1 : training on 523700 raw words (198512 effective words) took 2.6s, 75151 effective words/s\n",
            "INFO - 12:24:08: EPOCH 2 - PROGRESS: at 39.38% examples, 79086 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:09: EPOCH 2 - PROGRESS: at 80.39% examples, 78857 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:09: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:09: EPOCH - 2 : training on 523700 raw words (199321 effective words) took 2.5s, 79956 effective words/s\n",
            "INFO - 12:24:09: training on a 1047400 raw words (397833 effective words) took 5.2s, 77166 effective words/s\n",
            "INFO - 12:24:09: saving Word2Vec object under w2v_model_window-10_size-80.mdl, separately None\n",
            "INFO - 12:24:09: not storing attribute vectors_norm\n",
            "INFO - 12:24:09: not storing attribute cum_table\n",
            "INFO - 12:24:09: saved w2v_model_window-10_size-80.mdl\n",
            "WARNING - 12:24:09: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:09: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:10: EPOCH 1 - PROGRESS: at 39.38% examples, 78764 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:11: EPOCH 1 - PROGRESS: at 80.39% examples, 79421 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:12: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:12: EPOCH - 1 : training on 523700 raw words (199375 effective words) took 2.5s, 79834 effective words/s\n",
            "INFO - 12:24:13: EPOCH 2 - PROGRESS: at 35.34% examples, 69152 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:14: EPOCH 2 - PROGRESS: at 76.60% examples, 74516 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:14: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:14: EPOCH - 2 : training on 523700 raw words (199547 effective words) took 2.6s, 76261 effective words/s\n",
            "INFO - 12:24:14: training on a 1047400 raw words (398922 effective words) took 5.1s, 77772 effective words/s\n",
            "INFO - 12:24:14: saving Word2Vec object under w2v_model_window-10_size-90.mdl, separately None\n",
            "INFO - 12:24:14: not storing attribute vectors_norm\n",
            "INFO - 12:24:14: not storing attribute cum_table\n",
            "INFO - 12:24:14: saved w2v_model_window-10_size-90.mdl\n",
            "WARNING - 12:24:14: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:14: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:15: EPOCH 1 - PROGRESS: at 37.40% examples, 75580 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:16: EPOCH 1 - PROGRESS: at 80.39% examples, 78588 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:17: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:17: EPOCH - 1 : training on 523700 raw words (199337 effective words) took 2.5s, 79392 effective words/s\n",
            "INFO - 12:24:18: EPOCH 2 - PROGRESS: at 39.38% examples, 78096 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:19: EPOCH 2 - PROGRESS: at 82.28% examples, 78956 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:24:19: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:19: EPOCH - 2 : training on 523700 raw words (199164 effective words) took 2.5s, 80111 effective words/s\n",
            "INFO - 12:24:19: training on a 1047400 raw words (398501 effective words) took 5.0s, 79486 effective words/s\n",
            "INFO - 12:24:19: saving Word2Vec object under w2v_model_window-10_size-100.mdl, separately None\n",
            "INFO - 12:24:19: not storing attribute vectors_norm\n",
            "INFO - 12:24:19: not storing attribute cum_table\n",
            "INFO - 12:24:19: saved w2v_model_window-10_size-100.mdl\n",
            "WARNING - 12:24:19: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:19: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:20: EPOCH 1 - PROGRESS: at 33.37% examples, 67412 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:21: EPOCH 1 - PROGRESS: at 74.71% examples, 72613 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:22: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:22: EPOCH - 1 : training on 523700 raw words (199150 effective words) took 2.6s, 75853 effective words/s\n",
            "INFO - 12:24:23: EPOCH 2 - PROGRESS: at 41.53% examples, 80053 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:24: EPOCH 2 - PROGRESS: at 84.20% examples, 80355 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:24: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:24: EPOCH - 2 : training on 523700 raw words (199361 effective words) took 2.5s, 80637 effective words/s\n",
            "INFO - 12:24:24: training on a 1047400 raw words (398511 effective words) took 5.1s, 77856 effective words/s\n",
            "INFO - 12:24:24: saving Word2Vec object under w2v_model_window-10_size-200.mdl, separately None\n",
            "INFO - 12:24:24: not storing attribute vectors_norm\n",
            "INFO - 12:24:24: not storing attribute cum_table\n",
            "INFO - 12:24:24: saved w2v_model_window-10_size-200.mdl\n",
            "WARNING - 12:24:24: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:24: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:25: EPOCH 1 - PROGRESS: at 39.38% examples, 79330 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:27: EPOCH 1 - PROGRESS: at 80.39% examples, 78981 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:24:27: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:27: EPOCH - 1 : training on 523700 raw words (199263 effective words) took 2.5s, 80050 effective words/s\n",
            "INFO - 12:24:28: EPOCH 2 - PROGRESS: at 33.37% examples, 66450 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:29: EPOCH 2 - PROGRESS: at 74.71% examples, 73274 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:30: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:30: EPOCH - 2 : training on 523700 raw words (199287 effective words) took 2.6s, 75652 effective words/s\n",
            "INFO - 12:24:30: training on a 1047400 raw words (398550 effective words) took 5.1s, 77434 effective words/s\n",
            "INFO - 12:24:30: saving Word2Vec object under w2v_model_window-10_size-300.mdl, separately None\n",
            "INFO - 12:24:30: not storing attribute vectors_norm\n",
            "INFO - 12:24:30: not storing attribute cum_table\n",
            "INFO - 12:24:30: saved w2v_model_window-10_size-300.mdl\n",
            "WARNING - 12:24:30: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:30: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:31: EPOCH 1 - PROGRESS: at 39.38% examples, 77859 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:32: EPOCH 1 - PROGRESS: at 80.39% examples, 78428 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:32: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:32: EPOCH - 1 : training on 523700 raw words (199001 effective words) took 2.5s, 79362 effective words/s\n",
            "INFO - 12:24:33: EPOCH 2 - PROGRESS: at 39.38% examples, 77917 words/s, in_qsize 1, out_qsize 0\n",
            "INFO - 12:24:34: EPOCH 2 - PROGRESS: at 82.28% examples, 79700 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:35: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:35: EPOCH - 2 : training on 523700 raw words (199592 effective words) took 2.5s, 79861 effective words/s\n",
            "INFO - 12:24:35: training on a 1047400 raw words (398593 effective words) took 5.0s, 79172 effective words/s\n",
            "INFO - 12:24:35: saving Word2Vec object under w2v_model_window-10_size-400.mdl, separately None\n",
            "INFO - 12:24:35: not storing attribute vectors_norm\n",
            "INFO - 12:24:35: not storing attribute cum_table\n",
            "INFO - 12:24:35: saved w2v_model_window-10_size-400.mdl\n",
            "WARNING - 12:24:35: Effective 'alpha' higher than previous training cycles\n",
            "INFO - 12:24:35: training model with 1 workers on 3319 vocabulary and 2 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
            "INFO - 12:24:36: EPOCH 1 - PROGRESS: at 39.38% examples, 78067 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:37: EPOCH 1 - PROGRESS: at 74.71% examples, 73361 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:37: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:37: EPOCH - 1 : training on 523700 raw words (198873 effective words) took 2.6s, 75811 effective words/s\n",
            "INFO - 12:24:38: EPOCH 2 - PROGRESS: at 39.38% examples, 79353 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:39: EPOCH 2 - PROGRESS: at 82.28% examples, 80271 words/s, in_qsize 0, out_qsize 0\n",
            "INFO - 12:24:40: worker thread finished; awaiting finish of 0 more threads\n",
            "INFO - 12:24:40: EPOCH - 2 : training on 523700 raw words (199079 effective words) took 2.5s, 80267 effective words/s\n",
            "INFO - 12:24:40: training on a 1047400 raw words (397952 effective words) took 5.1s, 77698 effective words/s\n",
            "INFO - 12:24:40: saving Word2Vec object under w2v_model_window-10_size-500.mdl, separately None\n",
            "INFO - 12:24:40: not storing attribute vectors_norm\n",
            "INFO - 12:24:40: not storing attribute cum_table\n",
            "INFO - 12:24:40: saved w2v_model_window-10_size-500.mdl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRfVnlojTp0j",
        "outputId": "0ebaefd3-425a-4577-9fa2-a81cc1b152d7"
      },
      "source": [
        "model = Word2Vec.load(\"w2v_model_window-2_size-300.mdl\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 12:36:04: loading Word2Vec object from w2v_model_window-2_size-300.mdl\n",
            "INFO - 12:36:04: loading wv recursively from w2v_model_window-2_size-300.mdl.wv.* with mmap=None\n",
            "INFO - 12:36:04: setting ignored attribute vectors_norm to None\n",
            "INFO - 12:36:04: loading vocabulary recursively from w2v_model_window-2_size-300.mdl.vocabulary.* with mmap=None\n",
            "INFO - 12:36:04: loading trainables recursively from w2v_model_window-2_size-300.mdl.trainables.* with mmap=None\n",
            "INFO - 12:36:04: setting ignored attribute cum_table to None\n",
            "INFO - 12:36:04: loaded w2v_model_window-2_size-300.mdl\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qos5oq_QV1UE",
        "outputId": "76f472fb-53cd-40b4-ebd2-c4e550f6b9dd"
      },
      "source": [
        "model.wv.most_similar(positive=[\"grownup\"])"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('happen', 0.9999999403953552),\n",
              " ('feed', 0.9999998211860657),\n",
              " ('pull', 0.9999998211860657),\n",
              " ('television', 0.9999997615814209),\n",
              " ('arnie', 0.9999995827674866),\n",
              " ('valentine', 0.9999995827674866),\n",
              " ('cook', 0.999999463558197),\n",
              " ('rack', 0.9999994039535522),\n",
              " ('forward', 0.9999988675117493),\n",
              " ('hugh', 0.9999979734420776)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdYtTyi2WQhu",
        "outputId": "6618d817-1890-42b7-8d29-4d77671dc29f"
      },
      "source": [
        "model.wv.similarity(\"marge\", 'grownup')"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9761697"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 959
        },
        "id": "tgYK0Tb45eMt",
        "outputId": "f11ad3a2-cb7e-48fc-eba2-92c9fa6ce0e6"
      },
      "source": [
        "for model in model_var:\r\n",
        "  name = model + \".bin\"\r\n",
        "  model = Word2Vec(min_count=20,\r\n",
        "                     window=windows, \r\n",
        "                     size=dimensions,\r\n",
        "                     sample=6e-5, \r\n",
        "                     alpha=0.03, \r\n",
        "                     min_alpha=0.0007, \r\n",
        "                     negative=20,\r\n",
        "                     workers=cores-1)\r\n",
        "\r\n",
        "                     \r\n",
        "  t = time()\r\n",
        "  model.build_vocab(sentences, progress_per=10000)\r\n",
        "  print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))\r\n",
        "\r\n",
        "  t = time()\r\n",
        "  model.train(sentences, total_examples=w2v_model.corpus_count, epochs=2, report_delay=1)\r\n",
        "  print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))\r\n",
        "\r\n",
        "  model.save(name)\r\n",
        "      "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 12:33:04: collecting all words and their counts\n",
            "INFO - 12:33:04: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
            "INFO - 12:33:04: PROGRESS: at sentence #10000, processed 61718 words, keeping 9558 word types\n",
            "INFO - 12:33:04: PROGRESS: at sentence #20000, processed 127351 words, keeping 14506 word types\n",
            "INFO - 12:33:04: PROGRESS: at sentence #30000, processed 187829 words, keeping 17619 word types\n",
            "INFO - 12:33:04: PROGRESS: at sentence #40000, processed 243332 words, keeping 20385 word types\n",
            "INFO - 12:33:05: PROGRESS: at sentence #50000, processed 303182 words, keeping 22878 word types\n",
            "INFO - 12:33:05: PROGRESS: at sentence #60000, processed 363940 words, keeping 25200 word types\n",
            "INFO - 12:33:05: PROGRESS: at sentence #70000, processed 425408 words, keeping 27401 word types\n",
            "INFO - 12:33:05: PROGRESS: at sentence #80000, processed 485464 words, keeping 29275 word types\n",
            "INFO - 12:33:05: collected 30178 word types from a corpus of 523700 raw words and 85964 sentences\n",
            "INFO - 12:33:05: Loading a fresh vocabulary\n",
            "INFO - 12:33:05: effective_min_count=20 retains 3319 unique words (10% of original 30178, drops 26859)\n",
            "INFO - 12:33:05: effective_min_count=20 leaves 437324 word corpus (83% of original 523700, drops 86376)\n",
            "INFO - 12:33:05: deleting the raw counts dictionary of 30178 items\n",
            "INFO - 12:33:05: sample=6e-05 downsamples 1200 most-common words\n",
            "INFO - 12:33:05: downsampling leaves estimated 199161 word corpus (45.5% of prior 437324)\n",
            "INFO - 12:33:05: estimated required memory for 3319 words and 500 dimensions: 14935500 bytes\n",
            "INFO - 12:33:05: resetting layer weights\n",
            "INFO - 12:33:06: training model with 1 workers on 3319 vocabulary and 500 features, using sg=0 hs=0 sample=6e-05 negative=20 window=10\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Time to build vocab: 0.04 mins\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception in thread Thread-12:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
            "    self.run()\n",
            "  File \"/usr/lib/python3.6/threading.py\", line 864, in run\n",
            "    self._target(*self._args, **self._kwargs)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\", line 270, in _job_producer\n",
            "    epoch_progress = 1.0 * pushed_words / total_words\n",
            "TypeError: unsupported operand type(s) for /: 'float' and 'NoneType'\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-74-4e205e68f201>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mw2v_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpus_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Time to train the model: {} mins'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks)\u001b[0m\n\u001b[1;32m    890\u001b[0m             \u001b[0msentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m             \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             queue_factor=queue_factor, report_delay=report_delay, compute_loss=compute_loss, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_sentences\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, sentences, corpus_file, total_examples, total_words, epochs, start_alpha, end_alpha, word_count, queue_factor, report_delay, compute_loss, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_alpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mend_alpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_count\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_count\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m             \u001b[0mqueue_factor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqueue_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreport_delay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreport_delay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             **kwargs)\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_job_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_iterable, corpus_file, epochs, total_examples, total_words, queue_factor, report_delay, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    551\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch(\n\u001b[1;32m    552\u001b[0m                     \u001b[0mdata_iterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m                     total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)\n\u001b[0m\u001b[1;32m    554\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m                 trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch = self._train_epoch_corpusfile(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, data_iterable, cur_epoch, total_examples, total_words, queue_factor, report_delay)\u001b[0m\n\u001b[1;32m    487\u001b[0m         trained_word_count, raw_word_count, job_tally = self._log_epoch_progress(\n\u001b[1;32m    488\u001b[0m             \u001b[0mprogress_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_queue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcur_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_examples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_examples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_words\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal_words\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             report_delay=report_delay, is_corpus_file_mode=False)\n\u001b[0m\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrained_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_word_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_tally\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36m_log_epoch_progress\u001b[0;34m(self, progress_queue, job_queue, cur_epoch, total_examples, total_words, report_delay, is_corpus_file_mode)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m             \u001b[0mreport\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprogress_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# blocks if workers too slow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreport\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# a thread reporting that it finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m                 \u001b[0munfinished_worker_count\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"'timeout' must be a non-negative number\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arRtyx2h-2wH"
      },
      "source": [
        "model = Word2Vec(min_count=20,\r\n",
        "                     window=windows, \r\n",
        "                     size=dimensions,\r\n",
        "                     sample=6e-5, \r\n",
        "                     alpha=0.03, \r\n",
        "                     min_alpha=0.0007, \r\n",
        "                     negative=20,\r\n",
        "                     workers=cores-1)\r\n",
        "      model.save(name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YYcTaouUzjh5"
      },
      "source": [
        "w2v_model = Word2Vec(min_count=20,\r\n",
        "                     window=2, \r\n",
        "                     size=300,\r\n",
        "                     sample=6e-5, \r\n",
        "                     alpha=0.03, \r\n",
        "                     min_alpha=0.0007, \r\n",
        "                     negative=20,\r\n",
        "                     workers=cores-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0FM6wyGzozZ",
        "outputId": "4c738095-0a10-4559-e080-2d5e438d65fe"
      },
      "source": [
        "import tempfile\r\n",
        "\r\n",
        "with tempfile.NamedTemporaryFile(prefix='gensim-model-', delete=False) as tmp:\r\n",
        "    temporary_filepath = tmp.name\r\n",
        "    w2v_model.save(\"w2v_model\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO - 12:15:19: saving Word2Vec object under w2v_model, separately None\n",
            "INFO - 12:15:19: not storing attribute vectors_norm\n",
            "INFO - 12:15:19: not storing attribute cum_table\n",
            "INFO - 12:15:19: saved w2v_model\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zA75469C7GvO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
