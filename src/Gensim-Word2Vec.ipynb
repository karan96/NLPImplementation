{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from collections import defaultdict\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging  # Setting up the loggings to monitor gensim\n",
    "logging.basicConfig(format=\"%(levelname)s - %(asctime)s: %(message)s\", datefmt= '%H:%M:%S', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158314, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('simpsons_dataset.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.info of              raw_character_text  \\\n",
       "0                   Miss Hoover   \n",
       "1                  Lisa Simpson   \n",
       "2                   Miss Hoover   \n",
       "3                  Lisa Simpson   \n",
       "4       Edna Krabappel-Flanders   \n",
       "5                 Martin Prince   \n",
       "6       Edna Krabappel-Flanders   \n",
       "7                  Bart Simpson   \n",
       "8                           NaN   \n",
       "9                  Lisa Simpson   \n",
       "10                     Landlady   \n",
       "11                 Lisa Simpson   \n",
       "12                     Landlady   \n",
       "13                 Lisa Simpson   \n",
       "14                     Landlady   \n",
       "15                 Lisa Simpson   \n",
       "16                          NaN   \n",
       "17                 Bart Simpson   \n",
       "18                 Nelson Muntz   \n",
       "19                 Bart Simpson   \n",
       "20                 Terri/sherri   \n",
       "21                 Bart Simpson   \n",
       "22          Milhouse Van Houten   \n",
       "23                 Bart Simpson   \n",
       "24                 Bart Simpson   \n",
       "25          Milhouse Van Houten   \n",
       "26                 Bart Simpson   \n",
       "27                 Bart Simpson   \n",
       "28               Wendell Borton   \n",
       "29                          NaN   \n",
       "...                         ...   \n",
       "158284                BERGSTROM   \n",
       "158285            Homer Simpson   \n",
       "158286                      NaN   \n",
       "158287             Lisa Simpson   \n",
       "158288            Marge Simpson   \n",
       "158289             Lisa Simpson   \n",
       "158290            Marge Simpson   \n",
       "158291             Lisa Simpson   \n",
       "158292            Marge Simpson   \n",
       "158293             Lisa Simpson   \n",
       "158294            Marge Simpson   \n",
       "158295             Lisa Simpson   \n",
       "158296            Marge Simpson   \n",
       "158297             Lisa Simpson   \n",
       "158298            Marge Simpson   \n",
       "158299             Lisa Simpson   \n",
       "158300            Marge Simpson   \n",
       "158301             Lisa Simpson   \n",
       "158302            Marge Simpson   \n",
       "158303             Lisa Simpson   \n",
       "158304            Marge Simpson   \n",
       "158305             Lisa Simpson   \n",
       "158306                      NaN   \n",
       "158307             Lisa Simpson   \n",
       "158308              Miss Hoover   \n",
       "158309              Miss Hoover   \n",
       "158310              Miss Hoover   \n",
       "158311              Miss Hoover   \n",
       "158312             Ralph Wiggum   \n",
       "158313                    JANEY   \n",
       "\n",
       "                                             spoken_words  \n",
       "0       No, actually, it was a little of both. Sometim...  \n",
       "1                                  Where's Mr. Bergstrom?  \n",
       "2       I don't know. Although I'd sure like to talk t...  \n",
       "3                              That life is worth living.  \n",
       "4       The polls will be open from now until the end ...  \n",
       "5             I don't think there's anything left to say.  \n",
       "6                                                   Bart?  \n",
       "7                          Victory party under the slide!  \n",
       "8                                                     NaN  \n",
       "9                           Mr. Bergstrom! Mr. Bergstrom!  \n",
       "10      Hey, hey, he Moved out this morning. He must h...  \n",
       "11                    Do you know where I could find him?  \n",
       "12      I think he's taking the next train to Capital ...  \n",
       "13      The train, how like him... traditional, yet en...  \n",
       "14      Yes, and it's been the backbone of our country...  \n",
       "15                             I see he touched you, too.  \n",
       "16                                                    NaN  \n",
       "17                        Hey, thanks for your vote, man.  \n",
       "18                     I didn't vote. Voting's for geeks.  \n",
       "19      Well, you got that right. Thanks for your vote...  \n",
       "20                                             We forgot.  \n",
       "21      Well, don't sweat it. Just so long as a couple...  \n",
       "22                                                 Uh oh.  \n",
       "23                                                 Lewis?  \n",
       "24                              Somebody must have voted.  \n",
       "25                 What about you, Bart? Didn't you vote?  \n",
       "26                                                 Uh oh.  \n",
       "27                                                    NaN  \n",
       "28                                      Yayyyyyyyyyyyyyy!  \n",
       "29                                                    NaN  \n",
       "...                                                   ...  \n",
       "158284                      Mr. Simpson, she did earn it.  \n",
       "158285                You are smooth. I'll give you that.  \n",
       "158286                                                NaN  \n",
       "158287  He ruined the one chance I had of getting to k...  \n",
       "158288  Well... I'll tell you what. Why don't we invit...  \n",
       "158289  Oh, Mom, that's wonderful. Can I find out his ...  \n",
       "158290                                              Sure.  \n",
       "158291                           Can I wear your jewelry?  \n",
       "158292                                              Sure.  \n",
       "158293                         Can I get my ears pierced?  \n",
       "158294                                                No.  \n",
       "158295                           Can I dye my shoes pink?  \n",
       "158296                                               Yes.  \n",
       "158297                              Can I paint my nails?  \n",
       "158298                                                No.  \n",
       "158299                                  Can we have wine?  \n",
       "158300                                               Yes.  \n",
       "158301                                   Can I have wine?  \n",
       "158302                                                No.  \n",
       "158303                        Does Bart have to be there?  \n",
       "158304                                               Yes.  \n",
       "158305                            Can we do it this week?  \n",
       "158306                                                NaN  \n",
       "158307  Mr. Bergstrom, we request the pleasure of your...  \n",
       "158308                                Good morning, Lisa.  \n",
       "158309                                          I'm back.  \n",
       "158310  You see, class, my Lyme disease turned out to ...  \n",
       "158311                                 Psy-cho-so-ma-tic.  \n",
       "158312                     Does that mean you were crazy?  \n",
       "158313                  No, that means she was faking it.  \n",
       "\n",
       "[158314 rows x 2 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_character_text</th>\n",
       "      <th>spoken_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>No, actually, it was a little of both. Sometim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>Where's Mr. Bergstrom?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Miss Hoover</td>\n",
       "      <td>I don't know. Although I'd sure like to talk t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lisa Simpson</td>\n",
       "      <td>That life is worth living.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Edna Krabappel-Flanders</td>\n",
       "      <td>The polls will be open from now until the end ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        raw_character_text                                       spoken_words\n",
       "0              Miss Hoover  No, actually, it was a little of both. Sometim...\n",
       "1             Lisa Simpson                             Where's Mr. Bergstrom?\n",
       "2              Miss Hoover  I don't know. Although I'd sure like to talk t...\n",
       "3             Lisa Simpson                         That life is worth living.\n",
       "4  Edna Krabappel-Flanders  The polls will be open from now until the end ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    17814\n",
       "spoken_words          26459\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raw_character_text    0\n",
       "spoken_words          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna().reset_index(drop=True)\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en', disable=['ner', 'parser']) # disabling Named Entity Recognition for speed\n",
    "\n",
    "def cleaning(doc):\n",
    "    # Lemmatizes and removes stopwords\n",
    "    # doc needs to be a spacy Doc object\n",
    "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
    "    # Word2Vec uses context words to learn the vector representation of a target word,\n",
    "    # if a sentence is only one or two words long,\n",
    "    # the benefit for the training is very small\n",
    "    if len(txt) > 2:\n",
    "        return ' '.join(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['spoken_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to clean up everything: 1.19 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "txt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n",
    "\n",
    "print('Time to clean up everything: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85954, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = pd.DataFrame({'clean': txt})\n",
    "df_clean = df_clean.dropna().drop_duplicates()\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>actually little disease magazine news show nat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>know sure like talk touch lesson plan teach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>life worth live</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poll open end recess case decide thought final...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>victory party slide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mr bergstrom mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>hey hey move morning new job take copernicus c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>think take train capital city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>train like traditional environmentally sound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>yes backbone country leland stanford drive gol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hey thank vote man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>vote voting geek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>get right thank vote girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>sweat long couple people right milhouse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>martin martin like recount</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>want sure martin martin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>way mister president</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>board track afternoon delight come shelbyville...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>mr bergstrom hey mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>oh mean go leave like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>ah sorry lisa know life substitute teacher fra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ah true teacher come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>lie good know need project capital city</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>problem middle class anybody care abandon need</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>understand mr bergstrom go miss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>feel like rely need know</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>thank mr bergstrom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>guess mind run alongside train speed life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>goodbye lisa honey okay read note</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>throw party big bash champagne musician holy man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131785</th>\n",
       "      <td>life take place rest hear</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131786</th>\n",
       "      <td>place intelligence asset liability</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131787</th>\n",
       "      <td>yes place believe true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131788</th>\n",
       "      <td>believe word body language semitic good look</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131789</th>\n",
       "      <td>dear miss hoover lyme disease miss kevin bit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131790</th>\n",
       "      <td>oh great ralph</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131791</th>\n",
       "      <td>hey kid learn week springfield museum natural ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131792</th>\n",
       "      <td>hmmm lisa need museum tomorrow think</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131795</th>\n",
       "      <td>homer talk lisa concerned relationship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131796</th>\n",
       "      <td>mom think drift apart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131799</th>\n",
       "      <td>marge understand trap smart think right right ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131800</th>\n",
       "      <td>hey mean suggested donation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131801</th>\n",
       "      <td>pay wish sir</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131802</th>\n",
       "      <td>wish pay zero</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131806</th>\n",
       "      <td>think people go to pay dollar cent goodness go...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131809</th>\n",
       "      <td>hey pay read sign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131811</th>\n",
       "      <td>tooth jag edge rip body swallow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131813</th>\n",
       "      <td>actually mr simpson know great deal process mu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131815</th>\n",
       "      <td>ohh pretty creepy chase wolf man</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131817</th>\n",
       "      <td>mr simpson go to presumptuous notice lisa feel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131820</th>\n",
       "      <td>tell right look see everybody dad good educati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131821</th>\n",
       "      <td>mr simpson get big man wonderful girl future s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131824</th>\n",
       "      <td>great tell favor tell earn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131827</th>\n",
       "      <td>ruin chance get know mr bergstrom outside school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131828</th>\n",
       "      <td>tell invite mr bergstrom dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131829</th>\n",
       "      <td>oh mom wonderful find favorite dish help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131835</th>\n",
       "      <td>dye shoe pink</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131846</th>\n",
       "      <td>mr bergstrom request pleasure company mr bergs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131849</th>\n",
       "      <td>class lyme disease turn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131850</th>\n",
       "      <td>psy cho ma tic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85954 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    clean\n",
       "0       actually little disease magazine news show nat...\n",
       "2             know sure like talk touch lesson plan teach\n",
       "3                                         life worth live\n",
       "4       poll open end recess case decide thought final...\n",
       "7                                     victory party slide\n",
       "8                               mr bergstrom mr bergstrom\n",
       "9       hey hey move morning new job take copernicus c...\n",
       "11                          think take train capital city\n",
       "12           train like traditional environmentally sound\n",
       "13      yes backbone country leland stanford drive gol...\n",
       "15                                     hey thank vote man\n",
       "16                                       vote voting geek\n",
       "17                              get right thank vote girl\n",
       "19                sweat long couple people right milhouse\n",
       "27                             martin martin like recount\n",
       "29                                want sure martin martin\n",
       "30                                   way mister president\n",
       "31      board track afternoon delight come shelbyville...\n",
       "32                          mr bergstrom hey mr bergstrom\n",
       "36                                  oh mean go leave like\n",
       "37      ah sorry lisa know life substitute teacher fra...\n",
       "39                                   ah true teacher come\n",
       "41                lie good know need project capital city\n",
       "43         problem middle class anybody care abandon need\n",
       "44                        understand mr bergstrom go miss\n",
       "46                               feel like rely need know\n",
       "47                                     thank mr bergstrom\n",
       "49              guess mind run alongside train speed life\n",
       "50                      goodbye lisa honey okay read note\n",
       "51       throw party big bash champagne musician holy man\n",
       "...                                                   ...\n",
       "131785                          life take place rest hear\n",
       "131786                 place intelligence asset liability\n",
       "131787                             yes place believe true\n",
       "131788       believe word body language semitic good look\n",
       "131789    dear miss hoover lyme disease miss kevin bit...\n",
       "131790                                     oh great ralph\n",
       "131791  hey kid learn week springfield museum natural ...\n",
       "131792               hmmm lisa need museum tomorrow think\n",
       "131795             homer talk lisa concerned relationship\n",
       "131796                              mom think drift apart\n",
       "131799  marge understand trap smart think right right ...\n",
       "131800                        hey mean suggested donation\n",
       "131801                                       pay wish sir\n",
       "131802                                      wish pay zero\n",
       "131806  think people go to pay dollar cent goodness go...\n",
       "131809                                  hey pay read sign\n",
       "131811                    tooth jag edge rip body swallow\n",
       "131813  actually mr simpson know great deal process mu...\n",
       "131815                   ohh pretty creepy chase wolf man\n",
       "131817  mr simpson go to presumptuous notice lisa feel...\n",
       "131820  tell right look see everybody dad good educati...\n",
       "131821  mr simpson get big man wonderful girl future s...\n",
       "131824                         great tell favor tell earn\n",
       "131827   ruin chance get know mr bergstrom outside school\n",
       "131828                    tell invite mr bergstrom dinner\n",
       "131829           oh mom wonderful find favorite dish help\n",
       "131835                                      dye shoe pink\n",
       "131846  mr bergstrom request pleasure company mr bergs...\n",
       "131849                            class lyme disease turn\n",
       "131850                                     psy cho ma tic\n",
       "\n",
       "[85954 rows x 1 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models.phrases import Phrases, Phraser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent = [row.split() for row in df_clean['clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['psy', 'cho', 'ma', 'tic']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:58:52: collecting all words and their counts\n",
      "INFO - 17:58:52: PROGRESS: at sentence #0, processed 0 words and 0 word types\n",
      "INFO - 17:58:52: PROGRESS: at sentence #10000, processed 63557 words and 52796 word types\n",
      "INFO - 17:58:52: PROGRESS: at sentence #20000, processed 130938 words and 99801 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #30000, processed 192959 words and 138413 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #40000, processed 249832 words and 172509 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #50000, processed 311271 words and 208406 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #60000, processed 373576 words and 243519 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #70000, processed 436427 words and 278547 word types\n",
      "INFO - 17:58:53: PROGRESS: at sentence #80000, processed 497891 words and 311704 word types\n",
      "INFO - 17:58:53: collected 330480 word types from a corpus of 537095 words (unigram + bigrams) and 85954 sentences\n",
      "INFO - 17:58:53: using 330480 counts as vocab in Phrases<0 vocab, min_count=30, threshold=10.0, max_vocab_size=40000000>\n"
     ]
    }
   ],
   "source": [
    "phrases = Phrases(sent, min_count=30, progress_per=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:58:53: source_vocab length 330480\n",
      "INFO - 17:58:56: Phraser built with 127 phrasegrams\n"
     ]
    }
   ],
   "source": [
    "bigram = Phraser(phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = bigram[sent] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.interfaces.TransformedCorpus at 0x210ac487160>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30242"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_freq = defaultdict(int)\n",
    "for sent in sentences:\n",
    "    for i in sent:\n",
    "        word_freq[i] += 1\n",
    "len(word_freq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['oh', 'like', 'know', 'get', 'hey', 'think', 'come', 'right', 'look', 'want']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(word_freq, key=word_freq.get, reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "the best dog in the world"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w2v_model = Word2Vec(min_count=20,\n",
    "                     window=2, \n",
    "                     size=300,\n",
    "                     sample=6e-5, \n",
    "                     alpha=0.03, \n",
    "                     min_alpha=0.0007, \n",
    "                     negative=20,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:58:57: collecting all words and their counts\n",
      "INFO - 17:58:57: PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "INFO - 17:58:58: PROGRESS: at sentence #10000, processed 61710 words, keeping 9572 word types\n",
      "INFO - 17:58:58: PROGRESS: at sentence #20000, processed 127345 words, keeping 14535 word types\n",
      "INFO - 17:58:58: PROGRESS: at sentence #30000, processed 187806 words, keeping 17660 word types\n",
      "INFO - 17:58:58: PROGRESS: at sentence #40000, processed 243314 words, keeping 20424 word types\n",
      "INFO - 17:58:58: PROGRESS: at sentence #50000, processed 303176 words, keeping 22934 word types\n",
      "INFO - 17:58:59: PROGRESS: at sentence #60000, processed 363916 words, keeping 25246 word types\n",
      "INFO - 17:58:59: PROGRESS: at sentence #70000, processed 425379 words, keeping 27467 word types\n",
      "INFO - 17:58:59: PROGRESS: at sentence #80000, processed 485507 words, keeping 29350 word types\n",
      "INFO - 17:58:59: collected 30242 word types from a corpus of 523616 raw words and 85954 sentences\n",
      "INFO - 17:58:59: Loading a fresh vocabulary\n",
      "INFO - 17:58:59: effective_min_count=20 retains 3309 unique words (10% of original 30242, drops 26933)\n",
      "INFO - 17:58:59: effective_min_count=20 leaves 437086 word corpus (83% of original 523616, drops 86530)\n",
      "INFO - 17:58:59: deleting the raw counts dictionary of 30242 items\n",
      "INFO - 17:58:59: sample=6e-05 downsamples 1199 most-common words\n",
      "INFO - 17:58:59: downsampling leaves estimated 198624 word corpus (45.4% of prior 437086)\n",
      "INFO - 17:58:59: estimated required memory for 3309 words and 300 dimensions: 9596100 bytes\n",
      "INFO - 17:58:59: resetting layer weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab: 0.04 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.build_vocab(sentences, progress_per=10000)\n",
    "\n",
    "print('Time to build vocab: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:59:00: training model with 7 workers on 3309 vocabulary and 300 features, using sg=0 hs=0 sample=6e-05 negative=20 window=2\n",
      "INFO - 17:59:01: EPOCH 1 - PROGRESS: at 53.71% examples, 104450 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:02: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:02: EPOCH - 1 : training on 523616 raw words (198345 effective words) took 1.9s, 104950 effective words/s\n",
      "INFO - 17:59:03: EPOCH 2 - PROGRESS: at 55.69% examples, 106801 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:04: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:04: EPOCH - 2 : training on 523616 raw words (198260 effective words) took 1.8s, 111515 effective words/s\n",
      "INFO - 17:59:05: EPOCH 3 - PROGRESS: at 55.69% examples, 105768 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:05: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:05: EPOCH - 3 : training on 523616 raw words (198396 effective words) took 1.8s, 110544 effective words/s\n",
      "INFO - 17:59:06: EPOCH 4 - PROGRESS: at 51.81% examples, 100850 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:07: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:07: EPOCH - 4 : training on 523616 raw words (198528 effective words) took 1.8s, 108177 effective words/s\n",
      "INFO - 17:59:08: EPOCH 5 - PROGRESS: at 57.55% examples, 111101 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:09: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:09: EPOCH - 5 : training on 523616 raw words (198719 effective words) took 1.8s, 109369 effective words/s\n",
      "INFO - 17:59:10: EPOCH 6 - PROGRESS: at 57.55% examples, 110004 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:11: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:11: EPOCH - 6 : training on 523616 raw words (198322 effective words) took 1.8s, 107786 effective words/s\n",
      "INFO - 17:59:12: EPOCH 7 - PROGRESS: at 55.69% examples, 103641 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:13: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:13: EPOCH - 7 : training on 523616 raw words (198946 effective words) took 1.8s, 109267 effective words/s\n",
      "INFO - 17:59:14: EPOCH 8 - PROGRESS: at 53.71% examples, 104075 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:15: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:15: EPOCH - 8 : training on 523616 raw words (198713 effective words) took 1.8s, 109441 effective words/s\n",
      "INFO - 17:59:16: EPOCH 9 - PROGRESS: at 53.71% examples, 101508 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:16: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:16: EPOCH - 9 : training on 523616 raw words (198777 effective words) took 1.8s, 108180 effective words/s\n",
      "INFO - 17:59:17: EPOCH 10 - PROGRESS: at 53.71% examples, 104637 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:18: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:18: EPOCH - 10 : training on 523616 raw words (198531 effective words) took 1.9s, 105584 effective words/s\n",
      "INFO - 17:59:19: EPOCH 11 - PROGRESS: at 57.55% examples, 110042 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:20: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:20: EPOCH - 11 : training on 523616 raw words (198397 effective words) took 1.8s, 111623 effective words/s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:59:21: EPOCH 12 - PROGRESS: at 53.71% examples, 102034 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:22: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:22: EPOCH - 12 : training on 523616 raw words (198611 effective words) took 1.8s, 109061 effective words/s\n",
      "INFO - 17:59:23: EPOCH 13 - PROGRESS: at 53.71% examples, 101511 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:24: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:24: EPOCH - 13 : training on 523616 raw words (198436 effective words) took 1.8s, 109529 effective words/s\n",
      "INFO - 17:59:25: EPOCH 14 - PROGRESS: at 57.55% examples, 109126 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:26: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:26: EPOCH - 14 : training on 523616 raw words (198510 effective words) took 1.8s, 111039 effective words/s\n",
      "INFO - 17:59:27: EPOCH 15 - PROGRESS: at 57.55% examples, 110538 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:27: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:27: EPOCH - 15 : training on 523616 raw words (198581 effective words) took 1.7s, 114373 effective words/s\n",
      "INFO - 17:59:28: EPOCH 16 - PROGRESS: at 53.71% examples, 104316 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:29: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:29: EPOCH - 16 : training on 523616 raw words (198206 effective words) took 1.9s, 106151 effective words/s\n",
      "INFO - 17:59:30: EPOCH 17 - PROGRESS: at 51.81% examples, 100323 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:31: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:31: EPOCH - 17 : training on 523616 raw words (199002 effective words) took 1.8s, 109186 effective words/s\n",
      "INFO - 17:59:32: EPOCH 18 - PROGRESS: at 55.69% examples, 106631 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:33: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:33: EPOCH - 18 : training on 523616 raw words (198396 effective words) took 1.9s, 107042 effective words/s\n",
      "INFO - 17:59:34: EPOCH 19 - PROGRESS: at 53.71% examples, 105674 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:35: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:35: EPOCH - 19 : training on 523616 raw words (198423 effective words) took 1.8s, 111038 effective words/s\n",
      "INFO - 17:59:36: EPOCH 20 - PROGRESS: at 53.71% examples, 102727 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:37: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:37: EPOCH - 20 : training on 523616 raw words (198555 effective words) took 1.8s, 109962 effective words/s\n",
      "INFO - 17:59:38: EPOCH 21 - PROGRESS: at 53.71% examples, 102210 words/s, in_qsize 0, out_qsize 1\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:38: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:38: EPOCH - 21 : training on 523616 raw words (198767 effective words) took 1.8s, 109768 effective words/s\n",
      "INFO - 17:59:39: EPOCH 22 - PROGRESS: at 49.86% examples, 97349 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:40: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:40: EPOCH - 22 : training on 523616 raw words (198578 effective words) took 1.9s, 102554 effective words/s\n",
      "INFO - 17:59:41: EPOCH 23 - PROGRESS: at 57.55% examples, 111823 words/s, in_qsize 0, out_qsize 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 17:59:42: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:42: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:42: EPOCH - 23 : training on 523616 raw words (198256 effective words) took 1.8s, 110265 effective words/s\n",
      "INFO - 17:59:43: EPOCH 24 - PROGRESS: at 57.55% examples, 110545 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:44: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:44: EPOCH - 24 : training on 523616 raw words (198874 effective words) took 1.8s, 113226 effective words/s\n",
      "INFO - 17:59:45: EPOCH 25 - PROGRESS: at 53.71% examples, 104668 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:46: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:46: EPOCH - 25 : training on 523616 raw words (198773 effective words) took 1.8s, 109697 effective words/s\n",
      "INFO - 17:59:47: EPOCH 26 - PROGRESS: at 53.71% examples, 104380 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:48: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:48: EPOCH - 26 : training on 523616 raw words (198588 effective words) took 1.8s, 108953 effective words/s\n",
      "INFO - 17:59:49: EPOCH 27 - PROGRESS: at 55.69% examples, 106943 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:49: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:49: EPOCH - 27 : training on 523616 raw words (198845 effective words) took 1.9s, 106818 effective words/s\n",
      "INFO - 17:59:50: EPOCH 28 - PROGRESS: at 55.69% examples, 107053 words/s, in_qsize 0, out_qsize 0\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:51: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:51: EPOCH - 28 : training on 523616 raw words (198267 effective words) took 1.8s, 112007 effective words/s\n",
      "INFO - 17:59:52: EPOCH 29 - PROGRESS: at 53.71% examples, 102632 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:53: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:53: EPOCH - 29 : training on 523616 raw words (198682 effective words) took 1.8s, 108157 effective words/s\n",
      "INFO - 17:59:54: EPOCH 30 - PROGRESS: at 53.71% examples, 104849 words/s, in_qsize 1, out_qsize 0\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 6 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 5 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 4 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 3 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 2 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 1 more threads\n",
      "INFO - 17:59:55: worker thread finished; awaiting finish of 0 more threads\n",
      "INFO - 17:59:55: EPOCH - 30 : training on 523616 raw words (198402 effective words) took 1.8s, 109450 effective words/s\n",
      "INFO - 17:59:55: training on a 15708480 raw words (5956686 effective words) took 54.9s, 108463 effective words/s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.92 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "\n",
    "w2v_model.train(sentences, total_examples=w2v_model.corpus_count, epochs=30, report_delay=1)\n",
    "\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('rude', 0.7770212888717651),\n",
       " ('sweetheart', 0.7760750651359558),\n",
       " ('gee', 0.7625381350517273),\n",
       " ('embarrassing', 0.7622367143630981),\n",
       " ('crummy', 0.7588742971420288),\n",
       " ('marge', 0.7517530918121338),\n",
       " ('hammock', 0.7325915098190308),\n",
       " ('happen', 0.7325051426887512),\n",
       " ('straighten', 0.7279349565505981),\n",
       " ('terrific', 0.716513991355896)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"homer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('grownup', 0.764975368976593),\n",
       " ('ralphie', 0.7616559267044067),\n",
       " ('worry', 0.7569176554679871),\n",
       " ('sure', 0.7567306160926819),\n",
       " ('rude', 0.7535579800605774),\n",
       " ('homer', 0.7517530918121338),\n",
       " ('raccoon', 0.7514562606811523),\n",
       " ('sweetheart', 0.7497808337211609),\n",
       " ('worried', 0.7441363334655762),\n",
       " ('crummy', 0.7433844804763794)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"marge\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('lisa', 0.8640710115432739),\n",
       " ('hearing', 0.8371952772140503),\n",
       " ('convince', 0.8040638566017151),\n",
       " ('mom', 0.7893967628479004),\n",
       " ('homework', 0.788345217704773),\n",
       " ('pay_attention', 0.7860027551651001),\n",
       " ('strangle', 0.7801192402839661),\n",
       " ('jealous', 0.7796902060508728),\n",
       " ('surprised', 0.7708951234817505),\n",
       " ('muntz', 0.7708556056022644)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.most_similar(positive=[\"bart\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.50523514"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity(\"homer\", 'tavern')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.734279"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.similarity('maggie', 'baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING - 19:37:10: vectors for words {'kearney'} are not present in the model, ignoring these words\n",
      "C:\\Users\\saxen\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'milhouse'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match(['jimbo', 'milhouse', 'kearney'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saxen\\AppData\\Roaming\\Python\\Python36\\site-packages\\gensim\\models\\keyedvectors.py:877: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'nelson'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_model.wv.doesnt_match([\"nelson\", \"bart\", \"milhouse\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vec = w2v_model.wv['homer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'vec' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-95b62e977a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'vec' is not defined"
     ]
    }
   ],
   "source": [
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
